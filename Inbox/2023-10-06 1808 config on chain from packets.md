
>[!tip] Created: [2023-10-06 Fri 18:08]

>[!question] Targets: 

>[!danger] Depends: 

If we make a collection of autogpt agents that are programmed by whatever the QA has selected as solution for a given packet, then people can create solutions, QA passes them, and they immediately get triggered to be part of the new system.

This assures the contributors that they are getting recognition, and they can see system updates occur instantly.

The way we manage data, where the user controls everything, means the stakes a low for an upgrade that is malicious.  Each user can be asked if they want to upgrade, and be told how many other people have made the upgrade, then users can set their own limits on upgrading.  Can behave differently if it came from the company itself, or if it came from outside.

Each proposal would be tested by an AI test bench too, so we could have good confidence.

Be fun to see the background work of what the agents are doing as they reason their way thru the things you ask them to do.  Incorporate the agent plan into the prompt context so you can comment or complain or file an issue about a given thing.

