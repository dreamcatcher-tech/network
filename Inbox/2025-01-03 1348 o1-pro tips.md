
>[!tip] Created: [2025-01-03 Fri 13:48]

>[!question] Targets: 

>[!danger] Depends: 

And so the issue seems to be when generating with O1 Pro that if it has ancillary files within the prompt and the files are wrong it will be unable to ignore them so it can't seem to ignore things when it's told and so this means that we might need to make a dedicated step where it selects what to ignore and then it blinks them out of its mind before answering the question because it seems to be unable to handle this internally.

Also, being able to make top-level guidance documents, blocking out everything else, and then maybe using reference documents like prompts and rules to guide that, can help roll down the stack. So basically, we're just top-level thinking, apply the reasoning, and then low-level thinking, where we're following out the commands, as opposed to trying to do everything all at once, or do multiple features at once.

Also can't ignore content well, so things like issues, need to narrow those down to just little pieces.  Uncertainty kills it, so can't be vague about things.

Asking leading questions is better than asking for a final solution, since the lead up serves to allow us to check its thinking, and redo the prompt each time if we want changes, before getting it to do the final work in some kind of format.

Formats and rules seem to confuse it, as its best responses come when it is most free.

Might be easiest to talk about processes in terms of math formulas, then alter the math formula to ensure it mentions or covers all the requirements.  The requirements might be just a list of statements, and we take the statements, and ensure they fit the math formula, then we write all the other files like README and process.md and ultimately the code implementation.

