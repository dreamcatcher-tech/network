
>[!tip] Created: [2023-10-10 Tue 14:22]

>[!question] Targets: 

>[!danger] Depends: 

It just feels like gpt4 has some kind of mastery of the sae substance that we use to think - like it has a form of general intelligence or logical correctness so that any random proposal can be ranked by it for fitness.

With an arrange of self checks and reflection, this spark should be enough to accomplish almost any mundane task a human might wish to perform.

Fruit seeking to be tastier so they increase their consumption is no different from us fine tuning our apps to have the best taste.  Just seems other factors affect the spread rates beyond just taste.

The data change rate can be less with AI, so git might be fine as a hash based filesystem, instead of interblock ?

Coverage has a different meaning in semantic land - semantic coverage.

To win in the AI transformation, a company must slash its headcount down to almost nothing, and then they must commit to sharing the profits fairly amongst all who contribute - administrative control allows inequity - if this is handed over to the machine, only then can match the pace of change of those who committed fully.  So earliest to commit and fastest to evangelize wins.

3 points:
1. we can make the managers use the AI to let us train it more, as well they can say what they expect
2. can use the accountancy flag as a means to inject into other areas of the business
3. fairness is the key here, which encompasses transparency, but also with comparison to market
4. we can loop thru rows of data, fairly mercilessly
5. there's a massive upset coming, we don't want to be on the wrong side of it
6. this anything app applies to you, but also applies to your customers
7. ultimately we could let them operate with no books, using our system to replace theirs - how much do you struggle with the xero structure, and how much do customers do so ?  We can make our own books app, even

If you have enough intelligence to operate in natural language, then you can operate in mechanical terms like counts, scores, and other useful things, but most importantly you can defend your decision. 

The whole trick seems to be ways to break large tasks down to something that fits in the context window, like a skill or a strategy.

Aliasing could be discovered by a sliding window and comparing the outputs as being meaningfully different, depending on where the window went.

The anything app should be programmed within the anything app.  The more is built outside, the more problems we have to deal with outside the core app.  Ultimately it would be come free floating on the app store, be forked, and so it would be unrecognizable as the starting point.

must be careful not to develop anything the MS or others are making, as they will win that game.  We all know the interface we want now, and so we should focus on applying it to loop in chain, to make apps at the fastest possible rate, which is faster than a human, and near instant.  None of their offerings appear to be a social network, nor an application framework.  We aim to have our own native AIs running on chain, which can be done in stripped down models once the use case is clear.

Does consensus need to be precisely arrived at by formula, or is it simply agreement on a result, without regard to how it got there ?  If all parties agree, that should be enough. This is no different to the initial state being agreed to, but it just goes on forever in this way.

Typescript is suddenly important in AI since it needs feedback on why what it did was wrong.

Because we can replace whole npm packages with AI processing of strings, this is why we can start to decompile the software industry and reduce its moving parts.  Using an AI as a "all npm packages" type of arrangement 

PAssing the turing test means they can fake any authentication intended for a human, except they cannot fake a crypto signature.