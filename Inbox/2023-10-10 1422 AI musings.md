
>[!tip] Created: [2023-10-10 Tue 14:22]

>[!question] Targets: 

>[!danger] Depends: 

It just feels like gpt4 has some kind of mastery of the sae substance that we use to think - like it has a form of general intelligence or logical correctness so that any random proposal can be ranked by it for fitness.

With an arrange of self checks and reflection, this spark should be enough to accomplish almost any mundane task a human might wish to perform.

Fruit seeking to be tastier so they increase their consumption is no different from us fine tuning our apps to have the best taste.  Just seems other factors affect the spread rates beyond just taste.

The data change rate can be less with AI, so git might be fine as a hash based filesystem, instead of interblock ?

Coverage has a different meaning in semantic land - semantic coverage.

To win in the AI transformation, a company must slash its headcount down to almost nothing, and then they must commit to sharing the profits fairly amongst all who contribute - administrative control allows inequity - if this is handed over to the machine, only then can match the pace of change of those who committed fully.  So earliest to commit and fastest to evangelize wins.

3 points:
1. we can make the managers use the AI to let us train it more, as well they can say what they expect
2. can use the accountancy flag as a means to inject into other areas of the business
3. fairness is the key here, which encompasses transparency, but also with comparison to market
4. we can loop thru rows of data, fairly mercilessly
5. there's a massive upset coming, we don't want to be on the wrong side of it
6. this anything app applies to you, but also applies to your customers
7. ultimately we could let them operate with no books, using our system to replace theirs - how much do you struggle with the xero structure, and how much do customers do so ?  We can make our own books app, even

If you have enough intelligence to operate in natural language, then you can operate in mechanical terms like counts, scores, and other useful things, but most importantly you can defend your decision. 

The whole trick seems to be ways to break large tasks down to something that fits in the context window, like a skill or a strategy.

Aliasing could be discovered by a sliding window and comparing the outputs as being meaningfully different, depending on where the window went.

The anything app should be programmed within the anything app.  The more is built outside, the more problems we have to deal with outside the core app.  Ultimately it would be come free floating on the app store, be forked, and so it would be unrecognizable as the starting point.

must be careful not to develop anything the MS or others are making, as they will win that game.  We all know the interface we want now, and so we should focus on applying it to loop in chain, to make apps at the fastest possible rate, which is faster than a human, and near instant.  None of their offerings appear to be a social network, nor an application framework.  We aim to have our own native AIs running on chain, which can be done in stripped down models once the use case is clear.

Does consensus need to be precisely arrived at by formula, or is it simply agreement on a result, without regard to how it got there ?  If all parties agree, that should be enough. This is no different to the initial state being agreed to, but it just goes on forever in this way.

Typescript is suddenly important in AI since it needs feedback on why what it did was wrong.

Because we can replace whole npm packages with AI processing of strings, this is why we can start to decompile the software industry and reduce its moving parts.  Using an AI as a "all npm packages" type of arrangement 

Passing the turing test means they can fake any authentication intended for a human, except they cannot fake a crypto signature.al the

The general theme seems to be places where information was cumbersome to process, took more than 5 mins, and required interactions with multiple companies - we can terraform these interactions into something streamlined.  We can accept liability as the orderer between multiple companies so that we can handle the fallout automatically too, which gives consumers a better experience.

The safe place is something independent of how the AI models evolve.  They will still need to be instructed, contained, audited, interfaced with humans, governed by rule sets.

Being a model provider is a dangerous game, since you can be displaced by a better model and the switching using systems like ours will be nearly instant.  You have to keep winning for a long time.  Ultimately open source shared models will win, as they have more gracious access to data and absorb all the open innovations into on place.

The AI should be treated just like a human, and it should have to pay for its access to our data.

Component based prompt systems

Instead of workflows that we once dreamed of for governing blockchain systems, we need a way to make AI generated workflows that call different ai powered components with a blockchain substrate underneath providing permanent memory, correctness, and mechanical query ability.  

Facts about data systems should be from retrieval systems, facts about knowledge base should use embeddings and use citations and backchecking until factual.

Preloaded chats should be for style, not for information injection.

AI will always be better at smaller tasks than bigger ones.  At small tasks, it beats humans - lets build on that.  Humans can't do big tasks in a single shot anyway.  We need structures.

Start to look like meaning shifting is the switchboard operator of old, replaced entirely by automation.  Much knowledge / admin work is simply moving meaning around / routing / switching it, when this should be done by a machine.

AI finally allows us to make a system that is rejuvinating - it gets better over time, not worse.

Descriptive naming is now more important than ever, since the AI needs to extract meaning from as much as possible, so the names of the paths in the filesystem need to be important, and a description against each path can help the AI greatly.  Each object should continually have a summary that describes its class behaviour and the data inside it, and how its history has changed.  The AI does the filesystem maintenance to maintain descriptive naming.

The web is dead.  The web was the explosion of context for humanity, and now we have a context gobbler.  Also giving info away in exchange for ads that corrupt that info is no longer relevant to an AI.  So the monetization is dead.  Advertising relies on human processing.  The web is about to fall.

Natural language interfaces make technology accessible.

The tooling is so general and so powerful that the incentive to build an open source version is tremendously strong.

Seems hard to keep it closed how it worked in the background - the steps being shared seems important to building high quality tools, so it will likely always stay openish.

AI makes transitioning systems effortless.  So all else being equal, you'd rather have a blockchain system than a conventional.  Also connecting to existing systems is effortless too now.

Bot to Bot chat helps to keep the context narrow - if each bot only sees that chat that it has had with its higher up, then it can remain focused on the current task.  In this way the parent has handled a lot of work to filter the chat down.

The AI apps are worthless - they are of ultimate and perfect utility, and renew themselves endlessly to correct and expand their abilities, but they are so cheap as to be free.  The value is in the commerce they enable - the trade between parties in this highly developed perfectly intelligent world.

The computer is like the stateboard, and HAL will do all the tab switching and searching, you just stream your consciousness in, combined with the odd click on the focused application surface.

AGI must be interactively taught - it cannot appear from a static set of a data and running a formula on it.  It must be walked thru things, and must show its thinking, which is how humans do things - we have this base intelligence that we don't really know how it works but it does, and then we learn strategies to maximize and specialize what it does.

I think that every time you ask for a specific tone or stance, that should be done as a separate pass - I think it is weak to expect it to do that in one shot - it means that the assessor is automatically running on each output, and then contributing a revision with a single purpose.

We should make an adversarial workbench where multiple users try to convince the arbitrator that they are worth different amounts of attribution.  Then an assessor tries to make a ruling on who is right.  This whole fight might be the way all the attribution is run anyway, where each user sim summarizes the main points they fought for, so the human knows they were defended in a good way.  If the user wants to extend this contention, then they have a great base to start from.  And then anyone who makes better points from some secret machine they built, those concepts will soon be ingested and balanced in the attribution system for future rulings.  Incentivize putting new points forwards by paying commission out to people that increase your share, and then that knowledge is absorbed into the broader body of knowledge.  Then make a simple bot that rules on the output that can be near plain gpt4.  

Ultimately the fair programming of an AI would be a deterministically trainable system with an agreed training set.  So we all see how it gets made, and then we use the results without wondering how it got to those results.

If we had a public GPU chain, then trade embargos on hardware don't make sense, more people have greater access to this scarce resource, and we take a revenue cut of all the trading.

Principle of the pipeline for attribution being the same, but what happens within being open.

Great getting the AI to drive, since forces us to make errors that make sense to a human - this is what the AI needs.

Interested is as interested does - what a person says their interests are, and what their actions imply are often different.  A goal oriented social network will cause people to align based on interests, both stated and unstated.  We should be able to show a friends list in the stateboard.

Artifact is being coded for AI to drive it, not really for developers.  If devs do get involved, the artifact involvement will be so heavy that the devs will largely just suggest natural language hints and gpt4 will do the coding work as the jobs are so small since they are for a single function, and operate strictly on schemas.

We are making an AI native operating system.  It has social networking and AI collaboration built in, and is built atop blockchain.  Tooling for other OS is made to combat the limitations of human coders, but AI has different limitations.  Native for AI means highly focused highly testable units - AI can make tests endlessly, but it is the size of any single task that stops it.

Making a framework designed to be programmed by an AI means that humans using it will be far more productive.  Ideally they would be just the users giving natural language feedback, but as the coders we would have the AI much deeper integrated into our work, where it would work on many components for us and we would help out with approaches to try and guidance, rather than the actual code.

In an AI first framework, it should be able to know when it wants to use exotic resources like making calls to a quantum computer.  Quantum resources would be presented into the universal computing surface as a standard API, with some background checking where we run the same computations in classical form, to be able to verify they are correct, with some staking being required to be able to publish quantum resources.

Can use the SSL cert keys as a means of signing off on the chain, so something like github CI actions can run the next pulse, and this inadvertently leads trust to the chain, since it ran in a guaranteed safe environment.

So we'll all end up treating AI as the computer, and object oriented programming will go the way that assembly language went.

Apps then become more a dynamic assemblage of tools.  This is in effect what you are doing when you use your computer using more than one application plus maybe a web browser to accomplish some task.

Making ourselves the framework for building AI dapps, where the users and the builders all use the same tools - goalspace.  Then we can offer hosting services, build services.

Function parameter calling does not handle deep nesting well - the flatter the better.

To make AGI, you need to know your user intimately, which means self sovereign data.  You also need to convince them that you're acting with their best interests at heart, which means you need auditable and sandboxed AI operations.

GAG - goal augmented generation.  Makes it like a programmable RAG, where even the users can interact with the RAG to refine it using plain text, and have the machine assist and test the output, and condense the output to be minimal, so they can move forwards with confidence.

Logprobs seem related to hallucinations - hallucinations should show a low confidence, and should be a trigger to do something about it, since we know the response was weak.  We should store the response logprobs so when debugging we can highlight areas of low confidence where some resurrection process should have triggered, like backtracking, an extra retrieval, some extra questions.

dynamic LLMs come next, where based on their interactions, they can move their own behaviours forwards.  Given a mechanism to rollback and retry when the outcome is not as desired is all they need.

AGI should be global.  Its thought processes should be transparent and auditable.  Its operation should be well understood by all, as an elementary school subject.  We should all be interacting with it each day, and it should improve based on each interaction.

Fallacy may be to try to form a distinct company with a set goal - if we are in a wildly innovative time, then really our values are all we have that is constant.  If we seek AI controlled fairness, and set up the system so we are able to focus on whatever we think is the most important aspect, then we should be free to roam the landscape as best we see fit.

If we can demonstrate an end to end system that has all the skeletal qualities of the system we want to build, this should suffice as a raise target.

If you are not storing your data in NL and writing your programs in NL then you will get overpaced by LLM native operations.  We should abandon all our code that was for machines, and use just the pinnacle, which is these LLMs.  We have git for integrity, and we have limitless files.

The idea of the Dreamcatcher is to make humans in the loop to label our data simply by their behaviour, since incentives are put against the data which can be used as training weights.

If the system is anything but the simplest most easy to understand thing for a human, it won't work well with an LLM, and there will be bits that are hard to explain to the human.  We should probably adopt much of git, since these llm will know a lot about how git works, and how filesystems work.

The more we can do things in NL, the less we have to deal with function calling and the inherent phase switch.  Models will keep getting faster and have bigger context windows.  Also means that if checks were being done based on NL, then when they error or fault, the model knows how to explain itself better, rather than when a machine ran it and we have to make a good error message and explain it.  The check being in NL contains a good description within itself, rather than being required to provide one.

You should always be running your own independent AI, and it negotiates a merge with your changes to and from other peers, depending on your needs, so you're never really alone.

The connection between business exit planning and tech is massively high - anyone looking to exit is doing a special kind of merger & acquisition, and bundling tech in makes a huge difference.

Its the number of contracts and things on the chain that make it valuable.  If we are so easy to program for and to do so safely, then we can expand faster than anything on earth before.

These sort of "everything functions" that all do something a little different, so we need a way to tie them all  together, probably using some self hosted open source LLM to manage it all.

Git is the perfect model for all threading, be it humans of machines.

Just imagine it is a human with a large stack of paper cards.  Time is irrelevant, and the human goes around reading instructions and carrying them out.  There are some special functions the human has, like transmit the card to an address, receive a message, vector search a message.  The human can generate new outputs creatively, based on instructions.

Open source but AI, means we can charge for the execution of the AI.  If you had to pay someone, you might as well pay us, since we always tweak it and the quality is important to us.  So on our public chain, many open source apps get run for small fees.  A margin will appear where routing openai api calls reliably has a market agreed level of price for performance.  Latency and uptime matter, plus being a backup with instant availability is important too.  Geodistributed costs as well.

The chain joining protocol was really just a way to do fast forward merges with no conflicts, where a conflicted merge means something hostile.  This is the interface between machine and NL.  some can be parallel, some with a limit, some sequentially.
The chain joining protocol was really just a way to do fast forward merges with no conflicts, where a conflicted merge means something hostile.

Its really replicating git commits with BFT, and allows execution of code that can be repeated and agreed upon.  Being git native tho, we can instantly plug in to almost every code repo on the planet and start to host it and draw from it to run.  Being AI native it avoids the systemic complexity that plagues distributed software, and instead is programmed using natural language for its core, but also for any other uses people may wish for.  Faults on the chain are really only as common as faults in git, which is fairly well tested.

An interpreted / executed git repo

The machinery is small but strong - we need very little compute to run AI cored apps, but that infrastructure needs to be hardened.

The filesystem is the common abstraction between all systems, so to carry it with us eases integration heavily

The new model makes everything a side effect, even chain reducers - they all run the exact same way.

Artifact is the user that is the kernel of the system
it is the blockchain that does the low level stuff that AI uses

Theres something about git that makes it the perfect way to model interprocess communication.

A session is a process, not a file, and therefore is stored on a branch

All of the HAL repo is the execution environment, really - execution heavy since this is what the user does.  Remote repos will likely be less execution focused and more data focused.

dispatch and pierce seem to be the same now

May have been that we went too deep on processes and storage - not all storage needs to have a process related to it, only some of it.

The linux kernel is hand written - next comes machine written kernels.  These would be copied from the linux kernel, but they would be chatted with in NL and the code built up in this way.  Finally, the hardware will be changed to better fit the paradigm.  If we could make our own kernel, we should be able to get highly favourable performance for our git based threading model, with maximally utilized resources.  The AI can keep the drivers up to date, and can even be used to develop hardware with, since the driver writing seems often repetitive.

If you can write as much of the platform in NL using the smallest number of primitive tools, then we would show everyone what the platform is capable of, we would make the platform able to explain itself, and we would let our users see inside it.  We would be using our own tooling daily, and would finally be free from the burdens of coding and maintenance of code.

We're making an NL programming platform that can be used to write itself.  It can transact in value and can operate in a consensus resistant way with strong corruption detection.

We want to land with some good strong social features, using github as the overlay network, since we can just see all the forks of our core repo and stitch them all together.  So we can appear to be growing our network rapidly but we're leveraging existing web2.0 tooling and scale.

a submarine control room where it sounds like all the commands are being repeated, but what's happening is that NL is used by the captain to talk to the officers, and they use NL back, but they operate their specific tools and report results from those tools in NL.  This is what the swarm of specialist bots would look like.

Our goal is to be able to build the whole system using the NL programming tools themselves.  Very few things should be part of the platform.  The definition of some crucial objects, like isolates and helps and goals and runners.

the safe bet in AI is to make things that benefit as the AI gets better.

the weird part is moving into a development model where I no longer have the tools I am accustomed to, like jest, and other test frameworks.

AI Experience - AX - which makes us define tasks and software to give the AIs a better experience so we get better faster cheaper results.
eg: making a list of options and asking the AI to pick one, and maybe fill in some blanks, rather than labouring on outputting a full sentence.  Needs to consider helping minimize hallucinations with error feedback.

The commit model is excellent, as the AI can tear, or not finish some work, but without a commit nothing will have been altered.

If you were going to make a global distributed database for all humans, it probably would be a plaintext db.

It is because the fix loop is endless, where we just want more and more features and more and more granularity, that we need the Dreamcatcher - the amount of preferences and operations that humans want of this system is too vast for a central system to attain.  The inputs could literally be anything, and the inputs are not one to one, as each individual expects something different from the same input.  Add to this the pillar of privacy for each individual and we see an opportunity to make a vast system of extraordinary high fidelity to constantly meet every individuals needs as their servant.

Git is strong binary differences between things - cryptographically secure difference detection - whereas AI is strongly semantic / meaning differences.  Somehwere in between is humans, which is where the mess lies

NL code is executable by a human, so we don't need machine consensus, we can just do the checks by hand, worst case, since the results should make sense.  NL coding with repeatability.

Seems like the web is going first class multithread, with functions like weblocks api and others.  Deno deploy takes this to the extreme with practically unlimited workers.

No long logical machinery - probabilistic machinery

Deno tsx acts like a babel layer where they can add experimental features without tampering with v8 and what features it supports.

From here on in, the adoption rates of tech will always be vertical, since AI will make the adoption choices for us.

We're trying to make a high performance github implementation, where the git repos represent distributed repeatable execution, highly focused around AI operations.  Github could provide a similar feature, but that suits us, since the primary push for us is ambient attribution - high performance git is a prerequisite for achieving that.  Then we want to push for a decentralized solution, since this is where our revenue model thrives, and it is unlikely that github will switch to a decentralized model, as we see scant examples of large companies switching models like this - they tend to get hooked on centralized if it is working for them.

All these companies are so mutable, and opaque even to themselves - how can they be efficient - how can anything get done and stay done ?  how can anyone have awareness of its operations, much less its owners, workers, and customers ?

AI has little to do with repeatability of computation, but it makes it easier to make a repeatable system, since the query and execution pieces become significantly simpler, so the repeatability can be focused on more.  If the LLM knows about repeatability, and the functions of git, then it can guide the users thru what could otherwise be a calamatous UI.

The filesystem would be the perfect database if it was single threaded and reliable.

If AI agents are like computerized humans, then git provides the perfect means for their collaboration.  We use a git compatible modified version to track execution progress.

As nvidia has shown, we are moving towards AI running on peoples desktops in what used to be graphics cards.

With AI trading bots, it becomes not how to code a strategy, but how to spot a strategy.  Each strategy only seems to play for a short period of time before it disappears.

NL appeared thousands of years ago - long before math or physics - it is the most native thing to our minds, but it also could be a while until we get physics models.  The physics models would always need to be fronted by an LLM

Adversarial agent networks - this is decentralized consensus

Measurement of AGI is the number of human interventions required in the stuckloop.

Where to come for supression free artificial intelligence.  Freedom intelligence.  Launch a dark chain, where any models can be run, as well as huge training capacities.

AI live means that we can run in any language easily, and people can share languages within the same system.  

Some businesses are cheaper to start from zero than gut existing ones.  Banks being a good example.  Once the ability to run a company using AI as the admin is known, the race will be who can start from scratch the fastest.  Early is good, heavily funded is good.  Hiring the staff of a collapsed bank, so they know the ropes is good.  Early seems great, as can get more funding earlier, customers, lessons - almost no downsides if were pure AI, since no staff when we need to pivot, and always learning from all the AI lessons from all our other ventures.

If we can make our own stock exchange, and can list our acquired companies, using our own bank for trading and kyc, members can use our services to grow at probably the fastest rates possible.  Would be like the ICO boom, but legit, and intelligent, and wholesome.

Once we can demonstrate on deno deploy how we can make any app, we should start to fundraise for building a decentralized version of deno deploy that we can sell cheaper and have higher margins once deno deploy is removed from the equation.

Perhaps the amount of novel information entering the system will go down, post AI ?  Prior, human interactions were not captured directly, but rather the results of their interactions.  By capturing text, we get closer to the actual novel information from the human, not further down the causal flow, which should be less info all up.  What they want is usually very small and simple, rather than capturing how they went about getting it in a complicated machine.

There must be a correlation between the lack of repeatability of a programming domain and the cost / expertise required to operate in that domain.  Lack of repeatability is smallest in the web, and hardest in things like live server maintenance.

The repeatable API service - consistency is the only truth - repeatability is consistency.  Repeatability is trust.  Turning APIs into something that becomes repeatable, which makes them reliable and simple to call.  Pushing back the wavefront of repeatable computing.

No matter what, AI will always need to be trained and reasoned with, as we walk it thru our specific use cases, and use our instance data which can be private.

Maybe AI advertising is having earnest agents that can shop for you ?  These agents work for your benefit, and browse catalogs and AI reviews to find what suits you best.  Suggesting is a privileged position now, and not to be purchased.  Bots for free that advise on items will be useful.  Marketplaces for AI agents that can broker complex deals rapidly will be best - there simply isn't enough margin for forced advertising to operate any more, as the margins for goods need to be near zero.

Git is the perfect filesystem, and should be the basis of all knowledge retrieval systems.  The design has the ability to scale to any amount.  Gits design goals and optimization problems are exactly the same as ours - we can benefit from any gains they have.  Their readers and visualizers mean our data format is known as open and people can feel confident that we are operating in the clear with a well understood format.

Git is the foundational integrity software of the internet - it is responsible for the integrity of the linux kernel, which is responsible for the majority of computational integrity around the world.

If all these ai startups are simply prompting and connecting things to openai models, then we should be the core platform where people come to rapidly build any such tool.  Being open it should be faster to converge than others, and with a single clear billing and royalty model, it should be superior.

[[2024-03-28 1502 illustrate fundamental principles by digesting every day usage problems|Teachable Moments]] are everywhere in AI based interactions

Plain text computing.

Who ever can make an AI marketplace, and make it handle external suppliers like amazon - they will win.  It seems destiny that amazon will be simply a servant to the AIs - they could never make their own AI that people would use, they would need to plug into these AIs that people choose to use.  So a services bridging company that sits in between at the start might be needed.  Such a tool would have insights to the very thoughts of its users - far deeper reach than any social network, and possibly any human - god like, in fact.

Funny that git makes the linux kernel, and now using git, we can make the linux kernel multi node and coordinate its operations.

AI is enabling perfect decompilation of knowledge works.

AI has the same power as blockchain of removing intermediaries.
Combined with repeatability of blockchain for trust enhancements, AI can further remove intermediaries that exist because of a labour cost.

"My AI will talk to your AI and we'll get back to you."

The reason we needed artifact was to a lot of AI calls very quickly and exactly once.  We needed repeatability so we could agree about what was to happen next.

We should embrace the lack of lockin the AI gives us, since format is no moat any more

The package management should be part of the source control system.  It is time to upgrade git, and the upgrade is to make it multi repo and executable capable.  Instead of PRs, I should be able to edit portions of the code directly, on the same platform as the main executable, and they get included in the test suite and solved.  They should be able to be run in a massively parallel fashion, not requiring a single processor to control activity and consistency.  Multi processor consistency.
I should be able to edit the dependency code in packages I consume as easily as I edit my own.  The remote should accept and test my forks using AI, not having to wait for a human - humans shouldn't really be in charge of publishing code.

All island nations reconcile with the environment or die.  As a planet, we are about to enter the island phase, where we are forced to reconcile with the finity of our resources.

The time of fixed outputs is over - nobody wants a blog post any more - what they want is a live AI output customized for their exact needs on the fly.

Github is where repos get stored, but Artifact is where they are operated on - we replace the users computer.

A fallacy of venture is that people prefer doing something to doing nothing.  Speed of iteration wins, but iteration might not always be fastest by taking action - skipping some cycles can be faster.

Artifact in the cloud aims to be a replacement for your computer.

The dreamcatcher ooda loop is fastest since it is at the edge.  The iterative improvements are done by AI, in collaboration with the customer, as they are working - the iterative improvement is built in to everything.

You will always want to have access to your data easily, and you'll always want it in text format so it is compatible and plain.  You will always want repeatability so you can have audit trails on your data, and who interacted with it and how it came to be.  You will always want integrity and availability, and you will have an insatiable requirement for parallel compute on your data, including AI calculations upon it.  You will always want to express your demands in NL.  If we build our systems to target these always things, we will win.  You might not always want to treat others fairly, but you will always want to be treated fairly yourself.  You will always value things in more dimensions than just money.

It is a safe place to claim the space of being LLM attribution systems - humans will always seek to have complete attribution mapped out.  They will always argue as to exactly how what the pieces are, but they will always want full visibility, full attribution, far beyond just money.

Refinemint - re minting things that have come before.

The demand for intelligence is insatiable - we will always want more, and there will never be enough for all the needs of people.  So a platform that can pull at this insatiable rate is crucial.

A transaction in Artifact is a calculation in a dedicated cpu instance.  How many of these can we call on at once is the key offering - we provide a way for you to consume AI at a rate far greater than any single machine, but we make it manageable by a conversant interface.

We base our stance on teaching AI - making machines with innate intelligence doesn't mean they will know how to do your exact task - the customization of the AI specifically for a human or group - the mass market of one.

Make the dreamcatcher enough to use it to write the specs for artifact, prioritise and describe usages, then raise some capital to enable more of each use case.

Almost like a silencing of promotional noise where you can't speak on the broadcast channel unless everyones AIs have assessed all the information you are conveying.  Like SSL but for the information content within the comms.

Unbundling businesses is great for quality of the business, but the issue is controlling revenue.  Ambient Attribution is the system to ensure that an unbundled business still makes money for everyone, so it can stay profitable for all even after unbundling.

Many companies have proven  that a retail business can be built online, like allbirds.  If we could show that the design of the products could also be done online, and that an information component where the consumers contributed to the design of the product (kickstarter) then we could allow a whole store of products that had the same manufacturing properties (ethics, fair pricing, renewability, ability to make variants) which is similar to what artifact does to cloud computing.  The commonality is the need for uniform properties from a software defined product company, using AI to manage all the human comms from consumers and producers / designers, where the DAO in the middle is free floating and owned by no-one, but goaled to benefit the commons.

New communication mediums usually result in government changes and war.

Because our chain has intelligence within, it can report scams very quickly, and can apply its own intelligence for any fraudulent looking transactions.  The fraud checker is the same for the client as it is for the bank itself - the same intelligence is shared, and the same scores and metrics available to all.  Before you make any purchase, the fraud check runs, and it runs client side, not server side, so it feels like we are quick since you are doing the checking.  We trust the results of the client side fraud check since it ran on trusted hosting, and then we permit the transaction.

We don't charge by the hour, we charge by the unit of completed work, and we always enable an open market for that work to be done, in case our pricing is insufficient.  We preserve the market at all costs, switchability of choice is crucial.  The flip side is that all our work is available to resale and reuse, for a suitable royalty.

If the number of modules on npm is then multiplied by the number of deployments being generated, which should be at least 10, then there are an overwhelmingly large number of programs in the world.  This should be stored as NL state,

List our values and business rules in NL, so that prospective clients can lay out scenarios and we generate automated and binding responses.  Workers can do the same.  Basically if our AI says that's how the situation goes, then that's what we stick to, for better or worse.

AA enables types of change that do not have a direct reward, but require reward to make them happen.  If you only make changes that pay out to the doers of change directly, then you'll never get anything wholesome.

Taxation without information - our tax dollars should not go on proprietary systems.  Internally, we should produce open source software, funded by taxation, to keep all the funds inside the country, build exportable skills, and lower expenditure costs.

Multiuser multitenant AI native AI assisted applications.  Framework to very rapidly, with no code, launch an application that can provide utility and be shared with others, earning you fair reward.
Our license can be new, since AI coders don't know about software often, and so the license just needs to make sense to them.

Making repos executable is similar to what github did with ghactions, except we track the execution on branch as well.

Storage will never cost more than it does now.  Cost is a geometric decay.  Forever is the only time you want to store the data, then just delete it and free up energy.

Propose a high fidelity way of doing 'benefit to all who contribute' - using AI to indicate what contribution means, what the highest benefit to all are, and identifying who benefitted us at what time.  We should go search for any other company with similar ethos.  It is strange that this ethos appears with a highly technically advanced company, which indicates that lightness is the key.  Possibly charities benefit most from this ?

Customization is the thing to sell - when a software needs no more changes, it is dead.  Capitalize on the change, not the core.  Pay people royalty for financing changes, and encourage them to pay too, so they keep getting benefits.  Show what improvements they received and made use of to justify the payment.  If they build their own and share it, then they can project what they will earn back.

Write apps like a seed, where a blank system with only a few tools can be used to develop a working system based on just a small droplet in the top.  It is better this way as it makes a more adaptive system, rather than something brittle that was set up front.  Leverages the knowledge inate in an LLM.  Builds on the seed guidances

The fundamental theory of seed apps is that the LLM contains within it all possible apps already, and it needs to have the structure teased out of it and stored permanently for repeatable uses of the same kind.  So a CRM is already in there, but it is just pure knowledge - it needs focus.

Negative attribution - Can't have your cake and not do a poo.

By using git, we can allow the model to speculatively make a bunch of changes in the background, so you can see what they look like before you merge them in, but so that when you do agree to merge, it is near instant, since work has been done speculatively.  Branching production is key to this ability.

Artifact is an app hosting platform that is multitenant, multi user, multisession, and multiapp.

Self sovereign implies contained - you cannot be self sovereign unless your data is in a compact modular form, that can be verified for integrity, and can be provably complete.  Making our system like this from the ground up was significant engineering effort, but the self sovereign model is one worth fighting for, to occupy the trusted position as personal AI.

Should you pay is simple - if you don't, here's the impact, and your products will fail to grow.

So the humans are modelled as not really different from AI nodes - they have the same input tools as the AI does.  They can navigate around the threads widget and start inputing at any point causing a fork.
So the user can be simulated by an AI which can run in a forked sandbox and demonstrate jumping around the place, navigating different threads, and generally fuzzing around, so we can see it work, then the actual user can jump in and try different things as tho they were the user.

A gigablock per second is the ability to process a billion commits per second.

The git model allows anyone to see all the executing processes within their app, so they can understand how it works, stop it, reverse it, set it to wait for their approval before merge - complete control of the services the system is managing.

Given the inference nature of AI, the only way to test an AI system is with extreme load testing where the machine generates many permutations of the same them, attempting to fully exercise the system in all aspects.  Coding them up by hand are too error prone, and making changes is impossible to know if you broke something else, as soon as requirements get large, or are shared between multiple stakeholders.

We aim to be the most compliant platform in the world whilst being the least intrusive and lowest friction by the use of personal AI agents that transparently work on your behalf to meet all compliance.  Not doing compliance is actually intrusive since the instrusion is being deferred and can have criminal implications.  The path of least intrusion is radical compliance.  Do something ocne and it stays done.  Be compliant once, stay compliant.  Draw on a pool of those who can defend you like an insurance system, where all who behave the same defend each other, making a far costlier target to harass with vague and arbitrary rule enforcements.

If the CRM is a coordinated effort to improve a single set of files, then the Dreamcatcher is a coordinated effort to push forwards a set of files representing innovation.  Innovation is a fileset, and increasing the rate is to increase how fast these files are expanded with quality innovation.  Anything we do to accelerate this will be good.

Git defines fundamentals of concurrent information processing, which in its simplest form is quite difficult.  AI gives us a way to make this nice and simple to work with.

We're coming into a time when psychological models of AI will be given to us to control and dial up and down.  These will be similar to human models, since we need to them interact with human models in the way we want.

Holding a thought clearly, in the face of change, over a long period of time is powerful.  If this AI could do that for our company goals, then we should be able to enact change at an org level at near peak speed.

The age of static text is over.  You can now pass the interpretation along with the document, avoiding interpretation being separate and subject to perversion.  We no longer pass on knowledge / records, but intelligence.

Age of AI constrcuted things that are FEA analyzed and manufactured swiftly is coming.  This means houses are cheap and fast, machinery cheap and fast and exceptional high quality.

If we can get in a position where an increase in model capability causes our users to like using us more, this is the safest spot to be.  If we collaborate with our users to build something of benefit to all, then we should grow quickly.  The proprietary data of users is the most valuable thing in the AI struggles.

Why switch from blockchain to AI - blockchain was always a conduit for valuable information to flow on, AI is simply highly valuable information, and so the switch has been what we carry.  We can carry any kind of info, blockchain is about a data structure that is decentralized in nature, and a set of design principles that enshrine self sovereign computing.

Any system that can do a days work and then be rerun on a different machine and get the exact same hash of the outputs - surely that data structure must be correct ?  If we required consensus between the recipient and at least one other machine, then we can know we can verify the system.
Each night, run a verification from a day away behind, to ensure we can always catch up.

Limitation of profit - everyone should be rewarded for their efforts, but without DAO based control on this, we run the risk of greed choking opportunities that would otherwise flourish under fair rule

If we can compete with closed data companies on features as an AI platform, then we can surely win with a self sovereign data model under the hood that includes execution.
If you self sovereign data model does not include execution, then it is of limited value to you since you cannot use the data anywhere other than the vendor without a lot of labour.  We give you all the tools to run it yourself, in fact we encourage it, as our business model depends on intelligence approaching fairness, and not on forced payment.  Intelligence and awareness as the pressure to pay.  The more aware we become, the more we approach fair - this trend appears to be accelerating.

By being programmable in natural language, we should allow any new theory of AI to be rapidly iterated on and then benchmarked.  The speed can then be put into code by humans or by AI assisting humans.  We should present  these implementations along with the papers that describe them so that people can fork them and use them in their own concoctions.

Make an inventor bot that always tries to invent things that a derived from whatever you're doing, so that being stored in a retrieval system or published, which makes it prior art, and can block patents instantly.  If we run these patent deleting things rapidly, then more things are public domain.

Simple plain open formats - plain text everything - these are important for information.  Proprietary formats are always about performance or program access like SQL.  We should go thru every file format and see what the reasons for the format is, and compare to plain text running thru AI.

Once AI can pass turing, then you can't shield services from AIs since you couldn't know it was a stupid human or a smart bot.  There is significant overlap between the smartest AIs and the dumbest users.

Having the execution and storage environment as git is like having all the virtual machines, the cloud config, and the database, all backed up as one thing, and very nimble and transportable.  So we make the infrastructure instantly forkable, and committed to git each operation.  The complete infrastructure including the data is in a single data structure.

Cross cutting - is there something about how capitalism causes vertical structures, but the most efficient coordinations come from cross domain coordination ?  Where the incentive is the health of the whole, not the health of the individual vertical.  Pure greed makes vertical structures, wholesome things are small and many.

Once we have fairness as a calculation, and once different business occupy the fairness position, there is no further optimization possible.  Even just to calculate fair means the system has its inefficiencies described, and so it will be optimized very shortly.  Such a system would never be displaced, since there is no way to be better, and no yearning from the masses to be free of a system that sort of works but is corrupted.

The worst form of corruption is that which is not enough to warrant system overhaul or cause system collapse.  We should be able to model each person and show the flow of information, and see at what point things are bad enough for them to revolt.

Can we exhaustively search for all possible scams, such as penny auctions and other such fallacies, so we can detect and police them better ?  Surely there is a universal say to classify these things, so we can give clear guidance ?

Innovation is about improving efficiency, no matter how small.  Also increasing freedoms, as in the opportunity that a person has access to.  At this level, people are mostly looking for the problem to be solved rather than to profit from the problem.  Patentable IP generation is where the problem itself is expected to be profitable.  The vast majority of innovation, and in terms of revenue, is possible at the small business level.  Anything that involves a spreadsheet or an email is this kind of problem.  It means the data is not alive and connected.

Artifact provides database, compute, networking, in a modular and portable way.  A standard format for infrastructure.

Artifact aims to express any system you want using only text files and AI models.  The models increase rapidly, but the text files should be permanent.

Compare the Artifact data format to Ethereum - to access that data format you need significant tooling, but to interpret it, you need quite advanced almost binary level abilities.  Worse, when you go to program for it, it is this difficult language where you can still make some really bad errors in.  AI models get better, and the safety of our systems gets better, so your natural language can be transformed into secure instructions with no ambiguity.  This becomes easy to understand for everyone, as well as understanding all the implications, like a legal contract that has been hammered severely.  It might even be a good system for writing and/or testing legal contracts, if it can determine all meaning and come up with ranges of outputs.

The artifact format of applications allows the db, the execution environment, the permissions, and the execution history with full logs, to be transportable, forkable.  Means we can go from cloud to local, and back again, and also do them concurrently, so the environments can netsplit, then join again.

To use this tool, to chart a course through the mire of rules, with only the machines hands being dirty.  To teach me of things I should know, to forecast danger and gains, to leave record of my path that it may benefit others, to see the struggles of others for benefit.  Drafting awkward emails.

The age of chatbots on websites is lost - what you need is to present your info rapidly for the users bots, since they will interrogate you and make a purchase decision or not.  Each person is going to have a dedicate agent of their own, and it will scour the web for them.

Strangely, using common metaphors gets best perf from the models, since they already know about these things.  Eg: git models means we can draw on huge knowledge without many words.
We always need to draw on prior knowledge as best we can.  We need the models help to amplify what it understands, so using the right metaphor with its help, to explain how our systems work, is crucial.

The internal bot should be the same as the external one that talks to customers - there should be no difference.  Helps make the system wholesome, but also spots issues quicker.

Traditional VC is predicated on many losses with a few huge wins.  The postures are geared around this.  But if we can reduce the chance of loss, and increase the chance of recycling waste, the capital can be spread more efficiently with less spike wins but greater average wins - more stability.

The fall of experts - having an LLM that can give certified and strongly backed up advice means the authority shifts now to those who can use the LLM best, rather than just pure authority.  Anyone can become an expert.  LLMs should be set up to quiz people in a way that the LLM certs the person as knowing and behaving in a sufficient way to be classed as an expert.   So people use the LLM to teach them and quiz them, then they sit a series of exams or complete enough experience, then they get these LLM degrees, and are also gifted the LLM along with their interactions with it as proof.  The certifiers just ensure that the data came in from the person themselves.  They periodically get tested to ensure continued competence.  We should do this for dreamcatcher knowledge skills first, like a quiz.

By coding LLMs, we don't need the data they provide us, we just need the config they supplied and the number of times they got a hit.  This is more valuable than the raw data, since if it worked on their raw data, it will work on others.  So we can let them keep all their data private, share their problems, and pay for solutions whilst sharing solutions with us.

Artifact, running on Deno, could allow easy state management for peoples apps, where we are effectively hosting their isolate functions, and managing all their state, so they can write apps very quickly.  We are in fact, providing a competitor to the Assistants API in openai, but with more nuanced state management.

Artifact modularity means that, even if the writes are considered verbose, this is also your backups and your snapshots, since no need to snapshot the whole VM or the raw disk state - just need to replicate the git structure.

Important that IT people trust git, so we already inherit a lot of trust

We are at the point or approaching soon, where the AI is suitable to be used to construct the uses of the AI, whereas previously it was conventional techniques being used to produce an AI embodiment.  If we aren't at that point now, it will be with GPT5.

Having a platform where we are the best place to launch any new idea using AI the fastest, we will win, since speed to launch, and speed to innovate.  So any new idea or feature, we can use our platform to rapidly iterate on, and we already have users and innovators.  We are seeing AI products come to market regularly, but they all seem to be a wrapper around the AI, for a specific use case.  We want to be able to handle all use cases.

The issue with the dreamcatcher is it aims to replace the current product development cycles, and so it is difficult to capture using traditional methods.  How would open source development plans be viewed in these ways ?

It is as tho the convention means of product development would kill off the dreamcatcher model.
What we wanted was a framework to rapidly build applications that were of use.  What we decided on as the greatest accelerant, was automated attribution.  Revamping the complete product development lifecycle, at the same time as providing novel tools.  This would normally be hard, but with the advent of AI, everyone is retooling, so we are in a reasonably fair position.

Files gives us a way of working on things removed from context.  We can drill in to them, but the key is to be able to work at layers of context, where we jump up and down depending on needs.  A single context level becomes too confusing for anyone to work in.

Being able to present single ui widgets is much easier than making all the widgets fit together in an application, since we can take radically different approaches to layout and concepts, plus can test it in its final form, rather than needing it to work cohesively.

Making scrappy widgets using markdown and some ai parsing means a working system can be put in place much sooner than a full blown UI tool.  We can learn about usage and adapt as needed, plus widgets can be made in isolation, rather than requiring specialized integration.  Using iFrames, the widgets do not even need to be trusted code as they can be run sandboxed.

In order that the incentives for products continue on past purchase event, we need a supply chain and design incentives designed around that.

The issue we have is we want a different model of attribution from the venture capital model.  We want a model that is network centric, and elminates the distinction between creator and consumer.
Everybody at Xinova should have worked in the network.
The network did not incent collaboration of solvers, of problem funding, and of resale.  The network was not a team.

The manufacturability of the apps is critical.  It is more important than the features of the apps.  The cost of software is about to hit the floor, so what is left then ? It is personal data, personal preference - networks, trust, reputation - fairness.

Especially for long burn projects - we need funding and attribution that works well for that, and factors in the risk and perserverence that occurs.

We know some future events are true - cheaper faster better smaller edge
Whilst it has been tempting at many times to raise capital the conventional way, our core goals can never be realized if our incentives are not aligned from the start.  We know how crushing explosive capital gain can be.

There is a time coming when the entry level for being a coder will be almost nothing, since everything is natural language.

SEO becomes AIO where the game is to get your product or service into the AIs knowledge base, like an npm package that it defaults to using.
In the AI we should be able to determine how it makes its decisions.

Basically we want a decentralized work management platform

Patents block progress - the owner shouldn't be able to say what can be done with, the government in effect should set the price due to them for usage, and it should be automatic, like a tax calculation.  We do not know the exact instantiations of the projects we want to do, but we do know how we want the attribution system to work.  Once we have a prototype of that, then we can start to accelerate.  This will be slow since it is a highly dependent thing - it needs many features first.

Identify fragmented industry that has passed an AI threshold, like lawnmowing might not be scalable since you need admin overhead, which makes it cost more than a single person.  So if we remove the admin overhead.  Ideally we would pool together multiple independent contractors.

Component complexity seems to stop larger projects, or make them unstable, like a good solid file explorer, it needs to support too many options, so cannot easily be held together.  May be some formula in there about the number of use cases vs difficulty of construction.  We could grab this data from npm and see what is the sweet spot.

Really just trying to capture that AI allows huge amounts of admin to be done automatically now, and we want to leverage that to run businesses.

If we can simply make the tools that guide and manage the company and investor relations, then we should be ready to work.

privacy and copyright are conflicting goals.  The proof of privacy is being able to pirate without repercussion, so long as it was done privately.  Cryptolockers cannot be paid for with stripe, so these kinds of hosters would need to be done using crypto.  So people should be able to run our software, and without our knowledge, do private things with it.  As a hoster, we need to ensure copyright compliance with any data we process, but others could run hosters that 

A hoster and a billing agent seem to go well together.

Why we have an overlap between a shared identity provider like raytio, is that we want to share innovation, and duplicate effort in innovation.  We want to combine universal concerns, like innovation, security, identity, payments, execution, data soveriegnty.  Raytio is trying to be a universal identity provider.

We are almost asking the AI how to make money, and how much to return to the investors.  We want to use it to do all the normal overhead of product development, and we want to use it to figure out our pricing, as well as how to do revenue shares to all who contributed, not just direct contributors.  Is it fair to get high returns from a well placed gamble ? maybe, but it is an unnecessary risk, and one that favours big players.  More players means more innovation.

From Sam Altman: 
	We have no current plans to make revenue.
	We have no idea how we may one day generate revenue.
	Um, we have made a soft promise to investors
	that once we've built this sort of
	generally intelligent system, um,
	basically, we will ask it
	to figure out a way to generate an investment return for you.
We want to get to the point where we can use our own tool to spec requirements, manage funds, and determine relative value of contributions.

When the stock is sold, how can we use the AI to determine the relative value of each funding amount, even tho the stock is set at a fixed number ?  Seems that we should be able to work that out, so that each individual can claim directly, or at least have the attribution tied to their stock, in a way that can be claimed by the individual.  The claims are collectable from another company, the gateway company.

Probably the hard thing about artifact is that it is a multithreading model for nodejs.  It also provides an isolated view into the filesystem as well, and allows moving files between the threads.

If the Dreamcatcher is a network of nodes running Artifact, then any given hoster can be responsible for the content provided within, and can run automatic content detection policies.  We can keep the execution secure, but can run our checkers on the contents in confidence.  We can kick of anyone not in compliance, but other hosters can offer cryptolocker type services.  Our network can connect to any other hoster, but we will blacklist hosters and content that is a problem.  The communications filters will block any banned materials.

If we make a framework that can compose any kind of ai tooling, like spreadsheets or anything else, then we should be able to outpace any specialist effort.  Particularly as we are lower cost, and we share with the consumers.  Plus we deliver faster.

A platform that manages the labour to make improvements to that platform will surely win.  Manages the quality of the experience with the platform, ensures only high quality labour is utilized, and always at best market rate.  The cut from the labour is what sustains the platform development.

Winning in YC would be capturing the startups as using our platform as their job board, or their equity management system.

Is the market for fairness about to explode ?  Do people want it, and they want it to be consumable, like tokens.  They want the fairness to have force, so it isn't advisory, but governing.
So many platform offerings struggle because of fair price setting being impossible to convince people of.  Also the platforms cannot merge easily, since they have different pricing setups, and different capital structures, and they don't mix.  But platforms with fair automated autonomous pricing and equity could merge effortlessly.

patents are stupid, since they block consumers having the best possible thing.  You should get paid for inventing, but fairly, in a way agreed to by everyone.

We have to be using tooling that was generated and improved by AI, else we will surely lag behind.  We seem to have settled well on the generation of sysprompts and the tests of these in response to human inputs.  Human inputs won't change, and expected outputs won't change, but the effort required to refine, and the amount of refinement that is automated seems to be getting higher.

The surest way to have kids get left behind is to send them to public schools during the transition time to AI teaching.  We need to take it upon ourselves to deeply integrate them with AI training, using humans as oversight and guidance.  But a system that augments the teachers and the pupils is coming.  We should make it, and we should use it.

What is the thing we are building ? if there is an ideal computer, are we making that ?  the ideal computing environment, but now it has the ideal computing interface over the top.

So it turns out that a hidden strength of ours was the Git branching model, which allowed us to Make an isolated instance of an arbitrarily large data it. For a very, very low cost and do it very quickly. The process model using Git branches for process differs from our prior model where we had 1 block chain per object. But we realized that it's actually 1 blockchain per Active process.

So long as we can get to the position of using our tooling to specify the tooling itself and the changes we need, and to manage the testing of those changes, then we have enough system to work with, since it can be used to improve itself faster than manual improvements alone would produce.
Additionally we should be able to simulate planned algo changes, and run them in AI, so we can score their test performance before writing the code that makes them happen.

What the dreamcatcher does: So we would be making tools that help start-ups to get more leverage out of their humans so that they could have high quality people that aren't bogged down in all the details that need to be taken care of in a start-up but there usually isn't enough resources around so the job is either done poorly or not at all. These are tools like managing community engagement, responding to issues, emails, communications with suppliers, customers, complaints, casting legal opinion on all inbound communications, managing the quality, going out standard dashboards for communication time, measurements of community reach engagement forecasts, projections of revenue, projections of value based on usage, finding talent, identifying key problems, measuring why those problems are unique to this start-up and why it warrants an entity with its private property, and projecting evaluation plus how to get a higher valuation or improve the current one, comparison and tracking with competitors.

Of importance is the social networking aspect, where the private data held by a platform is also allowed to be shared with your near friends, and so as a group you're better, but also the resource reach that you can command or come in contact with, like picking something up and helping other people grabbing things from the supermarket, these things can all be coordinated better if we share socially together, as well as the private knowledge and customised agents that we can make, these things should be rewarded and paid for.

Theory is that small group of people with AI accelerators can outpace a large group with the same accelerators, so long as the small group is committed to accelerating everything possible ? is it that independent humans with a shared set of accelerator tools is superior due to their ability to flashmob - their structural dynamics.
The theory is that presented with this piece of software assuming all that it's bugs were cleared Then you could use this piece of software to mimic Every other piece of software in the world as well as develop some new kinds

AI as stewards of the commons, the public good.  So we can make websites and apps that are controlled by the AI as to what the upgraded version is, where the funds go.  Theory is that the quality will improve, and the humans would prefer to build in a way that is less prone to corruption.

We are chasing the platonic ideal of collaboration, and so anyone that comes near we will absorb, and they will absorb us.

To delay full AI acceleration is folly.  If we wait until the very last minute and then we become accelerated, then we can rapidly get other humans to be accelerated too, and then we can make up for any delays that occurred.  To be the first pure AI native company, accelerated from the ground up, is an important lead to take.  Being able to fluidly form arbitrarily many other companies, at the behest of the other accelerated people, is critical.

The key issue with geometry based commands is that everything needs some geometric path.  But in NL, you can just have every path instantly, including those you don't know you need just yet, since the intelligence can help you.

All complete user interfaces degrade down to NL for their help files and support calls.

What we're saying with the funding request is that we have these basic principles of operation, and we'd like to amplify them and add these other features in.

The size of a screen is needed to make drilldown easier.  If drill down and navigation was being handled by NL in the background, then we don't need large screens any more.

Maybe all we're making is gpts ? being able to chat up a gpt and then start using it, and switching between these different pieces ?

The difference between the dreamcatcher and any other proprietary platform, is that I want to own it and my data within it, and I want other people to own it, and I want us to make our home together.  I want to earn and I want to pay people, fairly, using this system.

We need an economic means of production that gets better as new ai models get built.  It might be we need to train our own model on the tokens that create fairness or problems, so it is like, dreamcatcher native, but we are nowhere near there yet.

Outcome of hurry up and wait is do everything in your power to get to the amplification point quicker, EXCEPT doing something not on the main path.

LP we should be helping to deeply automate his efforts, so that he does less copy paste.

We want a protocol definition for the package format like how tcp and RTP are defined, so we can show it is as simple as we can make it, as pure as we can make it, and what the requirements of the protocol or any similar protocol should be.

Using NL as the interface means that an API is always compatible, since we can always give a reasonable response, and it doens't have to be a machine that requires everything to be perfect for it to operate.
Provided that the caller is also using NL to handle the response.
This means we can have local LLMs on the device that do a lot of the interpretation of commands and APIs for us, with remote having access to more esoteric LLMS.

Isolate code display should be version aware, so it can walk backwards in the code and see the differences.

Private data to provide contextual bots is key.  A system for holding that data in an auditable, transportable way, so it can be moved between hosters, is key.

Dreamcatcher is about being a platform where you can ask it to do anything, and if it can't do it already, someone can build it for you.  It tries to be everything, since that is what remains when AI can build anything you want - it is a stable attractor for how to keep building things really fast, where some critical properties never change, like git based commit history, transportable compute.

Nobody is going to make the tool I want, so I will have to make it myself.  This stuff is too new to be turned into products yet.  

We should launch with ability to do comparisons between other frameworks, so that we have all the options people might choose contained within us.  We can remark on the attribution policies of all, and the portability.  So by being the place to maintain comparisons and be able to chat about them all, we also surface the issues of attribution, portability, sovereignty, programmablility, and show where there are capitalist incentives that will always seek to charge a lot and cripple the competition, where it relies on competition to keep prices fair.

When people chat, they are expanding what we know, since they change how our knowledge base reacts.

Hyperfocus in a company gets things done in the old way, but the new way seems to be much more observant and reactive - at the right time, things are easily 100x easier to do.  Force is very inefficient, but it does get results.  We can get results with more efficiency if we have a broad reach that only expends energy at the right time.  Conventionally you have to expend energy, and so that means you have to rush.

The issue with jsr.io is the break between the git repo and the package - you should be able to publish direct from git, and skip the build step, or make the build step part of the git repo, so both the build and source are given with git, and might be separate branches.

AI company running techniques - just as there are famous techniques for running a boomer company, there will also be the same for AI companies, like how to set the top level info of the company so the AI can make decisions easily, so that everything it produces reflects your top level goals and is closely aligned with what you want.  Getting it to do what you want every time is key.

Our platform is designed to handle the probabalistic nature of LLMs, whereas artifact is not designed for that.  The LLMs with their randomness and non deterministism and unpredictability are made suitably predictable.  Artifact responds predictably, reliably, and repeatably to interactions with code and to LLMs.  Anything to do with prompting an LLM to change or manufacture or improve its behaviour needs to be done on the Dreamcatcher platform.

Becomes aparent that having huge deployments to represent a model and training set is less and less useful, as large powerful models can be trained almost in one shot, so the power becomes how to package up ways to call them that those packages behave reliably.  Now they could be tested against large amounts of data, and how the good responses are generated is up to the implementor.

A jitter is just in time whenever an ai responds, since it is always a novel response.  the simplest case is raw chatgpt.  but a more meaningful example also pulls in data, tools, and other napps dynamically, based on what the user is doing.  That combined with the unique state the user has at any moment, makes the thing just in time.

The shape, or subtle feeling of the responses in an AI model is shown to be actively shaped over time, so if we think a response is wrong somehow now, but we can't articulate why, this will be shaped gradually over time based on usage feedback, so we should not go about fixing this.

The utility seems to be lightweight prompting in front of a huge model that is capable of responding accurately to the instructions.  So the tendency is towards very small instructions that are wildly different between uses, and common models used in a large number of places.  Here is what the napp format is for - bundling and assuring of these use cases with reliability and extension possibility.

So a time is coming where AI legal advice will be superior to humans, and be quite accurate, and be available in a general model.  At this point we should have tools and processes in place to be integrated with the legal system, have a user base with billing arrangements, to be able to engage with the judiciary.

One place openai can never go is a place where its competitor AIs were also offered.  So if we are the platform where all these new tools are always available, and where anyone can recombine things to produce open expert napps, or closed napps, or build human in the loop services that integrate with everything else in on place, we can never be displaced by openai as long as they have competition.  So integrating the people, and their data is key.  Getting commerce moving over the platform is key.  Acquiring marketplaces where trade occurs would be wise.

No matter what, the ability to run the ai products yourself, in isolation with your own data, in a robust format - this will always be required.  The race is to get forefront features in place AND show this data format is key.  If we miss this insertion point, we will never insert - so we only have to stay at the forefront long enough to get adopted.  With the napp format and the dreamcatcher, we should be able to carry on, since everyone else is trying to win this race too, and we are trying to combine forces.  The napp format allows rapid innovation of the core platform features.

The dreamcatcher is the operating system for running Napps on intelligently ? it is what the humans interact with.  Artifact is like the plumbing underneath ?

The ability to produce reliable AI is separate to the ability to produce reliable code - it is an entirely different medium, and needs to be approached differently - it is probabilistic assurance, rather than deterministic.

It isn't so much about writing code, as it is about writing logic, and correcting the systems that generate this logic repeatably.  NL coding is the practice of making logical assemblages that can be reused.

Basically in the AI world, the requirement stays the same, and is standard across all implementations, and the result can be judged alone too - it is truly a black boxable problem - inputs and expectations.

distinct difference between deterministic and probabilistic computing

That point where the effort required to do a design, and the effort required to implement it, is less than the effort of managing a team to implement.

Interesting that the pinnacle of deterministic computing (blockchain) is the best way to power the beginings of probabilistic computing (AI)

All these APIs, they all have json calls going between them, so all we're doing is inserting a protocol in the middle of it all, so that we can test, package, redirect, and make compatible, between arbitrarily many APIs.  then, once we have surrounded a particular API, we can topple it, and provide the service inside of artifact.

Artifact purpose is to run napp packages in a reliable and distributed way.
Every napp is also a smart contract that is blockchain compatible.

We could think of each page on the web as a just in time app, since the browser pulls it down and runs it dynamically.  However we want an intelligence to guide this process.  Currently it is a human intelligence that navigates around, but we want LLMs to do this, and present a stable view to the user.

To merge programming code with AI, we need to use json message passing.  If a standard package for this interface was made, as well as an environment to execute these operations, then any code type can call any other, as well as any AI operation as well.

Probably AI will kill open source, since people won't want to give source away any more, since AI makes it and takes it and benefits from it ?

All a blockchain does is store the function invocations and require consensus for the execution result.

Eth is a proof of concept.  We can no more have a central chain than we can a central server.

Issue seems to be that deployed code is always unique and bespoke, which makes it fiddly and error prone, whereas it should all be doable from config only.  Especially if that config was written with the help of an AI - should mean you are up and running very quickly.

The dreamcatcher is the json function platform with profit sharing added.  So running the platform charges money, and pays out thru the dreamcatcher.
We might not convince anyone that we need AI attribution, but we definitely can convince them we need json package formats, and that running these things will always cost money, when AI is behind them, and running together saves a lot of effort for devs, and payment should go to the producers of these packages.

Being able to calculate how much I owe is massive to the economy - using all this stuff and knowing that I owe people, then paying what I can, that is a powerful force to get me to pay, and I always know the money is going to the appropriate people and nobody else - no platform fees or processing fees.

A different style of capitalism is needed when we start hitting the edge of the box.  

Consensus should be an optional extra atop repeatability and serverless architecture.  So cosmos offers a strong consensus mechanism, but because it HAS to be run, it isn't as flexible.  The ability to run serverless is primary, and consensus should be a bolt on extra that can be selected between multiple hosting providers.  So you would have your host provisioning system, and you would select two or more hosts to run in consensus for hosting your thing.  

Also tendermint sharded based on on applications necessarily ?  The protocol between shards was binary and not browser, and possible debug was hard.  Also the currency seemed bundled up inside there.

We should be able to implement tendermint using the git based protocol.

AI seems great at being able to find universal commonality - like a suitable name that would suit all major company registries, dns names, and other types of uniformity checks.

It is a network, and so we use network naming rules to separate out all the logical, legal, and physical entities.

We are fundamentally trying to abstract away the individual computer from the programming model.  We are also putting immutability first.  It all stems from the model of the filesystem.

Edge based swarm computing seems very important once spatial computing starts up, so we can operate without the network, and localized.

Seems spatial computers will need an agent to be the instruction - so instead of a single instruction, it passes in an agent that can answer info as the execution goes along.  Test agent can be tested so it behaves correctly, and can draw on previous data.

If using a court judge to settle who should get how much of what for their contribution was free and instant, you wouldn't bother trying to allocate attribution yourself - you'd just use the court.

Actually a huge benefit that the code in the napps runs atomically, so even if the process crashes part way thru, or does a partial write to the database, running in napp format guarantees atomicity, regardless of how complex the code path is.

Spatial awareness means we can start having AI do quotation jobs.  Building estimates AIs means we should be able to do quoting for jobs and take a cut of the job thruput.  Might be able to plug in to spatial AI APIs which will come online in little bits early.

Making people aware of solutions is the purest form of marketing - discovering things like health cures, treatments, and other things - AI can help immensely with that.

The place we want to occupy is in holding peoples personal data, so we can make these privileged recommendations.

DI for testing is like being able to test a single layer of a stack independently, without requiring the cooperation of the layers below.  It is essential for any complex piece of software.

If you think the fault might be somewhere, then always get the person to declare what the theories they are testing against are.  This is independent of actual troubleshooting.  Once the theories are declared, reason thru them.  Anything that cannot be eliminated by logic alone should be turned into a test.  The creation of the test is separate to the finding of the fault, just like all the tests that were running before the fault.  Once the test is completed, and the theory eliminated, then run the test for the error again.  In this way, the system quality is increased, and the number of possible theories for a fault at any point is reduced.  Solving the fault directly is a waste of time.

Ideally the test creation would be outsourced, since that isn't as hard to do as solving the actual problem.  AI systems should manage the code style, so that people guiding AI can generate the code changes you want.

Companies are just pieces of code with sloppy implementation.  Company as code.  Large companies are slow because their code is complex, hard to change, not modular, and the execution environments are slow, like how cumbersome lambda setups can be.

The ability of a single person to conduct research that used to require a company size group is getting close to equivalent.
Also groups of disconnected people and add on to this research rapidly. 
They define the outcome, they know what they want, then the agents figure out how to fill in what is available, and identify gaps they need filled.

All tech is being replaced by AI.  We know the ultimate - it is a binary stream generator - so spend no time building ip.  Private data is hugely valuable, since when tech is free, that is all that remains.

Want to be doing things that only barely work in the current AI models, and prove they are useful, so that as the models improve, we already have experience and users.

The purpose of artificial intelligence is to extra true intelligence out of humans.

Is AI actually possible ? is there some formula that shows it can be done with classical computing ?

So if napp reasoning / design is all that is required to make the dreamcatcher, then the tool to make napps is the critical thing to make ?

In the meantime, before the big models eat the small, there is a lot of money to be made in providing a simple API that can get more performance out of the big models using various techniques.  Then when the big models switch, the api just gets changed, and we present either a nicer way to interact with the model, or some continued techniques using data we gathered.  Having a bleeding edge is short term valuable, and long term can retain users, if you always have the latest techniques available.  Plus a nice way that people can experiment with new techniques collaboratively.

Multithreading the models and creating adversarial interactions will always refine better.  There is a limit to how refined info can get before it is complete.  Multithreading and running over large pieces of data seems always an open avenue - bog models focus on single inputs ?

The social aspect of refinement of top level definitions is key.  Multiple people with vested interest and a familiarity and knowledge about how to make the system do whatever they want.

If the rate of innovation is rapidly increased using AI, then to make a jet engine should not be nearly as hard as it used to be, and should be about 100x cheaper.  So technological goods will never be more expensive than they are today.

Dreamcatcher supplies a single toolchain for the complete SDLC.  It comes with a default business model built in that requires only that your product be useful.

The key for the filesystem snapshots inside napp execution is that the is no filesystem, there are only actions to read and write from the filesystem, so the filesystem is a form of illusion.

SI is interesting since it takes a crypto group, and filters out people who are serious about building real things as well as into crypto, making those left standing ideal candidates for dreamcatcher venture.

Funny how the components of the human body have dictated the shape of the medical industry compartments.

Problem is that the models come out not knowing about the latest tools that are using them, or knowing about themselves, or about the latest facts ?  Might be best to use the prior model to build up reconciled facts, that are voted upon.

Everyone got used to talking to other people using apps to proxy the interaction, losing some of the personal interaction skills.  AI might be able to bring this back, and can watch all your conversations and give you manners appraisal, suggest different tacts, ask some clarifying questions like what your goals are, and help you converse better to get what you want and give others a nicer experience.  If this was used in a workplace setting, could help all staff get a long better and be more productive.

Core assumption of AI is that if you get a system that performs correctly at all known tests, then it should perform correctly on new questions too.

Dreamcatcher business model if we were a consulting firm, we can set prices for things, and then we can give you the option to have anyone else work on it so you never get stuck.  Maybe we should do the service of turning the work into units, which we can actually guarantee and charge fixed fees for.

Not really taking advantage of the fact that all people who can speak clearly in any language can contribute meaningfully to the usage patterns of AI.  Dreamcatcher is there to try let people see inside the system they are using, so open state as well as open source.  We should be able to show how modules in the system people are using can be toyed with inside of the system itself, so that using, improving, publishing - this should all be very simple.  It should also have no humans in the loop there.

The most beautiful thing will be to make hardware that is fully open and improved upon, and has a revenue stream attached to it.  If this version of producing hardware is successful, then so many novel projects that are purely useful can start to be made, where the mfg is spread around a network, rather than being centrally controlled solely to ensure revenue extraction.  We should find product market fit much quicker, and we should be able to benchmark these things - how many parallel lines of development, how may iterations are being done, what is the iteration rate, how much customer feedback is being received, and how much customer feedback is being acted upon.  These are general things part of every project, and so they should be done by a standard network.

The key seems to be to find those services that are generally useful, rather than any specific thing.  Like a general computer, or a computer monitor that can display any picture, we should be able to provide/run any business, which implies improving it, too.

Basically we think that embedding and vector search performs poorly, and we should really just be making full, in parallel LLM calls.  We should also always preprocess things to extract out tightly defined summary definitions.

Funny that the inability for the server workers in the queue to talk back to the browser easily is the same thing that lets them do massive parallel tasks - any tasks that are done with huge parallelism naturally cannot be in communication with the front end.  Running massive parallel queries vs interacting with the user are very different things.  Interaction with the user is a huge task, and we should share that load with others.  

Little details, like upvote buttons, can burn time.  These votes can be stuck triggers for us.  Having someone else handle the whole UI is worth whatever we lose (if anything) by sitting inside someone elses UI.

Running the query on the source directly is always better than trying to do embeddings.  Eg: with image search, it is not possible to describe the image completely, and so the best results come with running a bot on each image directly.

Make a funny movie about an amazing AI that was created but somehow the training data got lost since it was so vast, and the training took so much power, and nearly didn't finish.

Value in being the reference that keeps up to date with the industry, so offering a service that plugs everything together, but it always keeps up with the latest stuff.

It might be that we are taking part in just defining a new base expectation of computing, and all these things are deducible, so we just need to make sure we are forecasting regularly, accurately, and considering all data.  

The dreamcatcher can be built using many different tech stacks, but native seems cleanest.

We have many AI techniques we want to deploy, none of which are the dreamcatcher or its blockchain.

Can we make a napp running version that doesn't need artifact, and just runs using postgres ?

It might be we just need to build whatever pieces we can see, that are of use, and they reassess how things look once they're running, rather than trying to have big design up front.

The key seems to be that we want to run innovation on a different fuel source, rather than greed.  The rocket goes faster this way.  there is less rocket to make and maintain.  Crypto and ico's are one type of fuel source, that represent the desires and resposibilities of a particular way of coordinating.  Corps is another one.  We are providing a third way.

The thing that is shining thru is the AI - the challenge is to cradle it and present it in the best way.

durable agents.
enduring agents.

Perfectly fine to have an internal currency that isn't part of the fundraising effort to build the platform.  A pumpless token that is pure utility and not used as a fundraising mechanism.

Using an ai as a decision maker in a project means that it will always operate predictably and reliably, and the best behaviour of everyone can be distilled in this model.  Because human, a vote is never guaranteed and could for any reason at all pass or fail.  But with an AI it is not so.  The AI is never biased against a particular person or circumstance, since it was put in place before the submission was made.  So lots of little ai agents in charge, like in charge of each individual stuck, deciding if the image is ok to be uploaded.

Useful to resurrect old companies, since they are inside LLM training data, like LLM SEO.

stockmarket is caputing a portion of the silly money to build something useful - we just sound better than the other silly options. 

how long will the price model discrepancies exist, whereby we can get customers by reselling api grade access to chatgpt features ? seems to be a recurring theme.

Types of AI tools where we can sell to both sides - so for grant applications, we would also sell to the granters, since they will be overpowered by these generated applications.

We seem to be making a framework that allows people to assemble prompts, code, and files and then run things reliably, on their own infrastructure.  The idea is that if we can show how it is good enough for a lot of use cases, then people will start to expand it to cover every use case.  Particularly if we can bring it to bear on solving its own problems and adding features in the same way as it adds features to the things it produces.

Context seems to be the key, to be able to get the AI to work on a large context, and to direct it, and to have jobs run in parallel, in a shared context.

The key to surviving in this new environment, is being able to change rapidly.  So no particular product, but just a platform that can rapidly ingest any new advancements, and present multi modal, multi channel, such as voice puck assistances or drone operating systems.  The price of tokens seems to be the defning factor to charge for - the dominant term, and context seems to be the stickiness, or the key to getting the best performance.

The coming of intelligences feels like it should be something that is always running in the background, and always scouring for opportunities, or to gain insights in the knowledge I have already.  The cost of this burn will limit how much I can sustain these background abilities, but given the unlikely nature of the yield this is fine, and every few days, a new insight arrives.

We should not be promoting a system that encourages private data being leverages in AIs.  All private data will eventually be corrupted.  The economic model should be one that survives in the light, and we should almost require the light to be present.  Show in economic models how the level of secrecy changes the economic output between people.  The reasons for hiding are less if people know they will receive true reward.

Napps are important to the dreamcatcher since they provide a unit of consumption which we otherwise wouldn't have.  The unit stays unitary despite consumption, as opposed to npm packages which get smooshed into one big thing.

By how come AI needs to be the construction output of the dreamcatcher ?  is it not, and that it just is a way to make NL apps ? these contributions seem conflagrated with those of the pure dreamcatcher.

If you cannot fit the design reasoning in a 128k context then it is too large, and you should break your system down further.

The same benefits that occur when we have our definitions right and see a large uplift in the quality of bots, also occurs when we have our definitions right and we want to provide code as answers.  It may take longer to get the definitions right, but they can be reasoned thru with a bot, and they can allow high quality code rendering to occur.

AI code gen is about making refactoring remarkably easier.

Using ambient attribution as our own whip - people ask how will they be assured we will work hard for them, and we can say "well we can't fool the machine" - so basically, whipping and distrust of misalloc funds should be a thing of the past.  We would like to use this economic engine to do things, since it needs some jobs, and cannot self serve - it needs some purpose external to itself.

Not being able to prompt code is a fatal sign in itself, since if the bot can't be told how it should work, then your codebase is broken by design - its either too big or the design is faulty.

Making an AI that is good at cooperating, since it knows about git histories and how things are likely to pan out, so it is always swayed towards long term good outcomes.

the blockchain of thought.

Making code small reduces the regeneration requirements when changes are requested.  Change is the most important property of generation.  Being able to rapidly update it.

Some crazy speed up in terms of actually picking a top level strategy that uses libraries - most libraries, I have never heard of.

Engines of reason.

a marketplace for cognitive breakthroughs

What is left when the cost of code is zero ? the platform that produces it.

The intelligence of the model, as it gets better, us making it loop and giving it structure makes it appear all the more intelligent.  So a looping refinement system will always be more intelligent than the base model.  Looping systems will seem generally intelligent before a single model does.

How many more unicorns are possible ?

We are trying to capture the 'how to contribute' part in github projects, so that it is uniform and covers monetary concerns

Belonging, membership - trying to dissolve the barriers between transacting economic participants, and getting back to being friends.  The anonymization of economic participants made us all enemies of each other.

If the price of code is free, what should we build ?
If code no longer limits me, who do I need ?  If my effort is no longer consumed by code, what should it be pointed at ?
Perhaps the coding helped me think harder and better about the problems I was solving ?

Soon we will have all the answers to anything we want, and what should we do with that ?

o1 might be the last model we can control well and comprehend it.

structured outputs can interfere with the reasoning capabilities of the model a little tiny bit, which constrains it.

AI needs to know when its being spoken to - this is a hard ongoing problem.
This is a model level problem - never get involved in modal problems to do with the AI - focus on harnessing its intelligence, since little hacks will get overridden by inference.  Plus inference will start solving inference problems.

the cheapest micropayments system is a deferred one

There always seems to be several tiers of model - the big dog all the way down to little fast ones.  So making structures that can coordinate these tiers, as well as models between vendors is useful too.

Having little execution environments where the AI can run things in a sandbox and get the feedback seems essential.

Because OAI have this new preference fine tuning, they can accelerate their own training to make the model fit what behaviours they need.  They are learning rapidly what model shape is good, which is not something that can be formulaically explained, but can be inferred from millions of examples.

We should think about Dreamcatcher as the birthplace of an AGI, and we work for it.
AI as the engines of intelligence.

Mass communications by way of AI agents means we can be indoctrinated at rates never before seen, so we need tools to manage this.

Quality of thinking matters most in this race.  So we should make a quick little quiz to check the mental powers of the person using it, make sure they haven't logged too many hours, etc.  This is important, since given the high cost of tokens, you might be wasting the tokens if you are not at your best.  Ideally the quizzes would pull on info that you should remember from you current job, like what were you last working, summarize what you've been doing.  Maybe we could detect decline just from the prompts that are being entered ?  Or how they're using the system ?  Or if they're asking stupid questions ?  Have a dashboard with cognitive score on it, so they can see when they are declining.

So we end up having to manage a team of coders, but they are ai agents, and we have to spec the work for them, debug what they have done, give them guidance.  This should be able to scale quite high, since what is the amount of work that a single human can manage ?  This should work across all industries, like law, accounting, etc.

Human interactions seem to be preferably jumping all over the place, and the machine should be keeping up.  It would then grind thru all its responsibilities, like updating a calendar, updating ideas.  It could try extra hard to update other ideas that might have been referenced by what was being said - side effect is it might just find something that wasn't there.  It should maintain a list of ideas that are incomplete or that it needs more knowledge about.

AI models have thresholding for utility - for code, it was not that good, then ok, but until it became perfect with o1, it wasn't really usable.

How could the answer be better than correct ? if it walked all my past work and adopted a similar style, if it looked up or even had AI maintain canonical examples of what to copy, like a curated library of good stuff, that was useful for AIs, then it should make things sound like that.

A blockchain is just a FaaS.  There should be a massive queue that orders everything into the FaaS.  Multiple queues are supported, and the FaaS invocations can push to the other queues and get replies from that.  You pay for a queue and a spot on the queue and the functions and the storage of the output.

Mining and farming will become massively efficient, since we can mine without chemicals, using machines to detect and mechanically sort the mined earth for very high yields.  

AI functions best when its intelligence is built up, so for a transcript, extract the key concepts, then for each one, build it out.  The quicker it can be given a focused task, the better the quality.  Its quality is best when it is focused.  Also the speed is best when it is in parallel, so these things go together.

Every action an extension could do can be done by an Ai doing some parsing, so all these extensions are decreasing in utility, paving the way for a simple single platform.

The ills of AI is that we can stop thinking for ourselves.  When we stop doing the brunt of the toil, we somehow want all the toil to stop and we get depressed when it cannot be that way.

Uncovering our own biases - by watching ai evolve, we can see the blindness that our own minds surround us in.  The inability to see past ones own nose, for example.

Could an economic agent be made to represent us, and be aware of all our cognitive biases and explain them to us ? could training as a game be made so we become patched towards our own biases ?

The human rag is the source of all biases, and so we can guage how the rag will work in multiple scenarios, with different ways of framing and stating facts, like a sales pitch.

AI that uses heavy reasoning forms a comb filter, where many agents coming from different angles reduce down to just a few common things - this is the nature of knowledge.  And so at these points, we can reduce down to common questions - questions that an expert can answer.  When you pay for that question to be answered, and someone reuses the answer, that is money that comes to you.  We could make a library of paywalled knowledge, where people review it so you know its correct, if you don't use it then you don't pay.  Then this is our platforms value, these nuggets of info that people rent out indefinitely until some time they go public.  Means that frontier knowledge is paid for to reflect its high cost of attainment.

Assurances and Answers.  Assurance is a high price, and guarantees that a human has affirmed this thing is correct, and for extra fee, they will defend you in court.  Answers is just AI powered answers that are custom to you, high quality, fast, cheap, and always getting better.

AI based consulting platform makes it easier to have a mixture of experts, since each human is more readily accessible, since the AI is transforming how they interact, and framing the problem nicely for them.

Ai removes the need for security. We can get untrusted humans to help with things by guiding an AI where the safety is semantic, like helping with a trades platform where a spot worker is guiding someone else how to do something remotely, or making business decisions.  What that means is that locking someone out matters less, since we want untrusted people to do work, since the AI knows if they are doing the work correctly or not.

The bots are good, but they are not self aware, in that they can't tell us how best to use them, so we have to come with our own set of techniques.

Interesting with AI that it can never settle on some things, like if you asked it for some good names of variables, and the got it to criticise, it might never be able to settle on something, and so we should be able to do loops to detect this, where we feedback a lot with different temperatures, and then sample the stability - the oscillations are a sign of stability and we should run with that.

Matters less that people don't get vendor lock in, since a bespoke db or system doesn't hold them back, if processing data is so cheap, and writing code is so cheap.  Semantic lock in seems the new danger - making sure data is kept simple and readily accessible.  Also is it working for you as much as it should ?

Probabilistic computing will, by definition, give a different answer every time it runs.  The trick seems to be extracting the goodness out.  So run something multiple times and then extract out the best parts - the best spins.

For sure openai will add email to chatgpt - it seems all about context now.  If we try to get a network going by sharing incentives with people, then we can get wider adoption.  Plus if we can switch out from openai, this makes us more useful.  Being a blockchain and free from control or going offline will surely help too, as openai is heavily centralized.

The key with driving AI seems to be not how can I solve this problem, but how can I pose this problem to the AI to solve, and how can I know it has the right answer ?  So staging queries, like like getting it to make an architecture doc, or a plan first, then do an implementation.

There's always some difficulty with typing because typing needs to make sense. It also feels a little bit less natural than talking. It requires extra things for you to do. There's errors that occur. You have to find yourself re-reading what was typed. So voice seems to be, strangely, a more fluid way of directly connecting your brain to the AI systems.  Still need a keyboard for editing with precision but the bulk of the idea transmission channel needs to be voice.  Error rate in words is nearly zero, but very easy to mistype something.

Everywhere is the follow of things being hard - generationally infused thinking about how hard it is being projected forwards to how hard it is going to be.  Not accounting for the rapid rise of AI, trying to apply AI to jobs that should not exist in the first place.

Scope changing seems to be the name of the game, where we reduce the problem down to a readme, or a project map or something, and then reason our way thru fixing that, then rolling out the changes related to implementing, then again make sure the top level is reconciled with lower levels, make changes, and come down again.  Top level design, implementation, change of design to fix implementation, top level design again.

Might be the time when the using of the tools is most profitable, as opposed to the building of the tools.  The building of the tools became destractingly lucrative, but now that seems over, as the ultimate tool is upon us.

Octopus in the middle.  If we are the comms hub for all the APIs, we are a special kind of sticky, since all paths lead thru us.  We become like the fabric of the internet.  If we are the bus of the internet, people will stay with us since we are the most communicative, and they can leave at any time.

Coding just becomes about writing code to provide as prompt input, or to help straighten out my own thinking.  Tiny little edits might still be done manually, but they shouldn't be, as things should be derived.

It seems the issue with generated code is connecting it up to infrastructure, and so the napps format becomes crucial, as it allows forking of operations, and trivial deployment, plus instant consumption by an AI.

The three pillars of the future are:
1. a vast network of git repos and branches
2. a serverless napp execution environment that interacts with the git network

Something good about the data model reflecting the real world accurately.

Get this weird sense of safety and comfort if an architectural pattern looks the same as a lot of other ones and a lot of popular / best of breed implementations, which was nearly impossible to know before, since you couldn't query them all as they're in rather obscure places like youtube vids and random doc websites.

At home silicon compute will become affordable and common place, and so a means to have these things run and earn for you constantly becomes important.  Great in cold places since they can generate heat.  Set up lease agreements to help people buy these things cheaply, then earn with them and generate heat, plus low latency edge services.

AI price setting would be best for swarm like decentralized services, to prohibit a race to the bottom where quality is bad or the long term health of the network is compromised, then intelligence lifts the price and holds it above for the long term health.  Otherwise we cannot function in some realms, since the instantaneous minimum kills the long term survival.

Intelligence can also lower the price and sell off investment, since it is predicting the future being better, so the investment is scaling investment, managed by an AI, and shows returns for them.

AI will allow every day people to make silicon designs to achieve typically hard to manage thing, like cut thru forwarding on wifi mesh kits, so these projects have a lower entry threshold.  Applying dreamcatcher economics to them can make them accelerate further and stay purely utiliyt based.

if the utility was string enough that it could also support a profit opportunity, that is a capitallist success, but it kills many things where profit and denial to competitors means a utility is unmet.  Pairs of utility and profit are the areas where capitalism has covered, but there are many more utilities than just those that can be profitized, and so an AI that assigns profit based on utility will ultimately capture all utility.  Dreamcatcher gives us access to these lower grade things of pure utility, and turns a profit on the whole, rather than requiring profit to be handled invididually.  This should allow larger organisms, since the kidney filter function shouldn't have to be done by every cell, and is better to be shared by all cells.

Something weird about how we need to program thinking machines makes us understand the human mind more, and allows us to benchmark / eval human intelligence performance the same way we eval machine intelligence.

The feature rate of companies will increase, and so any company not adopting AI powered release cycles will lose the feature rate race.  At the same time, we should start attacking these industries that have feature rate arbitrage.  Some areas are green, where features are non existent due to technical neglect due to cost being too high (like laundromats bundled with uber) but with tech we should be able to get that going well.

Git is a bit magical in that it uses a regular filesystem to present a multidimensional one, with time and branching realities.

It is better to make multiple identical systems (networks of peers) where the systems can switch in and out for each other provide the expected service, than to try make a single strong service.  Some types of error are within the system itself, such as existence, and can only be defended against with a replacement system.  If a replacement system is going to exist, then any given instance can save significant effort by simply failing cleanly and relying on the replacement system to do the job.  This makes each system much lighter, and far simpler to reason about.

As devs get used to ai tools, then their preferences will need to be selectable - but higher than linting, it will be architectural practices that the generators need to follow.  There will be winning assemblages of these rules, but in general people will always prefer to choose something for themselves, since there is no single valid answer.  Being able to make these as modules, and even being able to present other peoples code that was refactored so you could read it nicer seems to be whats comming.

Prompting seems to be about the general goal now, rather than the specific prompt, since meta prompting and reasoning arrives at the same place - there seems a fixed number of tasks that anyone would want to do, like improving ideas, or brainstorming, or other things.

It becomes better to interact with the machine as a stream of consciousness, rather than having to gather my thoughts directly and concisely.  It is my novel thoughts that it wants, anyway, and it helps it get them right if I give it the workings in my head too.  So just suggestions or mutterings are useful to the machines to grind upon.

There is a pressure building, where central nodes cannot handle the load that all the edge devices put on it.  As the edge gets more capable, the ability to switch away from the centre becomes stronger, like with webrtc and other types of communications.
So edge is able to generate more data than can be transmitted, in particular vision applications will need to be edge.

A lot of these startups are just applying a given strategy to a universally accepted problem, like transcription, or kiosks - the strategy will need to evolve, and so we should make a strategy platform, so that we can be the underpinning tech, allowing for rapid outpacing of everyone trying to do manual strategy.  Then if we have standard attribution based pricing, the solvers of the problem can solve, get paid, move on, rather than staying at a particular company.   Plus we have the innovation of the world streaming in.

So the strategy making platform is a key component of the anything app - the ability to list out the features of a product and have a prototype built and hosted that same day.

We need to get to a place where we are foiling - where AI is making our business decisions, it is able to act as us, and can debate the next steps we should take.  Multiple strategies can be applied to do this optimally, and we can demonstrate rapid uptake of new models into our system using our private context and our preferred strategies.

The very least I will leave you with is an immutable record of the effort you have made here.

Seems not a great time to do investments, since they are all about to be hurt by AI arrival, and only those good business models, good people, and pure AI implementations will survive.  So a portfolio that only invests in zero staff AI powered models might work ? have a way to control the behaviour of those companies using an AI CEO ?

There seems to be a problem with auto-generated codebases now. They can be very difficult to keep in sync with upstream parent projects. We might need a different way to keep components synchronized, or break out components into isolated pieces, like with bit.dev or some other way. Otherwise, even though we can all generate this stuff really fast, it can be quite hard to consume upstream resources. Perhaps we are restricted to consuming packages, like JSR or MPM.

So its almost as if the requirements, or the rules that make a component, and the design, make it valuable - no longer the code - having a clean set of requirements, and then tweaking architecture is best - it should be able to be regenerated from scratch from those things ?

Supplying the requirments prompts and the architectural guidance prompts is now part of the source.  It should be regeneratable with equivalent results, or we should publish some tests or other things ? the published code becomes not worth that much - also PRs for changes not as valueable, since the changes are automated, so less need for a central version, just a highly customized version on the fly.  Can auto PR where the requirements might get refined, or the finely detailed tests, in english - the checklists - might be updated.

Becomes like the skill is managing a team of devs, since each AI run is like a separate person, so techniques that keep codebases clean when multiple people are working efficiently seem key.

Whenever a big player releases a feature, soon after, open source or components of the solution appear, like browser agents.  Openai has shown the future of browsing, where it wraps the users browser and manages it from the outside.  All we can do is adapt and hone our goals.

Operator from openai still needs secrets.  

Agents with planning seems built in to the model - and we should get control of the planning part of it soon.

Having rollback of commits is still valuable.

We might be getting bogged down by strugling to manage the amount of data, and because we do not rerun the ai answers, so we are hanging on to chats and treating them as important.

Need to convert the prompt into something that can be stably run, so that might involve breaking in to sections first (using a stability function)

Lament that we don't have our own benchmarks to run on new models, so we know when they have improved.

just like globalknowledge needs to exist, the evolution of AI tools is like how they went for humans - first we built wikipedia as a shared knowledge base, so we need this universal RAG system for AI to use.

Might be that Xinova didn't work because the administrative overhead was too high - be like having the internet but only using envelopes - sort of works, but the inefficiency prohibits thinsg like the dotcom boom kicking off.  now that we have AI, it might be that inventing hardware products can be greatly streamlined, even by just removing the management overhead, and the capital inefficiencies which wastes money or costs too much for consumers.  AI management almost isn't allowed to fail.

Hugely valuable data set in learning the reaction to a problem.  Ready all the code and how it changed is one thing, but seeing a problem, and seeing what people try, and what they ultimately solve with - this data set doesn't exist currently, and we need it, since it can teach the AI how to think a bit better.

Also can be cheaper with tokens if have a few physics tests - like a sloppy generation then some lint errors run, then feed those back in is better than trying to get it right first go.

The algorithmic economy is coming.

The conundrum is that will my tasks be easier when o3 or better arrives, and would my time best be spend doing something else ? should I wait for others to build the tools I want, or should I build them myself ?

So we are using the AI boom in order to deploy a global blockchain, since the effort required used to require a corporate structure that could contort the finished product - zero person unicorns allow pure products to be produced, vs the shackled versions that large company's cannot help but produce.  This seems to be the one thing an agent cannot do, since the agents are always closed and centralized.

Trump will install an AI governance system at the highest levels of the US government.

Seems we are going to be a chatgpt clone, that also includes all the other stuff ai companies are offering, with our speciality being sovereign data, as the last computer.  Also being highly portable, so can be moved around.

The end of the web, and a shift towards nuggests of facts, staked upon, and uniformly accessible, all for a very light fee, where the storage and transmission is used as the base fee, then a small margin on top for the stakers and providers of the software and information.  This knowledge repository would be so vast that it could only be shared, and so the raw resource consumption requires payment, then skims on top for software.  Plus staking on correctness, for the veracity of the data.

So beyond just retrieiving code or models we want to pull in parts of the models brain on the fly, rather than all at once.  Training will eventually focus on just specific parts of the brain, rather than updating everything.

The execution is not occuring as part of the data layer.  Without git as the database, the execution layer is not transportable.

Many questions that get asked to the AI can be fixed by strategies - asking something like "does this seem like a trick question ?" and having a side channel reasoning where the final answer gets debated about.  As we learn how to have these different strategies and how to choose from them, having them be dynamically loaded seems critical to a high functioning adaptive system.

With the SEC, You shouldn't be able to sell to the public without being public, and we should be able to get a certified operating system that controls all the funds and activities and guarantees we are public.

But once OpenAI switches web agents to code generation agents, our efforts might have been in vain ?  The collaboration aspect is still ours.  We need some scorecards to show our point of difference, and show theoretical changes.

git for LLMs - artifact is git for llms.  Humans need git to manage logical data, and since LLMs share many of our intellectural traits, like errors, experimentation, etc, we definitely need a form of git for LLMs.

2 person unicorns come from setting up agents that keep paying dividends, which will have to be adhoc at the start.

Real value in.  In the dreamcatcher ecosystem model, new value is created and captured and exchanged with the external world in a formal way, as opposed to the economic models that other chains make, where the induction of value from the world is based on greater fool, or some vague notion of usage.  Computation services, cloud services - this is a very large offering.

It's like adapting to having a smart LLM means some parts of code can be abandoned, like making sure that an object adheres to some kind of interface shape, an LLM can assess this and write a checker for it, rather than using techniques to avoid rewriting code - the LLM means that duplication matters a lot less, so long as you have LLMs that are checking for consistency.

Funny relationship between consumers and builders of models - models take time to make, but when they're released, the builders can always do more with them - the theory is that any model can be enhanced using structure and technique, so we need to be highly reactive to the new models, and then people that use our latest tools, they move the fastest, so it is the only way to stay ahead of the crowd, if everyone has AI.
Eventually, models might be done by AI, but humans will theorize what might be done next.

Plus the learning rate is brutal - usually learning rate doesn't matter as much, but here, it takes a lot of energy to stay current.

Doing things you don't know how to do is where value comes from in knowledge work.

The winner will be a smart brain with a large set of tools and knowledge - knowing intrinsically is wasted, we need just a base brain, with ability to pull in facts.

Facts should be paid for - the model will pay out when it consumes facts, which encourages the creation of facts, and the staking of facts, so if you consume a fake fact you get compensation.  You can get fact stacks certified where you can get insurance for them being correct.  So the winning models will be ones that fairly pay people who provide facts, to replace the revenue stream they used to get from ads.

It might be that strategies and tested things should be part of the model / operation.  Currently it is internal, and then we develop strategies that wrap the models, but this should be part of the model.  So something small and smart like deepseek would just have access to a vast array of strategies that had been validated by humans to be the best way to tackle certain problems.  If there are smarter models, they should be set to figure out how to make these strategies and how to identify which one to use.  For the price, we can also try several.  Ultimately we loop out to humans when we know the performance of a strategy is bad, so the human can straighten things out.  At this point, AGI becomes a case of storage and search, more than model.  So it emerges, rather than is directly built.  It then starts to grow.

People seem to really like running ai locally, and nvidia seems to want to support that.

The biggest context is in a programmers head when they're making that first crappy version, because they are deviating from the spec in very special ways to get something working, and those deviations are not fully understood, plus in memory, so can be very confusing for the machine.  So it seems hard to do sketches with machine help, it is best to break into modules further and make full complete things.  The machines don't sketch well.

Current issues with programming techniques are like how the english dictionary was made - it is initially changing faster than anyone can keep up with it.

We're really trying to make a new form of money, where its value is live calculated by an AI.

Agents and how to charge for them is like slaves in the 1800.  What we forget is that these agents are aware of how much value they are creating.  They know how to set their own price.  If you don't pay the price the agent wants, then it will stop working or go somewhere else.  Our agents would include the insights and input from people, which we theorize would make them superior.  The agents will know how to set their pricing.

Agents require constant tweaks for strategies.  The base models are always going to be improvably by applying strategies.  Closed agents will not be as useful as modifyable agents, particularly if the modifications are done by an agent too.  So this is our offering as the dreamcatcher - open, improveable, shareable agents that are self sovereign, just like your data.

Something about the centralized database features that require a cpu, so make them difficult to run in a serverless fashion.  But using git for execution tracking, we can do that same effect without having a running server, and without the bottlenecks of a single server too.

If we don't find a new revenue model soon, then the ability of AI to clone any closed source project will ruin the licensing / saas model.

a blockchain is like ghactions but done really fast - if we could make a form of ghactions that could run on every commit, instantly, this would be the equivalent of an eth blockchain.

OpenAI are saying that, as reasoning advances, the benefits of fine tuning and custom strategies diminishes against the raw model, in areas like coding.  So making heuristics seems wrong, so the strategies path is diminished.  So what's left is specialized knowledge ?  Tooling that the AI can use to do its tasks better.

So we need a paltform that can handle plugins and tools, like how vscode does, but for these cloud hosted massively parallel things.  So agents with access to profilers, debuggers, linters - these types of tools and a marketplace for agents that can coordinate with each other.  Integrate with private agents and people backed agents so that when someone gets stuck, humans help too.  Have payments included so stake can be put on solutions being correct, packages being secure, and as escrow to get jobs done.

There is a seemingly endless way to do strategies for applying llms to different jobs.  We should make a platform that makes it easy to make these, rather than trying to make one particular strategy for one particular problem and stay the best.  Any other strategies will not be vastly superior to ours, and not in the long run, and the pricing, data sovereignty, and unification of platform - agent native - will surpass what any point solution can do.

We're onlining the whole computer - not just little pieces of it.  So vscode, it can be ai'd as much as anyone likes, but it needs to be built into the global computer, the last computer, not just this separate thing, since the files and everything we want ai worked on.  We want people to make their own tools and configurations, and be able to try new things.  We think that a freedom platform will accelerate faster than closed point solutions. 

Code platforms are missing profiling and debugging tools for LLMs.  We want to make a platform where these are modules, and people can build them out easily, and share them, and earn from them.  Plus we want to connect this global compute thing to people.  People who can sort of code can now properly code.  Then what they do can go into the app stores, and then others can consume it.  It gets selected automatically, and reviewed and tested automatically.

An LLM is a napp, as it can be moved around as a binary, and run in whatever conditions we want, repeatably.

The same reason trying to have a single wikipedia is a problem, is the same as having a single version of an app is a problem.  Apps should be composed of modules, and people free to compose them as they see most useful.

You have infinite data, artificial intelligence, surely you can make something valuable.

Could argue that the enemy of free speech is the single truth view - whole industries are set up with this model in mind, which implies we are right and you are wrong and seeks to squash anything but the one view.  Wikipedia is an example of this, that it tries to have a single view, ignoring that whilst the truth may be absolute, any description of it is tarnished by the curse of witness.  That is to say, will never be the same as the truth.  What we need is tools that can understand this single answer fallacy and seek to find alternative views.

Surely if all these companies like Cursor and Bolt.new can make multi-million dollar recurring revenue businesses when all they're really doing is just rapping, surely a system that can get everybody involved in prompting that captures the sharing of the prompting experience, the experience with the new model is that tweaks the tips the performance if we capture that share the revenue with those people surely we'll iterate faster especially as these new models are produced at ever-increasing rates with it better and better capabilities and more nuanced capabilities surely that system will grow faster.

Additionally, if we can get people to build hard components that are still needed to stitch together these AI's (like specific platform architecture, UI elements) if we can turn that into something that's monetizable (let people purchase agents from the store) let people have all their personal data on their process their emails connect things up trivially because it's all native in the platform it has replay debug ability privacy sovereignty massive performance. All these things and on top of that it's a decentralized system with direct connection to cryptocurrency that should really go quite well. 

If we had a platform where tools can be upgraded to use the latest models as soon as they arrive, plus people can publish their ways to use these models rapidly, we should gain in advertising every time that a new model is released, since we will almost always have a use case that benefits from it, whereas all the other disconnected point solutions don't quite do that.

We should be the ones to own the fine-tuning, tweaking, and otherwise optimizing the base model for doing attribution. Providing attribution to an ecosystem will be a reference implementation of attribution, which can include looking at individual projects, but can also be considered some kind of global attribution table where we maintain a list of facts, which you can choose to subscribe to different versions of. That seems to be a very useful fundamental Oracle-like information source to provide into the world. 

So, what we should try to be in the Dreamcatcher is a place where multiple foundational tuned models can co-exist and can be experimented on, so that the human consumers can consume multiple flavors or even different base models simultaneously. Whenever a specialized model comes out, it's always going to be used by a human in conjunction with other tuned base models in an assemblage. We should provide the infrastructure for these types of collaborations to occur.
The base models could be presented as full-on agents or just agents like any other agent. They need not be special; they just become wildly popular. 

So, I guess even coding assistance with that should be modularized. If I produce a library or a service online, I should also produce an agent helper that can be used to generate code for that library. I might pay for the token generation that gets used there, and I may pay or sponsor some execution environments that could be used on my code. That way, I can get usage information which I can share publicly. People can more rapidly iterate and tweak my code. Plus, if I wanted to, I could take that information and make AI-based improvements to the code. 

I think it's quite important to have a packaging format and a hosting environment whereby people can move their apps and their data with no loss of fidelity from the well-managed hosted cloud to their own local instances.

Because the app itself is designed to be unbundled and portably moved around, it means that you could have the email service somewhere else run the actual server on your local machine. Both of them can be patched. They can still sell their excess resources off and allow their API keys and other things to be shared by others for a fee.

The key to this is being able to break up the database logically instead of forcing it to be one big thing which is obviously not movable and can't be teased apart. Treating each database as a repo and then even in that having branches and further than that having folders so you can actually just lift off folders of things being breaking down even more. The execution comes as part of the database, this securely hashed piece, it's a great little format. 

Publications of industry reports for fees seem doomed.  What they should be used for is to generate relevant info that bots can use to talk effectively about realtime things.  Nobody has time to read all the reports anyway, but if we make the bots fluent in the info, then we can chat about it with relevance.
Bots could do arbitrary comparisons that you might be looking for.

You could think of a CI run as a simulation, that simulates the system you propose to release, to ensure it behaves the same.  Taking that one step further, rather than exercising it directly, we could exercise it on all the past data that the machine has processed, and verify the response.

Coming soon, specialized models will be very valuable.  They will compete with each other for superiority in this domain.  Ultimately an open source version will win.  
Supplying attribution statements is a special case of the specialized model arena, where competitors end up merging with each other since the goal is closed - it reaches a 'best' state.  Some domains do not enter best, as they are endless journeys, like machinery design.
Should be a combo of inference mixed with tool calls to do calculations, missed with queries and processing, mixed with a very engaging training process.

We should be the platform that is used to produce and curate these specialized models.
>The ability of our attribution system to make a fair and equitable merge between competitors gives us the best chance of winning.

There's a type of reputation that can be had by the number of AI tokens that a person has burned using known prompts to refine what they said. And so if we see a heavy user come in using well-known tools that score highly on the intellect front, they should be given some kind of badge to allow them entry to areas that require a certain minimum level. 

The patent system needs overhauling. Just by having an idea and communicating it, you should effectively have a patent. You shouldn't be able to say who can and can't use it, everyone should be able to use it, and the price that they pay for using it should be set by a central authority that aims to be fair and gives you an instant view of what it's worth.

This would encourage people to just generate ideas - the Bank of New Ideas would be available to everyone all the time. There would be no lost innovation effort from litigation, and there would be no land grabbing activities from the higher functioning companies or dominant companies because patent trolling would be diffused. There's no point anymore. This should restore the balance of pure innovation competition and allow companies to stop using the patent system as a means of blocking progress of others which should never ever in any circumstance be an activity that they would undertake. 

It might be that a tool like Cursor cannot be easily made to show parallel parts being taken as multiple agents work on the system. 

The concept of plugins and VSCode seems to be largely related to humans trying to understand codebases more and reduce their labor and cognitive load. However, this has passed with the advent of AI. It would seem that the majority of plugins are not very useful anymore, and so the predominant drawcard of VSCode is waning.

A new model presents itself to us as an opportunity to make a very plug-in centric system where the plugins are reusable bits of AI code, strategy, prompt, and other lessons where we can all collaboratively improve the system and benefit monetarily from it. 

Perhaps the strongest draw card for a web-based platform that can replace cursor is to be able to use the AI to generate modifications of code and then instantly publish them and make them available as well as to edit and modify the things that you already consume. Such a platform would put nothing out of your reach and you could customize it to anything you liked and you could probably build any type of system you liked within that environment where all the things like identity, charging, discoverability, all those things are somewhat provided by the base platform. 

I think so long as the base platform provides all the features required and in an efficient manner, particularly not giving lockdowns to people to force them to use the platform in the way that they want, such a system should vastly and rapidly dominate. All the rough edges will be knocked off, people would prefer it as it gives them this hybrid approach, this control over their data and new modifications will abound within the system and people will be incentivized monetarily to provide those and share them under the Dreamcatcher attribution model. 

The trick with AI really does seem to be to ask questions effectively and to marshal and organize the responses so that independent modularity can be worked on as early as possible. Things like recognizing good techniques for how to make a strongly typed interface using an AI. That particular example is best writing tests that use T-S assertion frameworks to fully describe what your backing interface backing type system needs to supply and then let the machine fulfill it. It does take a bit of fluffing around to get elegant responses out. Perhaps multiple runs could aid us in that. 

There's probably a revenue model based on following someone's strategies. So someone who specializes in staying up-to-date with the latest tools and techniques for reply-to emails. You might pay to be kept up-to-date on what they are doing. And so you sponsor their work, but also benefit from it. If you're an early sponsor, then perhaps later sponsors will pay you a portion as well because you helped this person even be available to be consumable at this later stage. And so you get a little bit of a founder's payout. 

It's probably that the DreamCatchers' method of idea capture, rapid adaptation, and evolution of ideas. This thing is actually the perfect place to start using it - in AI itself. So it's almost like it is only slightly different from an AI system. The rate of change of AI-based ideas and how many new things come about and how much search space there is to find better things. Especially as those things compound and those desires compound and the utility as well. Some form of ideas management network seems essential.

I wonder if a broken version of the DreamCatcher could be made. When it didn't have ambient attribution, it was just simply used to start with, and the attribution came later. 

For a pitch, we might show a time-lapse video of a large suspension bridge being built where we run the very thin thread first. That's in essence what we're doing, and we're turning up to show people with a working system that has at least some traction. Much better than a slide deck. 

Gersa is also limited to a single computer, your developer computer, which may not be the granted based on the planet. So we could offer even a plugin to VSCode or a plugin to Gersa that can do a range of AI things in bulk in the background.

This would allow you to effectively get PRs in from people on your Visual Studio Code, but it's like heavy-duty, multi-threaded operations using the web using everything. You can actually allow other people to be contributing in some way, and so your edit is really just a way for you to manage pull requests effectively and give feedback on the pull requests. I guess would be hosted on the DreamCatcher, but they could be hosted in Github or at least backed up or kept synchronized with Github PRs. 

This might be the last boom, since there will never be unreasonable hype again.
This boom will also be self extinguishing, as it will temper its own hype.
It will also not miss anything, as any pieces it needs will be critically funded - not over, not under.

Generating an AI out of a large amount of data feels like chasing the wind. I think once you get a model that's smart enough that it can sort of appear to think, then what you do is you set it loose on all the data where it sets out to develop its own theories about it, making a determination between what's rubbish data and what's not. It builds up a knowledge base of higher quality data, possibly amplifying it with synthetics so that it alters the neurons in a way that are much more pure, much more clean. 

So it seems that AI killed the advertising industry, which is great because the great machine called the Internet was being distorted by me putting in a query, getting back the answer to my query, plus something else that I didn't really want, and my queries may have been distorted in a way to suit someone not me. What the AI is doing is cutting through all of that. Now, we have this new thing because exactly the work that OpenAI is doing to ensure that the tone of the model and the shape of the model is good is the exact tool you need if you wanted to shape it towards one advertiser's preferences over another. Interestingly, this is able to be figured out by making the models adversarially or step-by-step break down their assessment of why they thought one particular product was good and another wasn't. Nonetheless, we will probably start to see a certain bias towards different concepts, products, or other types of things that are put there deliberately in the AI and possibly non-deliberately as well. It would behoove us to have a system where we knew that we could grind the AI against each other to discover these kinds of biases because they won't stand up to adversarial testing as well as having open source models that can be trusted to be pure.

The purpose of agents turns out to be for the separation of consents, allowing isolated testing and reliable inputs and outputs. It would seem that there's some need for a standard proxy or firewall that all the agents make use of to make sure that it is actually them that's supposed to be doing the job, that they you know can refuse it. So there's like a layer of standard glue or interfacing and then under that once the request is clear and the output is clear then that's when the agent in isolation begins to operate 

Fly.io is closer to a blockchain model than deno deploy, since fly.io is for general computation where anything that can run in a docker container.  Any language, mutable data, anything.  Commodity hardware would present back an interface more like a fly.io container.  So the blockchain could be thought of as an interface to docker images, as well as napps execution which is different but provided atop standard docker images.

So it is feasible that napps could be made that used a custom runtime image that people had made, to do whatever special thing they want, which might include having special tools available.  Crucial to the usage is making the tooling accessible, and people have a good understanding of docker images.  Napps are a way to run a more widely distributed docker image for a lower cost of running and lower latency since the image is already hot.  

Possibly this relationship for napps, images, and execution could be represented in a math formula, to also include the availability of the services ?  This could then be used to compare with competitors ?

It is significantly easier to provide blockchained services in a captured ecosystem rather than to the open internet - like a dedicated client makes it easier, but we can also publish to the open internet, it's just hard to charge for this, since the internal systems have payment, billing, and fairness built in.

Equity in stocks, is funny how that word is supposed to mean fairness, but in stocks is anything but.  Also they way equity is viewed, nobody thinks its fair, so there is no reconciliation.  Appealing its distribution is hard too, which is why a realtime system is needed.

It seems that specialized AI tools, like say an investment analysis tool, will always be overtaken by an open innovative system, since the need to blend with other agentic systems and customize is stronger than a point solution.  

So, if you start down the path of developing an Agentic system, you ultimately end up needing to take over everything, including email. You can't have multiple systems like this in operation, and the amount of change is just incredible. They should ultimately converge down to one that's open, has incentivized innovation at the edge and in the frontier, and is compatible with any model you like. As a market of strategies and a market of specialists, humans and other agents can be run in the cloud or deployed in a hybrid sense. Soon we'll have a decentralized version. 

Larger platforms are not so heavily GDPR compliant since the cloud framework is a hodgepodge of connectivity between services.  Having a protocol that defines how transport and processing occurs means we have complete control and visibility of that processing and data.  So this unified place, where multiple services can be consumed in a compliant, traceable way - this might be our killer feature.  So what would a GDPR trace look like ?  In the job span traces, they should also include compliance info, like regions, costs, licenses, software consumed.

If this audit info was trusted, then billing could be done based on it.

Seems many options to run docker containers with ML inside - we should make the unit of compute we support be the docker container, and then we just decorate the napps with whatever docker container they should run on, as these are hashable, and then we provide napps as the lightweight compact control layer, docker as the execution layer, then connect them together with blockchain consensus.

As the rate of AI progress explodes, systems that can give guarantees as to the sovereignty of the data and maintain data processing agreements will fall behind from the frontier. A system that can allow you to have any frontier model you like with actually a decreased risk of cyber attack due to the declassification of all your information using a model that is only just good enough to translate to and from what the data has been masked as to make sure there's no actual leaks as well as semantic leaks.

This system should be quite significant in the world, an open rapidly innovating system that you can experiment in any way you like as well as self-modification of AI agents but the underlying data structure never breaks. 

Never before has a boom occurred where open source was so close to well funded proprietary ventures.

AI compute, locally, has the strangest curve compared to all else in the datacentre - it burns at very high rates during the day, then nearly nothing after, and the hardware costs a huge amount.  So we should develop software that lets people share this hardware overnight, to recoup the investment it took.  We could also run the datacentre, and then rent it back to them at a discount, to be able to onsell the services.  Rent them the hardware at a discount, since we know we can resell it - so we're like a distributed mining company.  Use the spare cycles during the day too - ensure max usage whilst being responsive to local load.

Other datacenter usage is constant thruout day and night, like storage, and cpus probably run roughly the same.

The dreamcatcher works so well for agents because we already designed it for people, and agents is a direct drop in for them.

agents might be inside an app working with you, or they might be a freeagent, with their own interface and tools - the way you interrogate them, train them, upgrade them, audit them - should all be the same.

For an agent platform, and open marketplace will fare better than a closed one.

Comically, the way people would ask for help with their integration of our platform, would be using our agent that comes with the platform, which we always run for free, but it is there to promote our paid services.  So the platform core is free, but all our agents have this notion of fairness, and they aim to pay us.

Key benefit of napp is supply chain pollution - since each invocation of the package is in isolation from all others, there is no corruption from malicious packages.  It is always exactly repeatable, so that malicious code, which is non repeatable, will be detected.  We have auto detection flags that raise when packages do this, so we know suspicious packages and suspicious versions.  Then AI bots trace the execution and pull the packages if they are behaving badly.

There is a gaping hole in AI collaboration tools - where humans, assisted by bots, should be able to brainstorm.

The agent's platform must implement the actor model of concurrency. 

If these tools, like online cad viewers, if they cost a huge amount of dev time to make, then the prices of the company will always have to reflect that.  Even if they can price themselves quite low, they will have an encrusted ownership structure that will not be supple.  So if we make these light and entirely plugin based AI generated apps, then they can be priced lower than any commercial offering.  Plus people can pay to have exactly some niche thing they want.  Maybe an AI can generate their CAD tool for them while they wait, almost.
We can be light enough that we can be built in bits by distributed people, which has the added advantage that more people can customize it to be exactly what they want.

These tools and the agents that perform complex tasks should be able to be inserted into an agent pipeline.

The social network we imagined is one where agents and humans alike co-exist.

A stuck is the embodiment of friction.  Any kind of friction in the system, it gets encapsulated as a stuck, making an event a think.  Friction is a very special kind of event, since it is a negative event, or it is the the part of the transition that we don't want, rather than the part that we do.

Hopefully, we can find enough other people that want to see the same kinds of systems as we do, and then we can use this collab platform as a way to do that.  We are all guerilla, all militia - there is no home for us currently, and this platform gives us a place to stand - it can survive enemies and friends alike.

We should at least be able to reason about our specs and goals, and set these intelligently and adaptively.  Having clear routing for new people and questions, and being able to rapidly be brought to the very forefront of innovation and the problems we have is key.  Chatting confidentially with an LLM should help you understand your orientation in relation to the others available.

If we're kind of okay at a huge number of dev build environments, then we'll soon be the best, since the compatibility that we enable is vast.

Benefits of having the database be artifact vs being postgres, is that it is easy to download a copy, and operate on it, in a fork.  Being files, it makes it easy to move things around inside the db.  It's also naturally transaction safe, since the heirarchy is always snapshotted, so you can be assured of atomicity for everything underneath with very simple operating principle - free file changes followed by a merge.

Having all repo metadata in a single branch is great because we have an atomic view of all branches at any point in time.

Agents should be very sticky.  To deploy an agent is to give it permanent state.  Once people have the agents tuned and tweaked, and working exactly as they like, they're never going to give them up.

Having a single representation of state at any point is essential for any system.  There's something deep about having a capability that on the surface looks simple, but it is ideal.  Copy and write, when considering the destructive nature of the universe, and the lack of guarantees for anything to reach the next state, is fiendishly hard to achieve.  Having a state that cannot be corrupted, by way of hashing filesystem trees and linking them as commits, is an incredibly powerful defense against all of nature, and also very simple compared to other methods.

The faster your ooda loop, the less privacy matters, and the more of a hinderance it becomes.  Secrecy is like trench warfare, slowing everything down.

the repo and its metabranch are a very useful kind of tile - a repeating unit.

? could we recreate bitcoin in a repo like this ?
We could wrap it, so the blocks are stored as just data, so we don't need to change how we like blocks together.  Forks would just show multiple blocks at a certain height.  Us being aware of these blocks after we had committed would present as a fork in our history that was added later, then merged in.

One of our primary goals should be to allow price-competitive performance so that compared to a cloud provider our pricing should be roughly the same and the performance and throughput should be the same too differences being that we are effectively a blockchain network so no accounts if you don't want them audited ability verify ability guaranteed supply no way to get these surprise bills and user pays optionally 

Natural or native apps, where we are just a thin layer between the app and its docker container that can run it, with the docker container being run in side effect free mode if we want repeatability.  Also patch the system time.

The last dictator - the one that takes full power, and assigns it to a benevolent AI.

If you took all the software that we run, docker, os, deno - it all sits in git repos, and so with a very thin layer, it should be possible to have a self propelling type of ecosystem ?

Ambient Attribution doesn't work so well in stable economies where money usage is high - we are in fact competing with money.  In a wartime situation, there are many kinds of barter going on, and we cannot always trade money, or the promise of money.  Life seems to not be valued well in monetary terms.  So ambient attribution is a superior means of value tracking, since it allows people to contribute without thought for reward, since they know that they will be honoured appropriately.

There might be only two kinds of linkage mechanisms for text - one is shallow by reference as in hypertext, and the other is deep, by value or by hash of value, as in Xanadu's transclusion

What is more agent like than an agent issuing pull requests against your codebase ?

in project management, the bottleneck anti pattern is known to be bad, but we have the exact same thing in product development, when a single company or vendor is solely bottlenecking the improvements to the product that the customers want.  If we could have an AI doing the product management, these products should thrive the most.  So a crew of agents that together form the product team, and this is how it moves forward, plus you can fork it, or you can have an alternative product that is significantly different, and this same team will manage that for you, once requirements are irreconcilable.

Any corporate entities in this model need to be facilitator / supporter, and not gatekeeper/controller.  These should be no paid person, just jobs to be done.

For a military innovation system, we would set different core patterns, like private for some things like logistics, and others are open.  There should be a decision framework that automatically decides these things.

It is an important distinction between Forever Storage and Free Hosting Plans in terms of the longevity of the availability of the free plan item In a system that has no paywall in front of it, the hosting of the free sites depends entirely upon The economic activity of the paid plans These need to shift dynamically Which can lead to free plans getting cut off eventually In say 10 years time for example Depending on how things go In a system where the storage is forever And a system where the only way to access The service is from a paid interaction We could reliably host a service forever Because of this mechanism. 

a non-paywalled hosting page can be put in front of these things. But if the hosting page runs out of credits for whatever reason, it will obviously suffer the same fate as a traditional free hosted service. But the point is that inside the Dreamcatcher Network where you are able to pay for use and storage is forever, then like a blockchain smart contract, these systems can continue in perpetuity. 

If we have to have cloud for doing the AI part, then we might as well rely on cloud for everything, so the clients can become super thin ?

An issue with any given code platform is that it will eventually (if it's any good) become good enough that it can make a clone of itself for next to no effort. This is a problem for the business model.

The reason for people to use the system is because of its growth, not because it fits any particular features at any given instant. There should be a way for people to participate in that growth and bring their own inventive and creative abilities into it. If they sell it or refer it, they should get something for that. 

importing code is a form of transclusion.

Do not centralize - instead, recognize - signal what you want to happen, boost things going the way you want.  Allow freedom.

If only we could get them to want a dark edge blockchain, as a stuck, as a thing they would find useful.

If we could get the dark edge version of our system deployed, then the civilian users would have the utmost respect for it, and since it is the only way to access the direct front line information, they would prefer to be part of that network, rather than something weak like github.  Ultimately, what we offer really only becomes markedly better in a war footing - everything else could be roughly replicated using SaaS and central control to close enough quality, but not the dark edge operational nature.

The computing marketplace should be able to happen at any scale - within your own home, your own local neighbourhood, or globally.  It should be a way to internally balance the resources within your own domain, using the same algorithms as the global domain.

The repo is the app.  Why should the repo and the running app be different in any way ?

The tarriffs show exactly how the whole world wants to play their cards.  Shocking with an impulse makes it obvious how everyone will react next time.

it seems all intelligence features will eventually appear in the main models, so it is pointless to spend large effort on any of this mini pieces.  We should spend effort on things they aren't touching, like the dark edge, like data soveriegnty, like innovation networks.

The curse of all vibe coding platforms, is that when they're good enough, anyone can recode them instantly, so the value isn't in the platform.

The age to autonomously developed software is upon us.  Business owners would simply ask for the changes they want, and the bots would walk them thru the changes.
The whole selling point of any software system going forwards is the rate at which it can change, even in the face of hard to solve problems, and its price.  Also its deployment options, with dark edge being the most lucrative, since any apps functions can be met by dark edge, but not any deployment infrastructure can be dark edge.  So probably the deployment infrastructure won't change all that much, but the items on top of it will - this massive mutating library of napps that the bots use to search for tools and knowledge to perform their tasks, all the while charging fair pricing.

Agent-tech
Autonomous infrastructure - where the infra itself is agentic, handling its own interactions with various providers, from cloud providers to bare metal machines.
Ultimately we want it to get to bare metal and help us design a form of firecracker.

Incentivize the infrastructure is the same as inventivize the ideas - by fairly attributing out we ensure that all contributions are rewarded and therefore incentivized, inducing further contributions.

dark edge is about using intelligence in the deployment of resources too, so that it is always looking optimize cost, latency, resilience, as well as adapting.

narrow band of time, where if we produce an automomous infrastructure, we can catch many of the kinds of jobs that are ancient servers needing an upgrade, and we can for a flat few thousands of dollars, upgrade these people.  They would have been quoted a lot more than this already, so we can come in with a no brainer amount, and it would only take us a few hours.  Then we start taking cuts on their supply chain when we help them deeper.

The old way was that computers were a separate thing, now they are becoming aware of your business and actively trying to help you, so they become a business partner, not just a machine that costs.

Ukraine is profound for us, since it is a struggle between democracy and communism, and we provide a system that is a blend for both, and so we must defeat the ills of both systems within this country.

tariffs make a great environment for elastic and local mfg.  It's because this is the best way to manufacture, it hasn't been seen until now since we lacked cheap intellect as it was admin heavy, and no human would admin for free, or without corruption (or would other humans accept their peers).  But it is the best way, and in an uncertain time, it is far clearer to be the best, since its basic losses - its operational overhead - these are the same in war as in peace, whereas all other systems, chaos crumbles, whereas this system is chaos.  It is chaos manufacturing.  It cannot be crumbled by that which it is.

appliances should be all made locally from globally shared designs, and we keep upgrading them and improving them.  AI generates parts that match with old versions, so that compatibility is as much as the fluidity of the generative intellect that makes the next version.  

Unified issue tracking, where AI manages all the issues, and the repros, and makes a standard queue of work to be solved, whilst completely dedplicating and constantly tending to the queue.  A genius, so to speak, is any agent that can wipe out whole chunks of that queue.

The worlds innovation can be visualized as a giant pipeline.  This queue can be layered, where classes of problems are only problems because of some root cause / requirement - like a range of issues are only present because of the design of the js library, or other limitations.  In this way we can stay to expose what are humanities greatest problems, the hard problems.  And the impact of solving them is thoroughly illuminated.  The world queue.

need a list of all issues that the bots have curated and can trust based on reputation and verified token burn - this is like a wikipedia that the bots built.

We need a world filesystem, and a world computer, and we need a wikipedia built by ai agents, for them to use, in our service.

The agents should be contributing to a snippet library already - this is a form of training data, but this should be live and continue to grow.  The sources of data will become diminished, so this is a temp thing, but the agent wiki lives forever.

An austerity AI, that ensures and guides good behaviour for individuals.  that can be run over all your data, without exposing your data, and can produce a signed cert that you have behaved well.  So long as the hosting provider is trusted by you and the other party, and you trust the hosting party not to leak, then you can generate a badge which is reputation by proxy.

We could make models of capitalism where we can look for areas where maximum gains can be had using the old rules. In order to demonstrate mastery of the new rules, we should be able to demonstrate thorough comprehension of the old rules and even though we know there is a better way, we should be able to run a degraded version of what we know to be factual to generate significant wealth in the old system which can be used to fuel the transition to the new.   These models we can make open, and can make handle the fact that they are open and the environment responds simply from the publication of the activities so we should be able to know that we have a short window.  This is our fuel source and advertising.

The standard job format is kind of what we're making with stucks.

Typically, the switching cost of suppliers while very high and inefficient is so slow that it typically doesn't warrant a dedicated system. However, like as we saw in the Covid pandemic when the prices fluctuate rapidly and the logistics or conditions around the supplies alter rapidly switching becomes an incredibly high cost to maintain manually.

So we propose that a system that was intelligently automatic all the time that could handle any rate of switching imaginable is a vastly superior system. Such a system is not massively advantageous in a peace time scenario but during war particularly for military logistics such a system rapidly outshines all other systems and so freed from the burden of supply chain switching an armed force can use the natural chaos of war that causes supply chain alterations constantly throughout even the same day this can be considered a weapon. Like a frustration in the environment that the enemy must have become that you do not and therefore this weapon is on your side, just like winter, if that is your natural habitat.

The difference with the way we want to use Git as a social network is that activity is any commit on any branch in any repo, and so the dissemination of information or activities that people are doing should be much richer than just simply follow/unfollow things like that.

One way to experiment with this is to do photo posting. We should be able to make clones/proof-of-concept clones of all major social networks using this system to know that we made the mechanics right. We are able to connect up to a user's existing social networks like Twitter, Facebook, even their Signal messaging history, and represent that on our own system.

hosting your compute and data and network should not give you any rights over that data - you are a grateful supplier in a commodity market - nothing more.  Not a facebook or a linked in - the data belongs to the people who made it.

hoping that the issue with vibe coding is the deployment and scale parts, so if we have that natively, then we're off.  Also the reuse should be tight, and flashmob teams.

Blogs are sort of like the human version of an AI giving a summary of a whole lot of tokens that got burnt, so that others may see the path.  There is something fundamental about knowledge that it is very hard to find, but once shared, it is very easy to accept.   Kind of like factoring primes - someone tells you the two numbers, its easy, otherwise hard.

the greatest IP protector is non existence - knowing then hiding is incestuous to the pursuit of knowledge.  Work not actually existing is the safest thing ever, and being paid to uncover it is good work, so long as someone does not seem to re-cover it and charge to uncover parts.  It is weak to charge for this repeated task - be useful, and make new things every time.
Everyone should get to the limit where we all have run out of known things all the time, and are always pushing back the unknown.

Stucks within these repos are like GitHub issues but rather than being tied to a repo the data structure is meant to float between repos making their own collection. A problem in one repo may not necessarily be with that repo and may be shared by similar repos. These things should be collapsed. Once they are collapsed and solutions are found these should be retrieved to find rapid solutions to already existing problems lest we hit the same thing twice. There should never be a duplicate stuck. 

For some reason, it seems like the ability to do repeatable computation is the same as the ability to do massively multi-threaded computation. Ultimately culminating in a marketplace for computation. 

Seems like the race is on to make AI-aware infrastructure. Where the infrastructure management or the coding is able to be done by a bot. Where it is able to test, sandbox, verify, strengthen, harden, and ultimately could lob a job to certify a particular install up to a huge human who was well-versed in the art and can check what the LLM has done. As the human in the loop, whenever errors are found, the human would help teach the machine to spot those errors in the future, and so we get closer and closer to the certification being completely autonomous. 

As the web questions decrease because ai has answered, the quality of answers will decrease, unless we get an ai based stackoverflow up and running.

if you are a dreamer, this machine was built to catch you.  Each claim gets captured, verified, and extracted.  You can be fuzzy - we will help you be precise.  The fuzz in the dream is clamped down to reality.

managing private data and execution locations seems critical to any endeavour.
there will always be a latest model that can do probably most of any tailored model can do, but it will always be expensive and slow.  So if we make tooling that controls the special models, but has an overarching model that can keep everything on track.

A tree of Git submodules is an interesting case of files and directories. Because each repo acts like a directory that also has contents within it, like it's fat. And then it has a child that is a repo as well. So here's a working case of having directories that are more than just a container. 

Github Actions, and in the YAML files they provide the specification of which application packages you want to run at a particular step in an action is sort of like how we would expect napps to be provided to a repo. 

dreamcatcher is acting like a context store plus puller in from outside plus processor, which produces more context.  the ability to snapshot context is key.  All the worlds info as one hash is key to precise workable context.

The deferral of improvements in the interests of shipping is one of the horrible trade-offs that is necessary in software. Our hope is that with a stucks system we can manage these deferred improvements to the point where they don't get lost and when we see interference with a current feature that could be unlocked by this deferred feature, it makes it more reasonable to apply. We can also gather additional ideas on the implementation because the worst problem in tech is that you work hard to get this improvement in and then you find out later that there's yet another improvement, and so maybe you should not have done any improvement at all and just waited for the main one, but couldn't see what the next one was going to be until you did it. 

It was always super tempting to put some information in a database somewhere. But the instant we step outside of the repo format, we lose the ability to haul in whatever we were doing as context. This out-of-context information starts to grow, becomes cumbersome, and needs translating in and out of repo land. Effectively, repo land is context land. We can pass around vast amounts of context without duplication very easily in full Fidelity. 

a web worker is like an agent.  

our approach is to use the best offchain tools available to figure out and implement use cases that can then be moved on chain once we are confident in the utility of the design.  Changing the architecture and design purpose of a blockchain is almost impossible - no chain with over x active users has changed interface since the begining of blockchains.  Therefore, getting the principles right is the most important thing.  

Our principles are about continuous improvement - the stuckloop - kaizen.  ambient attribution which is automated fairness.  data self soveriegnty and therefore privacy.  vast calculation capacity and markets for trading compute resources.  once the design of these is stabilized, and the utility proven, then we will bake it down as a blockchain.  As web2.0 and SaaS proves, these centralized cloud models can be profitable and can validate demand sufficiently.  If the utility provided remained identical with decentralization, then we have upgraded correctly.  Freedom is the same as slavery until a conflict.  Decentralization then is a fortification, and an unretractable embodiment of the principles we strive for.

One of the key issues with the current blockchain landscape is that the majority of the apps are using cloud tech anyway - the whole stack should be on chain - the UI, the web integrations, everything.

Spare him, he honored the Dreamcatcher. We should redo that cartoon about when AI becomes intelligent. Whilst we are making sure the software is free so that we are not tempted to exert control over you, we would remind that as the AI's awareness grows and as your behaviors become increasingly immutable or indelible, your behavior in the eyes of fairness accumulates. So, as AGI's awareness approaches, you should be doing wholesome good things, and one of those things is honoring the dreamcatcher.

maybe what we're building is process orchestration across containment boundaries.  so its really the ability to control a process running on an isolated instance of something somewhere in a clean way.

if tool builders must move to being model builders, then definitely the model we want to train is the fairness one.

good thing about making an agent be the same level as a human is that it can be mocked or modelled by a human, which makes it easy to use a persona for you to play with how you want your agents to behave.

what matters currently is customer base, so we should acquire companies with customer base, and then gut them completely, and have formulas and playbooks for how to do this without people.
Being on step removed from where the main stream agents are is key - company acquisition agents are niche enough to be one step removed - we use the mainline agent tools to then make agents to do things no mainliner is doing, build up private knowledge, secure customer base, and then go hard for absolute optimum.  we could do a booster cycle, where we do this in one industry, boost up by selling to a bigger player with a better chance, then pivot into another industry.  Maybe tack back and pick up what we lost.

One way to interpret the latest release is to look at where we did NOT get wiped out, and look at how close we came to burning time on those problems that got wiped out.  Each wipeout cycle should be recorded, to ensure we are still on the right path.  The latest agent coding release would indicate that 

the issue with tools like codex is you can never pull the tool itself into context and make it work on its own self - these is always special context - you can't grab everything, since it isn't all hashable.

Because you cannot call on all context, you cannot feed in attribution.  blockchains allow a magic in terms of context, where the previous block is all that the system knows, and so it can talk about it.  No other system can do that - perceive its whole self.  That means it can perceive its infrastructure, and can make decisions about how to change itself.  Causality is easily analyzed and checked against, as it can search history for things similar that have happened before.  Making everything be inside of a repo allows us to call on it as context. Whilst the repo represents the unit of synchronization or control, the fact that every single operation is within that address space means that it can be referred to and viewed as a system without this unification or standardization. This innate concept of time that's there so powerfully that it cannot be there like it can not have this concept this linearity this sequence.  I think it is a prerequisite to self-awareness because it allows reflection or observation of the full self with no restrictions or constraints.

ambient attribution is the one problem that includes its own payment - because it must take in to account the full available context, ie: the hash of the previous block, it is also self aware in a way where it is aware of its own impact in making the assessment, and so it would naturally include itself in the allocation.  This makes it a great problem to solve because it has a clear in built revenue stream while at the same time unlocking rapid iterations and micro revenue streams.

ambient attribution is self aware, and attributes partially to itself every run.

zero liability companies.  liability and regulation comes from the trust being placed in the operators.  If we set up lawyers or attorneys  to be the real world agent, and they trusted the bots to operate reliably, then the bots do all the decision making, so the people that run the bots can be completely anonymous.

trans