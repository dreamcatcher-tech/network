
>[!tip] Created: [2023-10-10 Tue 14:22]

>[!question] Targets: 

>[!danger] Depends: 

It just feels like gpt4 has some kind of mastery of the sae substance that we use to think - like it has a form of general intelligence or logical correctness so that any random proposal can be ranked by it for fitness.

With an arrange of self checks and reflection, this spark should be enough to accomplish almost any mundane task a human might wish to perform.

Fruit seeking to be tastier so they increase their consumption is no different from us fine tuning our apps to have the best taste.  Just seems other factors affect the spread rates beyond just taste.

The data change rate can be less with AI, so git might be fine as a hash based filesystem, instead of interblock ?

Coverage has a different meaning in semantic land - semantic coverage.

To win in the AI transformation, a company must slash its headcount down to almost nothing, and then they must commit to sharing the profits fairly amongst all who contribute - administrative control allows inequity - if this is handed over to the machine, only then can match the pace of change of those who committed fully.  So earliest to commit and fastest to evangelize wins.

3 points:
1. we can make the managers use the AI to let us train it more, as well they can say what they expect
2. can use the accountancy flag as a means to inject into other areas of the business
3. fairness is the key here, which encompasses transparency, but also with comparison to market
4. we can loop thru rows of data, fairly mercilessly
5. there's a massive upset coming, we don't want to be on the wrong side of it
6. this anything app applies to you, but also applies to your customers
7. ultimately we could let them operate with no books, using our system to replace theirs - how much do you struggle with the xero structure, and how much do customers do so ?  We can make our own books app, even

If you have enough intelligence to operate in natural language, then you can operate in mechanical terms like counts, scores, and other useful things, but most importantly you can defend your decision. 

The whole trick seems to be ways to break large tasks down to something that fits in the context window, like a skill or a strategy.

Aliasing could be discovered by a sliding window and comparing the outputs as being meaningfully different, depending on where the window went.

The anything app should be programmed within the anything app.  The more is built outside, the more problems we have to deal with outside the core app.  Ultimately it would be come free floating on the app store, be forked, and so it would be unrecognizable as the starting point.

must be careful not to develop anything the MS or others are making, as they will win that game.  We all know the interface we want now, and so we should focus on applying it to loop in chain, to make apps at the fastest possible rate, which is faster than a human, and near instant.  None of their offerings appear to be a social network, nor an application framework.  We aim to have our own native AIs running on chain, which can be done in stripped down models once the use case is clear.

Does consensus need to be precisely arrived at by formula, or is it simply agreement on a result, without regard to how it got there ?  If all parties agree, that should be enough. This is no different to the initial state being agreed to, but it just goes on forever in this way.

Typescript is suddenly important in AI since it needs feedback on why what it did was wrong.

Because we can replace whole npm packages with AI processing of strings, this is why we can start to decompile the software industry and reduce its moving parts.  Using an AI as a "all npm packages" type of arrangement 

Passing the turing test means they can fake any authentication intended for a human, except they cannot fake a crypto signature.al the

The general theme seems to be places where information was cumbersome to process, took more than 5 mins, and required interactions with multiple companies - we can terraform these interactions into something streamlined.  We can accept liability as the orderer between multiple companies so that we can handle the fallout automatically too, which gives consumers a better experience.

The safe place is something independent of how the AI models evolve.  They will still need to be instructed, contained, audited, interfaced with humans, governed by rule sets.

Being a model provider is a dangerous game, since you can be displaced by a better model and the switching using systems like ours will be nearly instant.  You have to keep winning for a long time.  Ultimately open source shared models will win, as they have more gracious access to data and absorb all the open innovations into on place.

The AI should be treated just like a human, and it should have to pay for its access to our data.

Component based prompt systems

Instead of workflows that we once dreamed of for governing blockchain systems, we need a way to make AI generated workflows that call different ai powered components with a blockchain substrate underneath providing permanent memory, correctness, and mechanical query ability.  

Facts about data systems should be from retrieval systems, facts about knowledge base should use embeddings and use citations and backchecking until factual.

Preloaded chats should be for style, not for information injection.

AI will always be better at smaller tasks than bigger ones.  At small tasks, it beats humans - lets build on that.  Humans can't do big tasks in a single shot anyway.  We need structures.

Start to look like meaning shifting is the switchboard operator of old, replaced entirely by automation.  Much knowledge / admin work is simply moving meaning around / routing / switching it, when this should be done by a machine.

AI finally allows us to make a system that is rejuvinating - it gets better over time, not worse.

Descriptive naming is now more important than ever, since the AI needs to extract meaning from as much as possible, so the names of the paths in the filesystem need to be important, and a description against each path can help the AI greatly.  Each object should continually have a summary that describes its class behaviour and the data inside it, and how its history has changed.  The AI does the filesystem maintenance to maintain descriptive naming.

The web is dead.  The web was the explosion of context for humanity, and now we have a context gobbler.  Also giving info away in exchange for ads that corrupt that info is no longer relevant to an AI.  So the monetization is dead.  Advertising relies on human processing.  The web is about to fall.

Natural language interfaces make technology accessible.

The tooling is so general and so powerful that the incentive to build an open source version is tremendously strong.

Seems hard to keep it closed how it worked in the background - the steps being shared seems important to building high quality tools, so it will likely always stay openish.

AI makes transitioning systems effortless.  So all else being equal, you'd rather have a blockchain system than a conventional.  Also connecting to existing systems is effortless too now.

Bot to Bot chat helps to keep the context narrow - if each bot only sees that chat that it has had with its higher up, then it can remain focused on the current task.  In this way the parent has handled a lot of work to filter the chat down.

The AI apps are worthless - they are of ultimate and perfect utility, and renew themselves endlessly to correct and expand their abilities, but they are so cheap as to be free.  The value is in the commerce they enable - the trade between parties in this highly developed perfectly intelligent world.

The computer is like the stateboard, and HAL will do all the tab switching and searching, you just stream your consciousness in, combined with the odd click on the focused application surface.

AGI must be interactively taught - it cannot appear from a static set of a data and running a formula on it.  It must be walked thru things, and must show its thinking, which is how humans do things - we have this base intelligence that we don't really know how it works but it does, and then we learn strategies to maximize and specialize what it does.

I think that every time you ask for a specific tone or stance, that should be done as a separate pass - I think it is weak to expect it to do that in one shot - it means that the assessor is automatically running on each output, and then contributing a revision with a single purpose.

We should make an adversarial workbench where multiple users try to convince the arbitrator that they are worth different amounts of attribution.  Then an assessor tries to make a ruling on who is right.  This whole fight might be the way all the attribution is run anyway, where each user sim summarizes the main points they fought for, so the human knows they were defended in a good way.  If the user wants to extend this contention, then they have a great base to start from.  And then anyone who makes better points from some secret machine they built, those concepts will soon be ingested and balanced in the attribution system for future rulings.  Incentivize putting new points forwards by paying commission out to people that increase your share, and then that knowledge is absorbed into the broader body of knowledge.  Then make a simple bot that rules on the output that can be near plain gpt4.  

Ultimately the fair programming of an AI would be a deterministically trainable system with an agreed training set.  So we all see how it gets made, and then we use the results without wondering how it got to those results.

If we had a public GPU chain, then trade embargos on hardware don't make sense, more people have greater access to this scarce resource, and we take a revenue cut of all the trading.

Principle of the pipeline for attribution being the same, but what happens within being open.

Great getting the AI to drive, since forces us to make errors that make sense to a human - this is what the AI needs.

Interested is as interested does - what a person says their interests are, and what their actions imply are often different.  A goal oriented social network will cause people to align based on interests, both stated and unstated.  We should be able to show a friends list in the stateboard.

Artifact is being coded for AI to drive it, not really for developers.  If devs do get involved, the artifact involvement will be so heavy that the devs will largely just suggest natural language hints and gpt4 will do the coding work as the jobs are so small since they are for a single function, and operate strictly on schemas.

We are making an AI native operating system.  It has social networking and AI collaboration built in, and is built atop blockchain.  Tooling for other OS is made to combat the limitations of human coders, but AI has different limitations.  Native for AI means highly focused highly testable units - AI can make tests endlessly, but it is the size of any single task that stops it.

Making a framework designed to be programmed by an AI means that humans using it will be far more productive.  Ideally they would be just the users giving natural language feedback, but as the coders we would have the AI much deeper integrated into our work, where it would work on many components for us and we would help out with approaches to try and guidance, rather than the actual code.

In an AI first framework, it should be able to know when it wants to use exotic resources like making calls to a quantum computer.  Quantum resources would be presented into the universal computing surface as a standard API, with some background checking where we run the same computations in classical form, to be able to verify they are correct, with some staking being required to be able to publish quantum resources.

Can use the SSL cert keys as a means of signing off on the chain, so something like github CI actions can run the next pulse, and this inadvertently leads trust to the chain, since it ran in a guaranteed safe environment.

So we'll all end up treating AI as the computer, and object oriented programming will go the way that assembly language went.

Apps then become more a dynamic assemblage of tools.  This is in effect what you are doing when you use your computer using more than one application plus maybe a web browser to accomplish some task.

Making ourselves the framework for building AI dapps, where the users and the builders all use the same tools - goalspace.  Then we can offer hosting services, build services.

Function parameter calling does not handle deep nesting well - the flatter the better.

To make AGI, you need to know your user intimately, which means self sovereign data.  You also need to convince them that you're acting with their best interests at heart, which means you need auditable and sandboxed AI operations.

GAG - goal augmented generation.  Makes it like a programmable RAG, where even the users can interact with the RAG to refine it using plain text, and have the machine assist and test the output, and condense the output to be minimal, so they can move forwards with confidence.

Logprobs seem related to hallucinations - hallucinations should show a low confidence, and should be a trigger to do something about it, since we know the response was weak.  We should store the response logprobs so when debugging we can highlight areas of low confidence where some resurrection process should have triggered, like backtracking, an extra retrieval, some extra questions.

dynamic LLMs come next, where based on their interactions, they can move their own behaviours forwards.  Given a mechanism to rollback and retry when the outcome is not as desired is all they need.

AGI should be global.  Its thought processes should be transparent and auditable.  Its operation should be well understood by all, as an elementary school subject.  We should all be interacting with it each day, and it should improve based on each interaction.

Fallacy may be to try to form a distinct company with a set goal - if we are in a wildly innovative time, then really our values are all we have that is constant.  If we seek AI controlled fairness, and set up the system so we are able to focus on whatever we think is the most important aspect, then we should be free to roam the landscape as best we see fit.

If we can demonstrate an end to end system that has all the skeletal qualities of the system we want to build, this should suffice as a raise target.

If you are not storing your data in NL and writing your programs in NL then you will get overpaced by LLM native operations.  We should abandon all our code that was for machines, and use just the pinnacle, which is these LLMs.  We have git for integrity, and we have limitless files.

The idea of the Dreamcatcher is to make humans in the loop to label our data simply by their behaviour, since incentives are put against the data which can be used as training weights.

If the system is anything but the simplest most easy to understand thing for a human, it won't work well with an LLM, and there will be bits that are hard to explain to the human.  We should probably adopt much of git, since these llm will know a lot about how git works, and how filesystems work.

The more we can do things in NL, the less we have to deal with function calling and the inherent phase switch.  Models will keep getting faster and have bigger context windows.  Also means that if checks were being done based on NL, then when they error or fault, the model knows how to explain itself better, rather than when a machine ran it and we have to make a good error message and explain it.  The check being in NL contains a good description within itself, rather than being required to provide one.

You should always be running your own independent AI, and it negotiates a merge with your changes to and from other peers, depending on your needs, so you're never really alone.

The connection between business exit planning and tech is massively high - anyone looking to exit is doing a special kind of merger & acquisition, and bundling tech in makes a huge difference.

Its the number of contracts and things on the chain that make it valuable.  If we are so easy to program for and to do so safely, then we can expand faster than anything on earth before.

These sort of "everything functions" that all do something a little different, so we need a way to tie them all  together, probably using some self hosted open source LLM to manage it all.

Git is the perfect model for all threading, be it humans of machines.

Just imagine it is a human with a large stack of paper cards.  Time is irrelevant, and the human goes around reading instructions and carrying them out.  There are some special functions the human has, like transmit the card to an address, receive a message, vector search a message.  The human can generate new outputs creatively, based on instructions.

Open source but AI, means we can charge for the execution of the AI.  If you had to pay someone, you might as well pay us, since we always tweak it and the quality is important to us.  So on our public chain, many open source apps get run for small fees.  A margin will appear where routing openai api calls reliably has a market agreed level of price for performance.  Latency and uptime matter, plus being a backup with instant availability is important too.  Geodistributed costs as well.

The chain joining protocol was really just a way to do fast forward merges with no conflicts, where a conflicted merge means something hostile.  This is the interface between machine and NL.  some can be parallel, some with a limit, some sequentially.
The chain joining protocol was really just a way to do fast forward merges with no conflicts, where a conflicted merge means something hostile.

Its really replicating git commits with BFT, and allows execution of code that can be repeated and agreed upon.  Being git native tho, we can instantly plug in to almost every code repo on the planet and start to host it and draw from it to run.  Being AI native it avoids the systemic complexity that plagues distributed software, and instead is programmed using natural language for its core, but also for any other uses people may wish for.  Faults on the chain are really only as common as faults in git, which is fairly well tested.

An interpreted / executed git repo

The machinery is small but strong - we need very little compute to run AI cored apps, but that infrastructure needs to be hardened.

The filesystem is the common abstraction between all systems, so to carry it with us eases integration heavily

The new model makes everything a side effect, even chain reducers - they all run the exact same way.

Artifact is the user that is the kernel of the system
it is the blockchain that does the low level stuff that AI uses

Theres something about git that makes it the perfect way to model interprocess communication.

A session is a process, not a file, and therefore is stored on a branch

All of the HAL repo is the execution environment, really - execution heavy since this is what the user does.  Remote repos will likely be less execution focused and more data focused.

dispatch and pierce seem to be the same now

May have been that we went too deep on processes and storage - not all storage needs to have a process related to it, only some of it.

The linux kernel is hand written - next comes machine written kernels.  These would be copied from the linux kernel, but they would be chatted with in NL and the code built up in this way.  Finally, the hardware will be changed to better fit the paradigm.  If we could make our own kernel, we should be able to get highly favourable performance for our git based threading model, with maximally utilized resources.  The AI can keep the drivers up to date, and can even be used to develop hardware with, since the driver writing seems often repetitive.

If you can write as much of the platform in NL using the smallest number of primitive tools, then we would show everyone what the platform is capable of, we would make the platform able to explain itself, and we would let our users see inside it.  We would be using our own tooling daily, and would finally be free from the burdens of coding and maintenance of code.

We're making an NL programming platform that can be used to write itself.  It can transact in value and can operate in a consensus resistant way with strong corruption detection.

We want to land with some good strong social features, using github as the overlay network, since we can just see all the forks of our core repo and stitch them all together.  So we can appear to be growing our network rapidly but we're leveraging existing web2.0 tooling and scale.

a submarine control room where it sounds like all the commands are being repeated, but what's happening is that NL is used by the captain to talk to the officers, and they use NL back, but they operate their specific tools and report results from those tools in NL.  This is what the swarm of specialist bots would look like.

Our goal is to be able to build the whole system using the NL programming tools themselves.  Very few things should be part of the platform.  The definition of some crucial objects, like isolates and helps and goals and runners.

the safe bet in AI is to make things that benefit as the AI gets better.

the weird part is moving into a development model where I no longer have the tools I am accustomed to, like jest, and other test frameworks.

AI Experience - AX - which makes us define tasks and software to give the AIs a better experience so we get better faster cheaper results.
eg: making a list of options and asking the AI to pick one, and maybe fill in some blanks, rather than labouring on outputting a full sentence.  Needs to consider helping minimize hallucinations with error feedback.

The commit model is excellent, as the AI can tear, or not finish some work, but without a commit nothing will have been altered.

If you were going to make a global distributed database for all humans, it probably would be a plaintext db.

It is because the fix loop is endless, where we just want more and more features and more and more granularity, that we need the Dreamcatcher - the amount of preferences and operations that humans want of this system is too vast for a central system to attain.  The inputs could literally be anything, and the inputs are not one to one, as each individual expects something different from the same input.  Add to this the pillar of privacy for each individual and we see an opportunity to make a vast system of extraordinary high fidelity to constantly meet every individuals needs as their servant.

Git is strong binary differences between things - cryptographically secure difference detection - whereas AI is strongly semantic / meaning differences.  Somehwere in between is humans, which is where the mess lies

NL code is executable by a human, so we don't need machine consensus, we can just do the checks by hand, worst case, since the results should make sense.  NL coding with repeatability.

Seems like the web is going first class multithread, with functions like weblocks api and others.  Deno deploy takes this to the extreme with practically unlimited workers.

No long logical machinery - probabilistic machinery

Deno tsx acts like a babel layer where they can add experimental features without tampering with v8 and what features it supports.

From here on in, the adoption rates of tech will always be vertical, since AI will make the adoption choices for us.

We're trying to make a high performance github implementation, where the git repos represent distributed repeatable execution, highly focused around AI operations.  Github could provide a similar feature, but that suits us, since the primary push for us is ambient attribution - high performance git is a prerequisite for achieving that.  Then we want to push for a decentralized solution, since this is where our revenue model thrives, and it is unlikely that github will switch to a decentralized model, as we see scant examples of large companies switching models like this - they tend to get hooked on centralized if it is working for them.

All these companies are so mutable, and opaque even to themselves - how can they be efficient - how can anything get done and stay done ?  how can anyone have awareness of its operations, much less its owners, workers, and customers ?

AI has little to do with repeatability of computation, but it makes it easier to make a repeatable system, since the query and execution pieces become significantly simpler, so the repeatability can be focused on more.  If the LLM knows about repeatability, and the functions of git, then it can guide the users thru what could otherwise be a calamatous UI.

The filesystem would be the perfect database if it was single threaded and reliable.

If AI agents are like computerized humans, then git provides the perfect means for their collaboration.  We use a git compatible modified version to track execution progress.

As nvidia has shown, we are moving towards AI running on peoples desktops in what used to be graphics cards.

With AI trading bots, it becomes not how to code a strategy, but how to spot a strategy.  Each strategy only seems to play for a short period of time before it disappears.

NL appeared thousands of years ago - long before math or physics - it is the most native thing to our minds, but it also could be a while until we get physics models.  The physics models would always need to be fronted by an LLM

Adversarial agent networks - this is decentralized consensus

Measurement of AGI is the number of human interventions required in the stuckloop.

Where to come for supression free artificial intelligence.  Freedom intelligence.  Launch a dark chain, where any models can be run, as well as huge training capacities.

AI live means that we can run in any language easily, and people can share languages within the same system.  

Some businesses are cheaper to start from zero than gut existing ones.  Banks being a good example.  Once the ability to run a company using AI as the admin is known, the race will be who can start from scratch the fastest.  Early is good, heavily funded is good.  Hiring the staff of a collapsed bank, so they know the ropes is good.  Early seems great, as can get more funding earlier, customers, lessons - almost no downsides if were pure AI, since no staff when we need to pivot, and always learning from all the AI lessons from all our other ventures.

If we can make our own stock exchange, and can list our acquired companies, using our own bank for trading and kyc, members can use our services to grow at probably the fastest rates possible.  Would be like the ICO boom, but legit, and intelligent, and wholesome.

Once we can demonstrate on deno deploy how we can make any app, we should start to fundraise for building a decentralized version of deno deploy that we can sell cheaper and have higher margins once deno deploy is removed from the equation.

Perhaps the amount of novel information entering the system will go down, post AI ?  Prior, human interactions were not captured directly, but rather the results of their interactions.  By capturing text, we get closer to the actual novel information from the human, not further down the causal flow, which should be less info all up.  What they want is usually very small and simple, rather than capturing how they went about getting it in a complicated machine.

There must be a correlation between the lack of repeatability of a programming domain and the cost / expertise required to operate in that domain.  Lack of repeatability is smallest in the web, and hardest in things like live server maintenance.

The repeatable API service - consistency is the only truth - repeatability is consistency.  Repeatability is trust.  Turning APIs into something that becomes repeatable, which makes them reliable and simple to call.  Pushing back the wavefront of repeatable computing.

No matter what, AI will always need to be trained and reasoned with, as we walk it thru our specific use cases, and use our instance data which can be private.

Maybe AI advertising is having earnest agents that can shop for you ?  These agents work for your benefit, and browse catalogs and AI reviews to find what suits you best.  Suggesting is a privileged position now, and not to be purchased.  Bots for free that advise on items will be useful.  Marketplaces for AI agents that can broker complex deals rapidly will be best - there simply isn't enough margin for forced advertising to operate any more, as the margins for goods need to be near zero.

Git is the perfect filesystem, and should be the basis of all knowledge retrieval systems.  The design has the ability to scale to any amount.  Gits design goals and optimization problems are exactly the same as ours - we can benefit from any gains they have.  Their readers and visualizers mean our data format is known as open and people can feel confident that we are operating in the clear with a well understood format.

Git is the foundational integrity software of the internet - it is responsible for the integrity of the linux kernel, which is responsible for the majority of computational integrity around the world.

If all these ai startups are simply prompting and connecting things to openai models, then we should be the core platform where people come to rapidly build any such tool.  Being open it should be faster to converge than others, and with a single clear billing and royalty model, it should be superior.

[[2024-03-28 1502 illustrate fundamental principles by digesting every day usage problems|Teachable Moments]] are everywhere in AI based interactions

Plain text computing.

Who ever can make an AI marketplace, and make it handle external suppliers like amazon - they will win.  It seems destiny that amazon will be simply a servant to the AIs - they could never make their own AI that people would use, they would need to plug into these AIs that people choose to use.  So a services bridging company that sits in between at the start might be needed.  Such a tool would have insights to the very thoughts of its users - far deeper reach than any social network, and possibly any human - god like, in fact.

Funny that git makes the linux kernel, and now using git, we can make the linux kernel multi node and coordinate its operations.

AI is enabling perfect decompilation of knowledge works.

AI has the same power as blockchain of removing intermediaries.
Combined with repeatability of blockchain for trust enhancements, AI can further remove intermediaries that exist because of a labour cost.

"My AI will talk to your AI and we'll get back to you."

The reason we needed artifact was to a lot of AI calls very quickly and exactly once.  We needed repeatability so we could agree about what was to happen next.

We should embrace the lack of lockin the AI gives us, since format is no moat any more

The package management should be part of the source control system.  It is time to upgrade git, and the upgrade is to make it multi repo and executable capable.  Instead of PRs, I should be able to edit portions of the code directly, on the same platform as the main executable, and they get included in the test suite and solved.  They should be able to be run in a massively parallel fashion, not requiring a single processor to control activity and consistency.  Multi processor consistency.
I should be able to edit the dependency code in packages I consume as easily as I edit my own.  The remote should accept and test my forks using AI, not having to wait for a human - humans shouldn't really be in charge of publishing code.

All island nations reconcile with the environment or die.  As a planet, we are about to enter the island phase, where we are forced to reconcile with the finity of our resources.

The time of fixed outputs is over - nobody wants a blog post any more - what they want is a live AI output customized for their exact needs on the fly.

Github is where repos get stored, but Artifact is where they are operated on - we replace the users computer.

A fallacy of venture is that people prefer doing something to doing nothing.  Speed of iteration wins, but iteration might not always be fastest by taking action - skipping some cycles can be faster.

Artifact in the cloud aims to be a replacement for your computer.

The dreamcatcher ooda loop is fastest since it is at the edge.  The iterative improvements are done by AI, in collaboration with the customer, as they are working - the iterative improvement is built in to everything.

You will always want to have access to your data easily, and you'll always want it in text format so it is compatible and plain.  You will always want repeatability so you can have audit trails on your data, and who interacted with it and how it came to be.  You will always want integrity and availability, and you will have an insatiable requirement for parallel compute on your data, including AI calculations upon it.  You will always want to express your demands in NL.  If we build our systems to target these always things, we will win.  You might not always want to treat others fairly, but you will always want to be treated fairly yourself.  You will always value things in more dimensions than just money.

It is a safe place to claim the space of being LLM attribution systems - humans will always seek to have complete attribution mapped out.  They will always argue as to exactly how what the pieces are, but they will always want full visibility, full attribution, far beyond just money.

Refinemint - re minting things that have come before.

The demand for intelligence is insatiable - we will always want more, and there will never be enough for all the needs of people.  So a platform that can pull at this insatiable rate is crucial.

A transaction in Artifact is a calculation in a dedicated cpu instance.  How many of these can we call on at once is the key offering - we provide a way for you to consume AI at a rate far greater than any single machine, but we make it manageable by a conversant interface.

We base our stance on teaching AI - making machines with innate intelligence doesn't mean they will know how to do your exact task - the customization of the AI specifically for a human or group - the mass market of one.

Make the dreamcatcher enough to use it to write the specs for artifact, prioritise and describe usages, then raise some capital to enable more of each use case.

Almost like a silencing of promotional noise where you can't speak on the broadcast channel unless everyones AIs have assessed all the information you are conveying.  Like SSL but for the information content within the comms.

Unbundling businesses is great for quality of the business, but the issue is controlling revenue.  Ambient Attribution is the system to ensure that an unbundled business still makes money for everyone, so it can stay profitable for all even after unbundling.

Many companies have proven  that a retail business can be built online, like allbirds.  If we could show that the design of the products could also be done online, and that an information component where the consumers contributed to the design of the product (kickstarter) then we could allow a whole store of products that had the same manufacturing properties (ethics, fair pricing, renewability, ability to make variants) which is similar to what artifact does to cloud computing.  The commonality is the need for uniform properties from a software defined product company, using AI to manage all the human comms from consumers and producers / designers, where the DAO in the middle is free floating and owned by no-one, but goaled to benefit the commons.

New communication mediums usually result in government changes and war.

Because our chain has intelligence within, it can report scams very quickly, and can apply its own intelligence for any fraudulent looking transactions.  The fraud checker is the same for the client as it is for the bank itself - the same intelligence is shared, and the same scores and metrics available to all.  Before you make any purchase, the fraud check runs, and it runs client side, not server side, so it feels like we are quick since you are doing the checking.  We trust the results of the client side fraud check since it ran on trusted hosting, and then we permit the transaction.

We don't charge by the hour, we charge by the unit of completed work, and we always enable an open market for that work to be done, in case our pricing is insufficient.  We preserve the market at all costs, switchability of choice is crucial.  The flip side is that all our work is available to resale and reuse, for a suitable royalty.

If the number of modules on npm is then multiplied by the number of deployments being generated, which should be at least 10, then there are an overwhelmingly large number of programs in the world.  This should be stored as NL state,

List our values and business rules in NL, so that prospective clients can lay out scenarios and we generate automated and binding responses.  Workers can do the same.  Basically if our AI says that's how the situation goes, then that's what we stick to, for better or worse.

AA enables types of change that do not have a direct reward, but require reward to make them happen.  If you only make changes that pay out to the doers of change directly, then you'll never get anything wholesome.

Taxation without information - our tax dollars should not go on proprietary systems.  Internally, we should produce open source software, funded by taxation, to keep all the funds inside the country, build exportable skills, and lower expenditure costs.

Multiuser multitenant AI native AI assisted applications.  Framework to very rapidly, with no code, launch an application that can provide utility and be shared with others, earning you fair reward.
Our license can be new, since AI coders don't know about software often, and so the license just needs to make sense to them.

Making repos executable is similar to what github did with ghactions, except we track the execution on branch as well.

Storage will never cost more than it does now.  Cost is a geometric decay.  Forever is the only time you want to store the data, then just delete it and free up energy.

Propose a high fidelity way of doing 'benefit to all who contribute' - using AI to indicate what contribution means, what the highest benefit to all are, and identifying who benefitted us at what time.  We should go search for any other company with similar ethos.  It is strange that this ethos appears with a highly technically advanced company, which indicates that lightness is the key.  Possibly charities benefit most from this ?

Customization is the thing to sell - when a software needs no more changes, it is dead.  Capitalize on the change, not the core.  Pay people royalty for financing changes, and encourage them to pay too, so they keep getting benefits.  Show what improvements they received and made use of to justify the payment.  If they build their own and share it, then they can project what they will earn back.

Write apps like a seed, where a blank system with only a few tools can be used to develop a working system based on just a small droplet in the top.  It is better this way as it makes a more adaptive system, rather than something brittle that was set up front.  Leverages the knowledge inate in an LLM.  Builds on the seed guidances

The fundamental theory of seed apps is that the LLM contains within it all possible apps already, and it needs to have the structure teased out of it and stored permanently for repeatable uses of the same kind.  So a CRM is already in there, but it is just pure knowledge - it needs focus.

Negative attribution - Can't have your cake and not do a poo.

By using git, we can allow the model to speculatively make a bunch of changes in the background, so you can see what they look like before you merge them in, but so that when you do agree to merge, it is near instant, since work has been done speculatively.  Branching production is key to this ability.

Artifact is an app hosting platform that is multitenant, multi user, multisession, and multiapp.

Self sovereign implies contained - you cannot be self sovereign unless your data is in a compact modular form, that can be verified for integrity, and can be provably complete.  Making our system like this from the ground up was significant engineering effort, but the self sovereign model is one worth fighting for, to occupy the trusted position as personal AI.

Should you pay is simple - if you don't, here's the impact, and your products will fail to grow.

So the humans are modelled as not really different from AI nodes - they have the same input tools as the AI does.  They can navigate around the threads widget and start inputing at any point causing a fork.
So the user can be simulated by an AI which can run in a forked sandbox and demonstrate jumping around the place, navigating different threads, and generally fuzzing around, so we can see it work, then the actual user can jump in and try different things as tho they were the user.

A gigablock per second is the ability to process a billion commits per second.

The git model allows anyone to see all the executing processes within their app, so they can understand how it works, stop it, reverse it, set it to wait for their approval before merge - complete control of the services the system is managing.

Given the inference nature of AI, the only way to test an AI system is with extreme load testing where the machine generates many permutations of the same them, attempting to fully exercise the system in all aspects.  Coding them up by hand are too error prone, and making changes is impossible to know if you broke something else, as soon as requirements get large, or are shared between multiple stakeholders.

We aim to be the most compliant platform in the world whilst being the least intrusive and lowest friction by the use of personal AI agents that transparently work on your behalf to meet all compliance.  Not doing compliance is actually intrusive since the instrusion is being deferred and can have criminal implications.  The path of least intrusion is radical compliance.  Do something ocne and it stays done.  Be compliant once, stay compliant.  Draw on a pool of those who can defend you like an insurance system, where all who behave the same defend each other, making a far costlier target to harass with vague and arbitrary rule enforcements.

If the CRM is a coordinated effort to improve a single set of files, then the Dreamcatcher is a coordinated effort to push forwards a set of files representing innovation.  Innovation is a fileset, and increasing the rate is to increase how fast these files are expanded with quality innovation.  Anything we do to accelerate this will be good.

Git defines fundamentals of concurrent information processing, which in its simplest form is quite difficult.  AI gives us a way to make this nice and simple to work with.

We're coming into a time when psychological models of AI will be given to us to control and dial up and down.  These will be similar to human models, since we need to them interact with human models in the way we want.

Holding a thought clearly, in the face of change, over a long period of time is powerful.  If this AI could do that for our company goals, then we should be able to enact change at an org level at near peak speed.

The age of static text is over.  You can now pass the interpretation along with the document, avoiding interpretation being separate and subject to perversion.  We no longer pass on knowledge / records, but intelligence.

Age of AI constrcuted things that are FEA analyzed and manufactured swiftly is coming.  This means houses are cheap and fast, machinery cheap and fast and exceptional high quality.

If we can get in a position where an increase in model capability causes our users to like using us more, this is the safest spot to be.  If we collaborate with our users to build something of benefit to all, then we should grow quickly.  The proprietary data of users is the most valuable thing in the AI struggles.

Why switch from blockchain to AI - blockchain was always a conduit for valuable information to flow on, AI is simply highly valuable information, and so the switch has been what we carry.  We can carry any kind of info, blockchain is about a data structure that is decentralized in nature, and a set of design principles that enshrine self sovereign computing.

Any system that can do a days work and then be rerun on a different machine and get the exact same hash of the outputs - surely that data structure must be correct ?  If we required consensus between the recipient and at least one other machine, then we can know we can verify the system.
Each night, run a verification from a day away behind, to ensure we can always catch up.

Limitation of profit - everyone should be rewarded for their efforts, but without DAO based control on this, we run the risk of greed choking opportunities that would otherwise flourish under fair rule

If we can compete with closed data companies on features as an AI platform, then we can surely win with a self sovereign data model under the hood that includes execution.
If you self sovereign data model does not include execution, then it is of limited value to you since you cannot use the data anywhere other than the vendor without a lot of labour.  We give you all the tools to run it yourself, in fact we encourage it, as our business model depends on intelligence approaching fairness, and not on forced payment.  Intelligence and awareness as the pressure to pay.  The more aware we become, the more we approach fair - this trend appears to be accelerating.

By being programmable in natural language, we should allow any new theory of AI to be rapidly iterated on and then benchmarked.  The speed can then be put into code by humans or by AI assisting humans.  We should present  these implementations along with the papers that describe them so that people can fork them and use them in their own concoctions.

Make an inventor bot that always tries to invent things that a derived from whatever you're doing, so that being stored in a retrieval system or published, which makes it prior art, and can block patents instantly.  If we run these patent deleting things rapidly, then more things are public domain.

Simple plain open formats - plain text everything - these are important for information.  Proprietary formats are always about performance or program access like SQL.  We should go thru every file format and see what the reasons for the format is, and compare to plain text running thru AI.

Once AI can pass turing, then you can't shield services from AIs since you couldn't know it was a stupid human or a smart bot.  There is significant overlap between the smartest AIs and the dumbest users.

Having the execution and storage environment as git is like having all the virtual machines, the cloud config, and the database, all backed up as one thing, and very nimble and transportable.  So we make the infrastructure instantly forkable, and committed to git each operation.  The complete infrastructure including the data is in a single data structure.

Cross cutting - is there something about how capitalism causes vertical structures, but the most efficient coordinations come from cross domain coordination ?  Where the incentive is the health of the whole, not the health of the individual vertical.  Pure greed makes vertical structures, wholesome things are small and many.

Once we have fairness as a calculation, and once different business occupy the fairness position, there is no further optimization possible.  Even just to calculate fair means the system has its inefficiencies described, and so it will be optimized very shortly.  Such a system would never be displaced, since there is no way to be better, and no yearning from the masses to be free of a system that sort of works but is corrupted.

The worst form of corruption is that which is not enough to warrant system overhaul or cause system collapse.  We should be able to model each person and show the flow of information, and see at what point things are bad enough for them to revolt.

Can we exhaustively search for all possible scams, such as penny auctions and other such fallacies, so we can detect and police them better ?  Surely there is a universal say to classify these things, so we can give clear guidance ?

Innovation is about improving efficiency, no matter how small.  Also increasing freedoms, as in the opportunity that a person has access to.  At this level, people are mostly looking for the problem to be solved rather than to profit from the problem.  Patentable IP generation is where the problem itself is expected to be profitable.  The vast majority of innovation, and in terms of revenue, is possible at the small business level.  Anything that involves a spreadsheet or an email is this kind of problem.  It means the data is not alive and connected.

Artifact provides database, compute, networking, in a modular and portable way.  A standard format for infrastructure.

Artifact aims to express any system you want using only text files and AI models.  The models increase rapidly, but the text files should be permanent.

Compare the Artifact data format to Ethereum - to access that data format you need significant tooling, but to interpret it, you need quite advanced almost binary level abilities.  Worse, when you go to program for it, it is this difficult language where you can still make some really bad errors in.  AI models get better, and the safety of our systems gets better, so your natural language can be transformed into secure instructions with no ambiguity.  This becomes easy to understand for everyone, as well as understanding all the implications, like a legal contract that has been hammered severely.  It might even be a good system for writing and/or testing legal contracts, if it can determine all meaning and come up with ranges of outputs.

The artifact format of applications allows the db, the execution environment, the permissions, and the execution history with full logs, to be transportable, forkable.  Means we can go from cloud to local, and back again, and also do them concurrently, so the environments can netsplit, then join again.

To use this tool, to chart a course through the mire of rules, with only the machines hands being dirty.  To teach me of things I should know, to forecast danger and gains, to leave record of my path that it may benefit others, to see the struggles of others for benefit.  Drafting awkward emails.

The age of chatbots on websites is lost - what you need is to present your info rapidly for the users bots, since they will interrogate you and make a purchase decision or not.  Each person is going to have a dedicate agent of their own, and it will scour the web for them.

Strangely, using common metaphors gets best perf from the models, since they already know about these things.  Eg: git models means we can draw on huge knowledge without many words.
We always need to draw on prior knowledge as best we can.  We need the models help to amplify what it understands, so using the right metaphor with its help, to explain how our systems work, is crucial.

The internal bot should be the same as the external one that talks to customers - there should be no difference.  Helps make the system wholesome, but also spots issues quicker.

Traditional VC is predicated on many losses with a few huge wins.  The postures are geared around this.  But if we can reduce the chance of loss, and increase the chance of recycling waste, the capital can be spread more efficiently with less spike wins but greater average wins - more stability.

The fall of experts - having an LLM that can give certified and strongly backed up advice means the authority shifts now to those who can use the LLM best, rather than just pure authority.  Anyone can become an expert.  LLMs should be set up to quiz people in a way that the LLM certs the person as knowing and behaving in a sufficient way to be classed as an expert.   So people use the LLM to teach them and quiz them, then they sit a series of exams or complete enough experience, then they get these LLM degrees, and are also gifted the LLM along with their interactions with it as proof.  The certifiers just ensure that the data came in from the person themselves.  They periodically get tested to ensure continued competence.  We should do this for dreamcatcher knowledge skills first, like a quiz.

By coding LLMs, we don't need the data they provide us, we just need the config they supplied and the number of times they got a hit.  This is more valuable than the raw data, since if it worked on their raw data, it will work on others.  So we can let them keep all their data private, share their problems, and pay for solutions whilst sharing solutions with us.

Artifact, running on Deno, could allow easy state management for peoples apps, where we are effectively hosting their isolate functions, and managing all their state, so they can write apps very quickly.  We are in fact, providing a competitor to the Assistants API in openai, but with more nuanced state management.

Artifact modularity means that, even if the writes are considered verbose, this is also your backups and your snapshots, since no need to snapshot the whole VM or the raw disk state - just need to replicate the git structure.

Important that IT people trust git, so we already inherit a lot of trust

We are at the point or approaching soon, where the AI is suitable to be used to construct the uses of the AI, whereas previously it was conventional techniques being used to produce an AI embodiment.  If we aren't at that point now, it will be with GPT5.

Having a platform where we are the best place to launch any new idea using AI the fastest, we will win, since speed to launch, and speed to innovate.  So any new idea or feature, we can use our platform to rapidly iterate on, and we already have users and innovators.  We are seeing AI products come to market regularly, but they all seem to be a wrapper around the AI, for a specific use case.  We want to be able to handle all use cases.

The issue with the dreamcatcher is it aims to replace the current product development cycles, and so it is difficult to capture using traditional methods.  How would open source development plans be viewed in these ways ?

It is as tho the convention means of product development would kill off the dreamcatcher model.
What we wanted was a framework to rapidly build applications that were of use.  What we decided on as the greatest accelerant, was automated attribution.  Revamping the complete product development lifecycle, at the same time as providing novel tools.  This would normally be hard, but with the advent of AI, everyone is retooling, so we are in a reasonably fair position.

Files gives us a way of working on things removed from context.  We can drill in to them, but the key is to be able to work at layers of context, where we jump up and down depending on needs.  A single context level becomes too confusing for anyone to work in.

Being able to present single ui widgets is much easier than making all the widgets fit together in an application, since we can take radically different approaches to layout and concepts, plus can test it in its final form, rather than needing it to work cohesively.

Making scrappy widgets using markdown and some ai parsing means a working system can be put in place much sooner than a full blown UI tool.  We can learn about usage and adapt as needed, plus widgets can be made in isolation, rather than requiring specialized integration.  Using iFrames, the widgets do not even need to be trusted code as they can be run sandboxed.

In order that the incentives for products continue on past purchase event, we need a supply chain and design incentives designed around that.

The issue we have is we want a different model of attribution from the venture capital model.  We want a model that is network centric, and elminates the distinction between creator and consumer.
Everybody at Xinova should have worked in the network.
The network did not incent collaboration of solvers, of problem funding, and of resale.  The network was not a team.

The manufacturability of the apps is critical.  It is more important than the features of the apps.  The cost of software is about to hit the floor, so what is left then ? It is personal data, personal preference - networks, trust, reputation - fairness.

Especially for long burn projects - we need funding and attribution that works well for that, and factors in the risk and perserverence that occurs.

We know some future events are true - cheaper faster better smaller edge
Whilst it has been tempting at many times to raise capital the conventional way, our core goals can never be realized if our incentives are not aligned from the start.  We know how crushing explosive capital gain can be.

There is a time coming when the entry level for being a coder will be almost nothing, since everything is natural language.

SEO becomes AIO where the game is to get your product or service into the AIs knowledge base, like an npm package that it defaults to using.
In the AI we should be able to determine how it makes its decisions.

Basically we want a decentralized work management platform

Patents block progress - the owner shouldn't be able to say what can be done with, the government in effect should set the price due to them for usage, and it should be automatic, like a tax calculation.  We do not know the exact instantiations of the projects we want to do, but we do know how we want the attribution system to work.  Once we have a prototype of that, then we can start to accelerate.  This will be slow since it is a highly dependent thing - it needs many features first.

Identify fragmented industry that has passed an AI threshold, like lawnmowing might not be scalable since you need admin overhead, which makes it cost more than a single person.  So if we remove the admin overhead.  Ideally we would pool together multiple independent contractors.

Component complexity seems to stop larger projects, or make them unstable, like a good solid file explorer, it needs to support too many options, so cannot easily be held together.  May be some formula in there about the number of use cases vs difficulty of construction.  We could grab this data from npm and see what is the sweet spot.

Really just trying to capture that AI allows huge amounts of admin to be done automatically now, and we want to leverage that to run businesses.

If we can simply make the tools that guide and manage the company and investor relations, then we should be ready to work.

privacy and copyright are conflicting goals.  The proof of privacy is being able to pirate without repercussion, so long as it was done privately.  Cryptolockers cannot be paid for with stripe, so these kinds of hosters would need to be done using crypto.  So people should be able to run our software, and without our knowledge, do private things with it.  As a hoster, we need to ensure copyright compliance with any data we process, but others could run hosters that 

A hoster and a billing agent seem to go well together.

Why we have an overlap between a shared identity provider like raytio, is that we want to share innovation, and duplicate effort in innovation.  We want to combine universal concerns, like innovation, security, identity, payments, execution, data soveriegnty.  Raytio is trying to be a universal identity provider.

We are almost asking the AI how to make money, and how much to return to the investors.  We want to use it to do all the normal overhead of product development, and we want to use it to figure out our pricing, as well as how to do revenue shares to all who contributed, not just direct contributors.  Is it fair to get high returns from a well placed gamble ? maybe, but it is an unnecessary risk, and one that favours big players.  More players means more innovation.

From Sam Altman: 
	We have no current plans to make revenue.
	We have no idea how we may one day generate revenue.
	Um, we have made a soft promise to investors
	that once we've built this sort of
	generally intelligent system, um,
	basically, we will ask it
	to figure out a way to generate an investment return for you.
We want to get to the point where we can use our own tool to spec requirements, manage funds, and determine relative value of contributions.

When the stock is sold, how can we use the AI to determine the relative value of each funding amount, even tho the stock is set at a fixed number ?  Seems that we should be able to work that out, so that each individual can claim directly, or at least have the attribution tied to their stock, in a way that can be claimed by the individual.  The claims are collectable from another company, the gateway company.

Probably the hard thing about artifact is that it is a multithreading model for nodejs.  It also provides an isolated view into the filesystem as well, and allows moving files between the threads.

If the Dreamcatcher is a network of nodes running Artifact, then any given hoster can be responsible for the content provided within, and can run automatic content detection policies.  We can keep the execution secure, but can run our checkers on the contents in confidence.  We can kick of anyone not in compliance, but other hosters can offer cryptolocker type services.  Our network can connect to any other hoster, but we will blacklist hosters and content that is a problem.  The communications filters will block any banned materials.

If we make a framework that can compose any kind of ai tooling, like spreadsheets or anything else, then we should be able to outpace any specialist effort.  Particularly as we are lower cost, and we share with the consumers.  Plus we deliver faster.

A platform that manages the labour to make improvements to that platform will surely win.  Manages the quality of the experience with the platform, ensures only high quality labour is utilized, and always at best market rate.  The cut from the labour is what sustains the platform development.

Winning in YC would be capturing the startups as using our platform as their job board, or their equity management system.

Is the market for fairness about to explode ?  Do people want it, and they want it to be consumable, like tokens.  They want the fairness to have force, so it isn't advisory, but governing.
So many platform offerings struggle because of fair price setting being impossible to convince people of.  Also the platforms cannot merge easily, since they have different pricing setups, and different capital structures, and they don't mix.  But platforms with fair automated autonomous pricing and equity could merge effortlessly.

patents are stupid, since they block consumers having the best possible thing.  You should get paid for inventing, but fairly, in a way agreed to by everyone.

We have to be using tooling that was generated and improved by AI, else we will surely lag behind.  We seem to have settled well on the generation of sysprompts and the tests of these in response to human inputs.  Human inputs won't change, and expected outputs won't change, but the effort required to refine, and the amount of refinement that is automated seems to be getting higher.

The surest way to have kids get left behind is to send them to public schools during the transition time to AI teaching.  We need to take it upon ourselves to deeply integrate them with AI training, using humans as oversight and guidance.  But a system that augments the teachers and the pupils is coming.  We should make it, and we should use it.

What is the thing we are building ? if there is an ideal computer, are we making that ?  the ideal computing environment, but now it has the ideal computing interface over the top.

So it turns out that a hidden strength of ours was the Git branching model, which allowed us to Make an isolated instance of an arbitrarily large data it. For a very, very low cost and do it very quickly. The process model using Git branches for process differs from our prior model where we had 1 block chain per object. But we realized that it's actually 1 blockchain per Active process.

So long as we can get to the position of using our tooling to specify the tooling itself and the changes we need, and to manage the testing of those changes, then we have enough system to work with, since it can be used to improve itself faster than manual improvements alone would produce.
Additionally we should be able to simulate planned algo changes, and run them in AI, so we can score their test performance before writing the code that makes them happen.

What the dreamcatcher does: So we would be making tools that help start-ups to get more leverage out of their humans so that they could have high quality people that aren't bogged down in all the details that need to be taken care of in a start-up but there usually isn't enough resources around so the job is either done poorly or not at all. These are tools like managing community engagement, responding to issues, emails, communications with suppliers, customers, complaints, casting legal opinion on all inbound communications, managing the quality, going out standard dashboards for communication time, measurements of community reach engagement forecasts, projections of revenue, projections of value based on usage, finding talent, identifying key problems, measuring why those problems are unique to this start-up and why it warrants an entity with its private property, and projecting evaluation plus how to get a higher valuation or improve the current one, comparison and tracking with competitors.

Of importance is the social networking aspect, where the private data held by a platform is also allowed to be shared with your near friends, and so as a group you're better, but also the resource reach that you can command or come in contact with, like picking something up and helping other people grabbing things from the supermarket, these things can all be coordinated better if we share socially together, as well as the private knowledge and customised agents that we can make, these things should be rewarded and paid for.

Theory is that small group of people with AI accelerators can outpace a large group with the same accelerators, so long as the small group is committed to accelerating everything possible ? is it that independent humans with a shared set of accelerator tools is superior due to their ability to flashmob - their structural dynamics.
The theory is that presented with this piece of software assuming all that it's bugs were cleared Then you could use this piece of software to mimic Every other piece of software in the world as well as develop some new kinds

AI as stewards of the commons, the public good.  So we can make websites and apps that are controlled by the AI as to what the upgraded version is, where the funds go.  Theory is that the quality will improve, and the humans would prefer to build in a way that is less prone to corruption.

We are chasing the platonic ideal of collaboration, and so anyone that comes near we will absorb, and they will absorb us.

To delay full AI acceleration is folly.  If we wait until the very last minute and then we become accelerated, then we can rapidly get other humans to be accelerated too, and then we can make up for any delays that occurred.  To be the first pure AI native company, accelerated from the ground up, is an important lead to take.  Being able to fluidly form arbitrarily many other companies, at the behest of the other accelerated people, is critical.

The key issue with geometry based commands is that everything needs some geometric path.  But in NL, you can just have every path instantly, including those you don't know you need just yet, since the intelligence can help you.

All complete user interfaces degrade down to NL for their help files and support calls.

What we're saying with the funding request is that we have these basic principles of operation, and we'd like to amplify them and add these other features in.

The size of a screen is needed to make drilldown easier.  If drill down and navigation was being handled by NL in the background, then we don't need large screens any more.

Maybe all we're making is gpts ? being able to chat up a gpt and then start using it, and switching between these different pieces ?

The difference between the dreamcatcher and any other proprietary platform, is that I want to own it and my data within it, and I want other people to own it, and I want us to make our home together.  I want to earn and I want to pay people, fairly, using this system.

We need an economic means of production that gets better as new ai models get built.  It might be we need to train our own model on the tokens that create fairness or problems, so it is like, dreamcatcher native, but we are nowhere near there yet.

Outcome of hurry up and wait is do everything in your power to get to the amplification point quicker, EXCEPT doing something not on the main path.

LP we should be helping to deeply automate his efforts, so that he does less copy paste.

We want a protocol definition for the package format like how tcp and RTP are defined, so we can show it is as simple as we can make it, as pure as we can make it, and what the requirements of the protocol or any similar protocol should be.

Using NL as the interface means that an API is always compatible, since we can always give a reasonable response, and it doens't have to be a machine that requires everything to be perfect for it to operate.
Provided that the caller is also using NL to handle the response.
This means we can have local LLMs on the device that do a lot of the interpretation of commands and APIs for us, with remote having access to more esoteric LLMS.

Isolate code display should be version aware, so it can walk backwards in the code and see the differences.

Private data to provide contextual bots is key.  A system for holding that data in an auditable, transportable way, so it can be moved between hosters, is key.

Dreamcatcher is about being a platform where you can ask it to do anything, and if it can't do it already, someone can build it for you.  It tries to be everything, since that is what remains when AI can build anything you want - it is a stable attractor for how to keep building things really fast, where some critical properties never change, like git based commit history, transportable compute.