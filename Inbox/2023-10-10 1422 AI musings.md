
>[!tip] Created: [2023-10-10 Tue 14:22]

>[!question] Targets: 

>[!danger] Depends: 

It just feels like gpt4 has some kind of mastery of the sae substance that we use to think - like it has a form of general intelligence or logical correctness so that any random proposal can be ranked by it for fitness.

With an arrange of self checks and reflection, this spark should be enough to accomplish almost any mundane task a human might wish to perform.

Fruit seeking to be tastier so they increase their consumption is no different from us fine tuning our apps to have the best taste.  Just seems other factors affect the spread rates beyond just taste.

The data change rate can be less with AI, so git might be fine as a hash based filesystem, instead of interblock ?

Coverage has a different meaning in semantic land - semantic coverage.

To win in the AI transformation, a company must slash its headcount down to almost nothing, and then they must commit to sharing the profits fairly amongst all who contribute - administrative control allows inequity - if this is handed over to the machine, only then can match the pace of change of those who committed fully.  So earliest to commit and fastest to evangelize wins.

3 points:
1. we can make the managers use the AI to let us train it more, as well they can say what they expect
2. can use the accountancy flag as a means to inject into other areas of the business
3. fairness is the key here, which encompasses transparency, but also with comparison to market
4. we can loop thru rows of data, fairly mercilessly
5. there's a massive upset coming, we don't want to be on the wrong side of it
6. this anything app applies to you, but also applies to your customers
7. ultimately we could let them operate with no books, using our system to replace theirs - how much do you struggle with the xero structure, and how much do customers do so ?  We can make our own books app, even

If you have enough intelligence to operate in natural language, then you can operate in mechanical terms like counts, scores, and other useful things, but most importantly you can defend your decision. 

The whole trick seems to be ways to break large tasks down to something that fits in the context window, like a skill or a strategy.

Aliasing could be discovered by a sliding window and comparing the outputs as being meaningfully different, depending on where the window went.

The anything app should be programmed within the anything app.  The more is built outside, the more problems we have to deal with outside the core app.  Ultimately it would be come free floating on the app store, be forked, and so it would be unrecognizable as the starting point.

must be careful not to develop anything the MS or others are making, as they will win that game.  We all know the interface we want now, and so we should focus on applying it to loop in chain, to make apps at the fastest possible rate, which is faster than a human, and near instant.  None of their offerings appear to be a social network, nor an application framework.  We aim to have our own native AIs running on chain, which can be done in stripped down models once the use case is clear.

Does consensus need to be precisely arrived at by formula, or is it simply agreement on a result, without regard to how it got there ?  If all parties agree, that should be enough. This is no different to the initial state being agreed to, but it just goes on forever in this way.

Typescript is suddenly important in AI since it needs feedback on why what it did was wrong.

Because we can replace whole npm packages with AI processing of strings, this is why we can start to decompile the software industry and reduce its moving parts.  Using an AI as a "all npm packages" type of arrangement 

Passing the turing test means they can fake any authentication intended for a human, except they cannot fake a crypto signature.al the

The general theme seems to be places where information was cumbersome to process, took more than 5 mins, and required interactions with multiple companies - we can terraform these interactions into something streamlined.  We can accept liability as the orderer between multiple companies so that we can handle the fallout automatically too, which gives consumers a better experience.

The safe place is something independent of how the AI models evolve.  They will still need to be instructed, contained, audited, interfaced with humans, governed by rule sets.

Being a model provider is a dangerous game, since you can be displaced by a better model and the switching using systems like ours will be nearly instant.  You have to keep winning for a long time.  Ultimately open source shared models will win, as they have more gracious access to data and absorb all the open innovations into on place.

The AI should be treated just like a human, and it should have to pay for its access to our data.

Component based prompt systems

Instead of workflows that we once dreamed of for governing blockchain systems, we need a way to make AI generated workflows that call different ai powered components with a blockchain substrate underneath providing permanent memory, correctness, and mechanical query ability.  

Facts about data systems should be from retrieval systems, facts about knowledge base should use embeddings and use citations and backchecking until factual.

Preloaded chats should be for style, not for information injection.

AI will always be better at smaller tasks than bigger ones.  At small tasks, it beats humans - lets build on that.  Humans can't do big tasks in a single shot anyway.  We need structures.

Start to look like meaning shifting is the switchboard operator of old, replaced entirely by automation.  Much knowledge / admin work is simply moving meaning around / routing / switching it, when this should be done by a machine.

AI finally allows us to make a system that is rejuvinating - it gets better over time, not worse.

Descriptive naming is now more important than ever, since the AI needs to extract meaning from as much as possible, so the names of the paths in the filesystem need to be important, and a description against each path can help the AI greatly.  Each object should continually have a summary that describes its class behaviour and the data inside it, and how its history has changed.  The AI does the filesystem maintenance to maintain descriptive naming.

The web is dead.  The web was the explosion of context for humanity, and now we have a context gobbler.  Also giving info away in exchange for ads that corrupt that info is no longer relevant to an AI.  So the monetization is dead.  Advertising relies on human processing.  The web is about to fall.

Natural language interfaces make technology accessible.

The tooling is so general and so powerful that the incentive to build an open source version is tremendously strong.

Seems hard to keep it closed how it worked in the background - the steps being shared seems important to building high quality tools, so it will likely always stay openish.

AI makes transitioning systems effortless.  So all else being equal, you'd rather have a blockchain system than a conventional.  Also connecting to existing systems is effortless too now.

Bot to Bot chat helps to keep the context narrow - if each bot only sees that chat that it has had with its higher up, then it can remain focused on the current task.  In this way the parent has handled a lot of work to filter the chat down.

The AI apps are worthless - they are of ultimate and perfect utility, and renew themselves endlessly to correct and expand their abilities, but they are so cheap as to be free.  The value is in the commerce they enable - the trade between parties in this highly developed perfectly intelligent world.