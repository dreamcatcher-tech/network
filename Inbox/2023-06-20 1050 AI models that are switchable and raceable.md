
>[!tip] Created: [2023-06-20 Tue 10:50]

>[!question] Targets: 

>[!danger] Depends: 

If we can make AI services available as chains, then you can run arbitrary models in parallel and combine results.  This is better because the price is lower, the interface is reliable as it accounts for API failure for you.  Payments is built in.  You can take the operation private if you need.  You can run locally on network if disconnected, or use the full power.  Queries can be queued up for when connectivity is restored or when pricing is favourable.  Payments are distributed ethically to the data providers.  Can easily make your users pay for credits, rather than routing thru you.  API version is locked, so you get deterministic results.  Your apps keep going even when you stop, since no need for hosting on your part or paying any bills.  Burstable demand doesn't charge you anything, in fact it makes you money.

You apps can be composed into other apps and the API calls are paid for by the executor of the bundle, and you get a cut of it, rather than then needing to replace your API keys and giving you nothing.  Makes your apps be more modular, and encapsulating the API within them, rather than never being able to capture the API internally.  Consuming these modules is very easy as the compute comes bundled within them, rather than having to rip it out and make your own API connections then having to debug it if the API sends back data the module didn't expect.

Keeping your code refering to a module means the module can be upgraded and your app instantly receives the benefit.

Charging any apps customers directly gives the network the relationship rather than just them.  In exchange

Attribution is done by proving who owns what content, and then using the micropayments to allow them to withdraw. 

Chains let you query mutliple different models and then summarize the results, or feed into other models.  Lets you have very complex flows.  Auditable in that they can be replayed.  Can be open so that the outputs can be parsed as training data.

Each time you run a model, it will be ethically paying out to everyone in the training set.

Model as a pool of hardware that is executing them, so you can run your queries against any model you like, or in fact several.  Works like an API, but you can easily run the model yourself, or shop around for price.  Spot like pricing that is based on people supplying their own hardware, or from using AWS spot instances to make up the hardware services.

Streaming output that is coming from multiple machines for repeatability.  Can choose to be cheap and run a single instance.  

Specify your pretrain data as chains.

Pay at good spot rates.  Supply your own hardware.  Run privately if you want, or make some tasks private and self hosted and others be using spot or dedicated hardware that you pay a premium for.

Higher uptimes of the service since blockchain distributed computing model.

We could run our own image generators using own own interfaces, and can handle our own charging of usage.  We can queue up some of the attribution that is due each time a payment is taken.  We can advertise we are working on AI attributions.

Tokenomics where a portion of all payments goes to cover paying for free usage, to encourage adoption and grow the network for all.