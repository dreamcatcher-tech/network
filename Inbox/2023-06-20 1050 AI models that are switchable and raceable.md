
>[!tip] Created: [2023-06-20 Tue 10:50]

>[!question] Targets: 

>[!danger] Depends: 

If we can make AI services available as chains, then you can run arbitrary models in parallel and combine results.  This is better because the price is lower, the interface is reliable as it accounts for API failure for you.  Payments is built in.  You can take the operation private if you need.  You can run locally on network if disconnected, or use the full power.  Queries can be queued up for when connectivity is restored or when pricing is favourable.  Payments are distributed ethically to the data providers.  Can easily make your users pay for credits, rather than routing thru you.  API version is locked, so you get deterministic results.  Your apps keep going even when you stop, since no need for hosting on your part or paying any bills.  Burstable demand doesn't charge you anything, in fact it makes you money.  Privacy guaranteed, as you can move between suppliers, have multiple for backup - the privacy supplier is separate from the software supplier, detached from the software, and so the independent privacy suppliers are incentivized to win at privacy.

No platform risk at all - everything you made can be stood up and hosted by you or anyone else, rather than being locked into a specific vendor.  Good long term security of hosting and long term resilience.

Closed APIs can be wrapped in chains too, which can handle your application hosting for you, as any API can be wrapped.  So basically publication requires no servers for you - even if you have API calls to make.  Hosting would have to handle secrets for you tho.

You apps can be composed into other apps and the API calls are paid for by the executor of the bundle, and you get a cut of it, rather than then needing to replace your API keys and giving you nothing.  Makes your apps be more modular, and encapsulating the API within them, rather than never being able to capture the API internally.  Consuming these modules is very easy as the compute comes bundled within them, rather than having to rip it out and make your own API connections then having to debug it if the API sends back data the module didn't expect.  Turns api connections into things, rather than services.

Keeping your code refering to a module means the module can be upgraded and your app instantly receives the benefit.

Charging any apps customers directly gives the network the relationship rather than just them.  In exchange customers get a standard interface.

Attribution is done by proving who owns what content, and then using the micropayments to allow them to withdraw. 

Chains let you query mutliple different models and then summarize the results, or feed into other models.  Lets you have very complex flows.  Auditable in that they can be replayed.  Can be open so that the outputs can be parsed as training data.

Each time you run a model, it will be ethically paying out to everyone in the training set.

Model as a pool of hardware that is executing them, so you can run your queries against any model you like, or in fact several.  Works like an API, but you can easily run the model yourself, or shop around for price.  Spot like pricing that is based on people supplying their own hardware, or from using AWS spot instances to make up the hardware services.

Streaming output that is coming from multiple machines for repeatability.  Can choose to be cheap and run a single instance.  

Specify your pretrain data as chains.  Allow the results of the output to be added to the training data - so users using and paying for the service are also submitting pretraining data.

Pay at good spot rates.  Supply your own hardware.  Run privately if you want, or make some tasks private and self hosted and others be using spot or dedicated hardware that you pay a premium for.

Higher uptimes of the service since blockchain distributed computing model.

We could run our own image generators using own own interfaces, and can handle our own charging of usage.  We can queue up some of the attribution that is due each time a payment is taken.  We can advertise we are working on AI attributions.

Tokenomics where a portion of all payments goes to cover paying for free usage, to encourage adoption and grow the network for all.

So basically all API usage should be part of our API library service, which can act as reliable operators of the API you use.

We would also be supplying a labour force that could make the models and things you want, providing royalty sharing for any usage that occured.  Might be better to concentrate on this small segment rather than generality ?