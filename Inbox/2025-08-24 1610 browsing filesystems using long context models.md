
>[!tip] Created: [2025-08-24 Sun 16:10]

>[!question] Targets: 

>[!danger] Depends: 

we could, instead of a search, stuff all the context in and ask a big model like 4.1 to answer the questions we have ? might be better than mechanical search ?

or could call smaller models with each file ?