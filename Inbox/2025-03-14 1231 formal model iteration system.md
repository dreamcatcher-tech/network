
>[!tip] Created: [2025-03-14 Fri 12:31]

>[!question] Targets: 

>[!danger] Depends: 

If questions are posed by users, then translated into queries for a base first cut TLA+ model, then if the scenario causes a fault, the system knows it needs to fix it.

In this way, we gradually build up to a complete and verified model, with all edge cases handled, in a way that any human can pose a scenario, or a range of scenarios that can be automatically generated.

Auto gen of a range of queries causes the LLM to repeat a pattern, then ask the model translators, and then do the TLA+ responses.  Can help the human feel safe about it.

Also use the intelligence of the model to try come up with examples that cause problems.