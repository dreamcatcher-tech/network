
>[!tip] Created: [2023-12-15 Fri 12:45]

>[!question] Targets: 

>[!danger] Depends: 

JS or other verbose languages are easy to code in since they do mem management.
If we could generate a rust version that was automatically updated by copying the version that was generated in any language.

Being able to have several languages that were all implemented and kept updated based on how each other was made ?  Useful since performance and availability to different devs is important to harness max creativity.

Requirements for an NL app can be vast, and should get auto arranged, nested, and clarified by the AI.  Then we can run tests for them, in natural language, that show how it would work, how the process descriptions execute theoretically, and how to segment features into now and later.  Says what the descriptions need to change to in order to fulfill different subsets of requirements, where a requirement describes a scenario with some guaranteed output.

The execution is happening in the AI's mind.  So we are using the AI as a computer, where it can imagine what would happen next, and it can do it without us supervising it, so the program can run without being coded.

In some cases, this might be all that is required.

Should the protocol be done in something agnostic like xstate to show how the flows work ? No, xstate should be a derivative view out of a natural language flowchart.  We can do relaxed forms of nested statecharts using just plain natural language.  There are probably some rules that we can derive from running xstate in the background so we can advise on when a flowchart design can be simplified or when it will likely run into problems.

These pipelines seem like the key to the whole system.

Is there something natural to an AI to describe how the program works in ?  Probably just natural language.

Optimizations for each language would be done as a derivation of the reference implementation.

If a language has modules, then we can isolate each module with an API and use it this way.

The queue channel thing should be the same internally as what gets used between chains.

The tests would be in plain language, and the implementation would be attempted to be generated by machine, then the coding done by machine, with human help.

If json was the way to describe the contents of each API call, and then the logic rules were laid out in natural language, then we should really generate from that.  So the AI would help us define the protocol in a natural language, and then reason about it with us, detect exceptions, do optimization.

The library to do this would treat each rule as a single unit, and they loop AI over it to compare it with a new global level rule, to reconcile everything.  Bugs would be introduces as natural language against the algorithm.

In this way, we might be able to maintain an implementation in TLA+ or similar that gave us operational correctness, 

So the architecture is in natural language, and the use cases are in natural language too, and the language implementations are built out by machine with human tweaks.

To have this model would mean we could alter things much easier, and receive pull requests in a much more natural way, since they could be PR in natural language, by anything who can think clearly.

This same tool would be used for letting users modify their own applications and bots, since you would engage with the natural language piping.

Any given problem can be mapped to this workflow so even if it is a protocol issue, we could step thru it using the natural language debugger.  The debugger can navigate using NL so it is far less picky about what it needs from the user.  So lets them program against this core flowchart, and update the chart, global rules, or instance rules to get what they want, all while running many parallel tests on past data and synthetic data.

So the interpulse protocol needs to be built using this AI tooling, and it is also used to make this AI tooling work well.  Means we can have python native, rust native, js native implementations that are all held in high standard, and easy for anyone to contribute too, since they can come in with their language of preference, this fulcrum round the natural language descriptions.

Issues, being in natural language, can have natural language repros.  If we can't generate the fault in the natural language model, then is it really a bug ?  It is most likely specific to a language implementation.  Natural language architecture then gets a TLA+ model built from it, and all other implementations follow.  It is an opportunity to move from traditional dev tools to pure AI tools, delivered as part of the application that is being consumed.  AI first programs mean we can deliver higher quality faster, with more rapid contributions flowing in from both users and programmers.

So a dashboard program made in NL could be easily translated to VR or web.
Physical objects could easily be generated to represent API connections between programs.

Start on the channel model as a simple way to implement this tool type.  Build out how it should work in NL, then break it into subsystems if possible, then show the json payloads moving around, then build out the logic of each function, where a function is just a type of processing that changes the data in some way.  Represented graphically, this could be much easier to understand, and an LLM can mine for repetitions of logic that can be collapsed down.

Committers get a ready to go environment just by using the dreamcatcher, where they can fork the running version and start chatting with HAL to get results back.  It is baked into the app and is triggered whenever they ask to make changes in HAL.  Privilege is irrelevant as it always forks.

If we run all this on a distributed GPU blockchain, then we can really gather some interest.

AI powered means we can wield a huge amount of parallel computation without it being cumbersome to interface with, such that simple commands are given to the AI that spin up a thousand cores running in parallel to test something.  Setup of these tools is nothing, too, since they come built in, and can work thru issues with the user naturally.