
>[!tip] Created: [2025-03-11 Tue 16:34]

>[!question] Targets: 

>[!danger] Depends: 

The properties of artifact are such that it effectively provides all of the compute resources and capabilities that many popular charged services offer, like pub/sub messaging, real-time video calling, large object storage, high-throughput queues, and high-throughput compute. 

We could take this base design and make the argument that we could make all these competitive standalone services that are really just Artifact under the hood, with global regions, but they can also easily integrate with other Artifact services. This provides a way for Artifact usage that is internal to poke out. 

they become standard competitive options unto themselves. If you additionally want to plug them into serverless compute, cheap high-volume storage, and other features, it comes kind of built-in, ready-to-go, and easy to use. 

all the while the deployment mechanism being AI-guided is very natural and very fast, going from prod to test and back to prod again is very seamless. As well as being hooked up to automated exception monitoring that can attempt to solve the bugs in your code in real-time based on the infrastructure. Plus allowing replay of any faults or any activity that has occurred. Plus allowing contributions from anyone if you open-source or open-state what your infrastructure is, and so anyone can see inside it and can improve it for you on your behalf. And can share revenue with these contributors based on some fair allocation algorithm. 