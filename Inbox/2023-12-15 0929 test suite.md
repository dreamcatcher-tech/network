
>[!tip] Created: [2023-12-15 Fri 09:29]

>[!question] Targets: 

>[!danger] Depends: 

Must be a jitter so that using HAL you can drive the interface to the tester.

Artifact is coded to be able make a test plan, then run it, then submit the results somewhere shared.  As long as artifact can run these suites, then HAL can run them.  Jitters then display their results.

This jitter can be our first way of coding jitters, so really all that is needed is the artifact commands.
We can then figure out how to present the objects using a react component.

The storybook of each covenant should be auto generated in effect, and be run in many different window sizes with all types of artifact status being tested and then automatically appraised.

Key seems to be to let the experts talk to the bot in order to train it, and give it better responses, possibly using FAQ style inputs using RAG, or by training the model using 

First delivery:
running in the CLI to make some hand coded tests run.

running in storybook to automatically run the tests.

run as a jitter where HAL can marshall the tests around, with different parameters.
Make an autorunning storybook that auto runs this marshalling jitter.

Much later, be able to interpret markdown docs as test specs, then update them automatically.

But need to make the schema easy to interpret first ?

Problem is that there are so many different strategies to try with wiring bots together, how can we make this wiring be in natural language, so that we can wire things up using AI to help us, so we just talk about it, and have AI figure out the rest ?