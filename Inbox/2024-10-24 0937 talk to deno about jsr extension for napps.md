
>[!tip] Created: [2024-10-24 Thu 09:37]

>[!question] Targets: 

>[!danger] Depends: 

They must surely have thought about how to incorporate LLMs into deno deploy.

Proposition is we have the jsr package library, which is great, we have deno deploy, which is also great, but we have no package format for AI agents, we have no AI offering for deno deploy that lets people rapidly deploy AI agents at the edge.

Key to the AI race is safe code execution of untrusted (ie: LLM generated) code - subhosting is PERFECT to supply this environment.

So if we get this napps format adopted, and make a deno native way to execute napps, and integrate some standard LLM offerings, then we can get artifact hoisted, napps hoisted, and then we can build the dreamcatcher.

Add runtime tracking, as in invocations, hotpath mapping - which code paths are heavily used.  Replay ability.

LLM replay and be able to use the opensource actions against the LLMs, sold at a discount, to see what the responses of the prompting and training was in the LLMs, to allow greater refinement.

Show call costs assosciated with all the presented LLMs, and offer revenue sharing.  Offer a mode where deploy can run the napps, or even the modules, and then people who produce these certified modules can receive revenue share.

Insurance pools to cover support assurance, reaction times.

Talk about this super computer that Ryan Dahl keeps going on about.
Make it a reality, since all your stuff would be on this computer, and not always somewhere else.