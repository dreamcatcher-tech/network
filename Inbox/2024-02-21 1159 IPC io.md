
>[!tip] Created: [2024-02-21 Wed 11:59]

>[!question] Targets: 

>[!danger] Depends: 

Need a separate set of io objects that track requests that were sent out from this chain to other chains.  Before making the requests, we need to commit them.  They would be stored in a trail, which is the execution of a single incoming request, and all the request replies related to them.

So outgoing is just another IoStruct that commits all the requests we made out, and the replies that came back.  Replies might be left as the remote branch, and we would need to look that up to replay it, rather than copying into the channel ?  Seems easier just to copy it in.

If we have serial request processing, then the outbound channel is only in use by one request at a time.  On conclusion of that request, all outstanding requests need to be cancelled - we should thru an error actually ? 

It cannot be repeatable with fire n forget - you must include the outcome of your actions, else how can we know the actions you triggered are repeatable ?

We have serial request processing since repeatability with filesystem interactions is impossible during concurrent execution.

? could these be done in a branch with a special relationship ?  like the fs control is handed to this branch so it will guaranteed fast forward upon return ?

If we give it a full loop around the event loop, then we know we grabbed everything.
The executor will try stick around, but can be restarted.

Needs to have a recovery plan too.

Requests that cause a branch seem weird - they would only ever come in from a pierce.

Updating the filesystem could require a dedicated action, rather than being by default, which would allow loopback operations to occur.

Outbound queue could be in the same IO channel, and it just has different target addresses in there.

How to do a commit of partial results of a serial operation ?  Would need to be some api function that gets called that causes the current operation to commit to disk.

Missing feature is how to trigger promises that have been settled, but a serial execution is waiting for.  Serial execution means this thing has execution lock, so it could just watch commits and pull in the changed io file to get the updated replies that it needs to continue on.

In the future, we will use commit watching to know when a reply has been committed.  This should be very lightweight and cheap on the db.  This would be the exact same mechanism as recovery.

We cannot trust watching the pool directly, since this is prone to skipping if our watcher is slow but our pooler is fast.

Commits are the single point of synchrony that we should rally around.

We might need to make piercings have some kind of external counter, so that double delivered messages are removed.  Could be a nonce tracked by the sender, or we could seek the ulid, or just store a copy of the ulid in the db for a time.  Ensures no double actions from redeliveries.  Ulid should implicitly come with a timeout, so if we do not process it with the expiration date, and the bufferlog expires in 2 x window, then can be pretty sure of no double ups.

An incrementing number stored on the users account is the best tho.

expiration of queue messages should be paired to timeouts of replies and any other message timesouts.