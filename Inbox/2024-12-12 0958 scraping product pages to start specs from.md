
>[!tip] Created: [2024-12-12 Thu 09:58]

>[!question] Targets: 

>[!danger] Depends: 

If we pull down the whole page, then we can use this to generate a readme to spec our own product that does similar things, or modules that do part of the spec.

scraper that is build as a napp tool using fetch.

Being able to scrape and store a snapshot is key.

Then we can build things like making a desktop app that can take in dictation, and turn that in to its own high grade transcription, that was made for doing a prompt.

We would be able to make a web app that can run a napp in this way, where it is running as an api service.

Could also trigger the live regeneration of the dump files, so the prompts are being auto loaded up.  This is always useful, since once we have an api, we will still use the same formats and everything, its just the copy paste will be done automatically.

These scrapes should be saved as ingestions, which the codebases is formed from.
Reapers check the codebase to see that all ingestions are currently either applied in the codebase or explicitly ignore from being patched in.

crawler should have different strategies based on domains, since we would start to specilize on particular ones.

So crawling youtube, to get the audio, might be chosen from a range of options.

Could then auto parse it thru deepgram, by crawling their api.
The crawler should support shared crawling, where there is a shared and staked (stake to say) library of prior crawls, which can be preprocessed to make more useful ?



