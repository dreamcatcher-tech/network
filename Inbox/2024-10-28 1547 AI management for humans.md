
>[!tip] Created: [2024-10-28 Mon 15:47]

>[!question] Targets: 

>[!danger] Depends: 

if all messages that come in to you go via the AI, and it makes a call as to the usefulness of the information, and then bounces you out if it doesn't make sense, or if the human is busy right now and this would distract him.

Viral marketing since the bounce comes with a watermark, so people can sign up.  Then they can communicate with each other directly using the AI moderator.

AI moderation of the social network.  How broken the world if the one true social network is captured by a handful of companies that refuse to let it be full.

Imagine this in a workplace setting, where managers assess if the filter settings are wholesome for the company, and then coworker comms get bounced if they do not meet standard, or if they didn't follow protocol, like did not answer the question.

This could all get bounced before the message ever got sent.

Whey should toxicity be constrained to online meetings ? why is it not omnichannel ?

Why not a moderator for all my comms, that is pluggable into all kinds of psychological models ?

Toxicity is not the only kind of fault - it could be distraction, deviation from goals, poorly worded.

You should be able to cobble together your own system as a blend of systems.