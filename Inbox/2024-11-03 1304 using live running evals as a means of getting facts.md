
>[!tip] Created: [2024-11-03 Sun 13:04]

>[!question] Targets: 

>[!danger] Depends: 

If we run the same question 100 times in parallel and then check all the answers to see if it all agrees, then we can detect when the model might be hallucinating.

We can then seek some ground truth so the model is more reliable in its answers.

The comparison could simply to find knowledge that has discrepancy, and so we would highlight this as an assumption, and run off and try get some ground truth, but at least keep working with whatever we had baked in.