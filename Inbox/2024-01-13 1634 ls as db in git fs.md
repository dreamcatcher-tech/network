
>[!tip] Created: [2024-01-13 Sat 16:34]

>[!question] Targets: 

>[!danger] Depends: 

if we make ls be a highly optimized command, then we can use it like a database.
Also find can be tuned to be like a db.

So the find tool gets rewritten to do graphql queries.

Also can optimize it for plain text, or for calling an AI on every record, even if its a small AI.

searching should be AI assisted anyway, and can have vector search suggestions stream in too.

If these glob searches were super fast, then we don't need a database per se

Can also use regex to do queries and summations on the contents of the text files.

One of the rules for a good text format is one where the fields can be unabiguously referenced by using a regex.  

## Pipelines
Just because something is slow, doesn't mean you can't work with it fast.  If we set up pipelines so that they would eventually have some output, then it doesn't matter how long each query takes.  So if you like the pipeline that has been built, we'd say how fast we think it will be and then we run it.