
>[!tip] Created: [2025-05-31 Sat 13:31]

>[!question] Targets: 

>[!danger] Depends: 

with all the context we have of a person, we should be able to detect statements that are contrary to what I would expect them to say based on their prior history.

We might be able to process all of their statements in the past. Break them apart into a form of atoms or utterances and then fine-tune the model based on them. This model would always say the things that were like what you said. It would be able to appraise whether or not what you said sounded a bit like or a lot like something you said in the past.

The key feature we want is the ability to detect things that disagree with what you said in the past and we should flag them and highlight them. Be like, "This is contrary to what you said on this particular date. Is it wrong? If it is a one-to-one discrepancy then maybe they've changed their mind, but if it's a hundred to one that might be quite severe and we should check with them and then alter our knowledge base significantly if a large change of mind has occurred." 