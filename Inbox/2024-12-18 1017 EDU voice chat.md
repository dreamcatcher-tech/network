
>[!tip] Created: [2024-12-18 Wed 10:17]

>[!question] Targets: 

>[!danger] Depends: 

Set initial context based on learned memory
ID the speaker and pull in memory they have
pull down the latest behaviours of the person so can have more context on recent activity
get context from parents.

Child begins talking.
parent on the side talks or types at a computer, which gets transcribed and then sent to the server as a queued update message.
These get receives on the browser client, and the pushed into the realtime session, using `session.update`

https://platform.openai.com/docs/guides/realtime-model-capabilities

Can have tasks we want done, so can steer towards certain tasks and outcomes.

o1 might process these side channel events to generate guidance for the voice models.

o1 can be overseeing the conversation, so it figures out behaviours and other things.  Figures out incorrect words based on parental correction and speaking, so it can guess a bit, but can also 