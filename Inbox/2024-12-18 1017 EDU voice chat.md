
>[!tip] Created: [2024-12-18 Wed 10:17]

>[!question] Targets: 

>[!danger] Depends: 

Set initial context based on learned memory
ID the speaker and pull in memory they have
pull down the latest behaviours of the person so can have more context on recent activity
get context from parents.

Child begins talking.
parent on the side talks or types at a computer, which gets transcribed and then sent to the server as a queued update message.
These get receives on the browser client, and the pushed into the realtime session, using `session.update`

https://platform.openai.com/docs/guides/realtime-model-capabilities

Can have tasks we want done, so can steer towards certain tasks and outcomes.

o1 might process these side channel events to generate guidance for the voice models.

o1 can be overseeing the conversation, so it figures out behaviours and other things.  Figures out incorrect words based on parental correction and speaking, so it can guess a bit, but can also 

App on parents phone that shows controls, as well as steerage.  Shows child stats.  Lets the parent ID the child, and id other children in the conversation.

Use VAD and DOA to separate out incoming conversation from multiple parties.  Detect talking over each other, and try train that out of them.

Measure sorts of events you want to train out of them, give advice on the psychology, and also allow a qualified expert to take a look at what is happening, ask you some insightful questions, and help you use the model to get the outcomes you want.