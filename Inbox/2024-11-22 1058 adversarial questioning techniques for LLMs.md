
>[!tip] Created: [2024-11-22 Fri 10:58]

>[!question] Targets: 

>[!danger] Depends: 

Since they do hallucinate, we need a double checking strategy whenever we do any tasks.

Finding standard ways to get the LLMs to check their own work in a way that would make errors exceptionally rare seems necessary.