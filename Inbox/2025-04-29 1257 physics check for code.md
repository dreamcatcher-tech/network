
>[!tip] Created: [2025-04-29 Tue 12:57]

>[!question] Targets: 

>[!danger] Depends: 

Many questions for an llm can be answered by running an actual experiment.

code is very good at this - so if the LLM has a question, it would just fire up a sandbox, run some code, and see what the results were, rather than relying on the web.

other types of pysics can be answered in the same way, like electrical simulations, mechanical engineering.

electronic circuit designs could be reasoned about by a bot, and it could learn from just trying lots of experiments and reasoning thru them.

Can have different degrees of calculator for the accuracy vs speed tradeoff.

When it learns things, these should somehow be deeply summarized, so that others can learn, along with a cheap experiment to prove the point, like a scientific publication in a journal - in this way the LLMs can "learn" and can be highly accurate.  This allows machine construction.

LLMs must also be subject to the assymetry between discovery and verification.  So if they have a knowledge base, which contains shortcuts with proofs, they can rapidly speed forwards as fast as the fastest reasoners currently are.

This creates a flamefront - all the rear can easily catch up to the front, but the front is hard to push thru.  

No token should be wasted in pushing thru - as soon as anyone pushes thru, all should join - the flamefront should be sharp - all light on the edge, all dark all around.