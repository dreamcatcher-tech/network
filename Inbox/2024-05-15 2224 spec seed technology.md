
>[!tip] Created: [2024-05-15 Wed 22:24]

>[!question] Targets: 

>[!danger] Depends: 

there is a seed of text that should be droppable into artifact, that will cause the machine to generate a fully tested workable crm.

As we test and refine the system, in the background it tries to distill down a new seed that still has all the end results that we wanted.

Use staging so that it knows it will derive a certain portion or piece, rather than the whole thing all at once.

Ultimately will test the grown from seed against the current patched / whipped iteration for equivalence in all tests.

We should be able to show multiple apps that can be recompiled in this way.

Means that if we drop this page or two of text in, the LLM should be able to test and retest and reshape itself into a working llm, and demonstrate simulations of the full working system.

Hopefully the intelligence of later models shines thru better using seed, rather than using constraints.

Inverted programming starts with all possible programs and takes away from it.  Contemporary programming is iterative / additive.  Inverted starts with every program and separates the pieces out.  Seed regenerates the end result from the smallest possible input.  As the models get better, seed time and seed size go way down.  There will always be a seed tho, however more of the seed will be included in the model itself.

Our next major adjustment / adaptation, is when the big models release data management / record management systems.  We should map out the developments in the AI space that will be cause for concern for us.

So is this yet again another intermediary step ?  However the internet has gone thru many intermediate phases, all of which have been wildly profitable, none of which are the end state.

Seed tech is something that gets incredibly better when new models come.  It provides a way to upgrade an application automatically when a new model comes on the scene.

The more we can have operations that instantly are better as more powerful models are released, we will benefit the most, the fastest.  Focusing on how the apps are made, financed, deployed, upgraded - this seems a good area.

We absolutely have to be positioned in a way that our offering is improved as the models improve, and ideally with an automated upgrade path, so that it is hands off as soon as new models come out.  Riding the uplift in AI is crucial to survival.  The pace is about to accelerate, and anyone not directly attached to the model growth will be left behind.

If our build capabilities were directly tied to model quality, then as models improve, we can build much faster and with a higher quality.

Seed is required so that the new model nuances are spotted as the whole thing is built using the model, so the model makes the best choices to suit it at every stage.