
>[!tip] Created: [2023-03-13 Mon 13:34]

>[!question] Targets: 

>[!danger] Depends: 

Comparators should allow for multiple people to run them and submit the results in a graph.  Can have an official single run.  

Can run across multiple flavours of machines much like ghactions works.  Can be included as part of the CI pipeline.  Can be used to detect performance regressions.  If they are using too much cpu, we can stall the results until someone else donates their cpu or some money to pay for others cpu.

Anyone consuming these libraries can signal to the world they are using them, can expose where they get used in their apps, or in their reducers, and can be notified when comp

Select which properties are important to you, so you can be notified when a more suitable option has arisen.  Include security alerts as number 1.  Show issues, PRs, livliness, and other health scores as decorated comparators atop the specific one.  Specific is for the module performance, meta is about project health, funding, usage, and other things.

Signal how hard changing between them all is - attempt to subtly pull all libs towards a standard interface.

## Example for threading libraries
Make a comparator that pulls in some common web worker / threading libraries, some which work on nodejs, others on browser, others on both.
Run a set of benchmarks on each one, inside a chain, publish them regularly as the guidance on threading libs.

Approach the authors and ask that they link to these comparator tables as part of their own benchmarks.  Can link to a specific version, or can import the copied markdown that includes a link to the comparator pulse hash to prove the latest run.

