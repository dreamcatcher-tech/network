
>[!tip] Created: [2024-12-10 Tue 10:56]

>[!question] Targets: 

>[!danger] Depends: 

AI seems always slow.

No matter how good it gets, it will always be slow.

Replacing a message and regenerating seems to be higher quality than continuing the conversation.

Trouble is that

When the first output comes from the model, we know the model flop, and so we have much more info to work with.

We should be able to fork multiple versions, and then merge them back in, so we can modify what we said in multiple different ways, while these things are running in the background, then we can merge multiple lines of development back together.