
>[!tip] Created: [2025-03-01 Sat 09:48]

>[!question] Targets: 

>[!danger] Depends: 

I should be able to say to the system "Hey make me a small demo that shows how async local storage works in a simple Deno app or with this particular library or something like that so I can send it off to do an investigative task where it will develop a small example app run some tests on it it may pass back some comment on some interesting observations that it thinks I might value that I'm not fun surprising and then it reports its result can be just a green tick or whatever 

over a long time frame these things can be used as integration tests or a system system integration test where we make sure that our understanding of the system that we lean upon is still current and so each time there's a new upgrade like a new version of node or the version of Deno gets upgraded then we can continually rerun these little tests and have the AI analyze any discrepancies in a response so that we can act accordingly 

lastly I think the different parts of our code base they rely on these particular methods and snippets these should be able to be linked back somehow through these little snippets so if the snip is changes then we need to revisit the code that used it in effect we're providing a knowledge base with a knowledge base is verified information where it's verified by running the code as opposed to just relying on the LLM's internal memory and which could have hallucinations in it so the idea is that we use the LLM's fuzzy memory to retrieve and identify links between things but then we guarantee or assert that knowledge by running code that actually compiles correctly. 