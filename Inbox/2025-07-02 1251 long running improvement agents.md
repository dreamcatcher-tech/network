
>[!tip] Created: [2025-07-02 Wed 12:51]

>[!question] Targets: 

>[!danger] Depends: 

If we had this thing grinding away and trying to improve a score on a particular set of tasks, and continually generating new tests for it to work against.

Keep checking that the task set has not drifted from the actual tasks that the human actually caused, so the synthetic tasks need to hold good alignment.

Then we see a graph of its improvement over time, and over token burn, so the tools should improve overnight.  Can be trying a range of techniques to improve scores.

Allow for avalanche solutions where a wild new strategy gets chosen and turns out to bear fruit.

Try meta solutions, where it looks at what you're trying to do and solves the problem one higher, possibly removing the need for the solution at all.