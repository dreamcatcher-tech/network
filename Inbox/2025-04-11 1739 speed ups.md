
>[!tip] Created: [2025-04-11 Fri 17:39]

>[!question] Targets: 

>[!danger] Depends: 

~~seed should be cached per machine.~~
deletes can be weak, except for the HEAD
make sure all gets are weak, except for head
make sure all exists checks are basically skipped ? 
getStrong when get fails is probably wasting time
object puts can be weak
all puts should return immediately, but should hook some main context promise to ensure that they finish, like a promise on the store - needs retry on error too
ensureActorRepo can do a weak head get, since will reject if always exists
avoid having concurrent ensureActorRepo jobs in parallel using promise caching
flush has 3 major areas where it can be parallelized
all puts can return instantly, but we should cache them until done, so when something tries to get that same path, it will first wait for the put promise to complete
BUT get on a put should be cached anyway ? so we should just return the payload ?
puts can return instantly, but when git commit occurs, these must be flushed, which is complicated
ensureActorRepo should be cached, too
remove the syd region headers from tigris and see if that helps us
puts should be gathered within a context, and all awaited at the end - could be a good use of the span context as the 'box'
consistent reads on something that was just written seem slow - we should never do this operation
need to break up the traces so we know exactly what operation in the benchmark is taking place
use deno built in kv store to add a cache to the disk, since we get about 7GB of disk on fly.io.
getSeed should be a weak get
back to back calls to latest are wasting time, they should be condensed somehow ? some degree of caching is beneficial, particularly if nothing else has been done in this thread.
figure out the tree hashes locally, without having to wait for the put operation, since the trees need to be walked up to the top
move the flush operations to the server side, so the calculation isn't wasted / can be calculated ?
if getAtomicHead is mising, then a call is made to get `00/00000000000000000000000000000000000000` which is pointless.
init does a total of 3 putAtomicHead operations, just to create a new repo - this should be only two
in putObject from the store, there is about 100ms before the actual GET request goes out - tune out why
write the seed to the db cache and store it in the docker image
need to throttle on send to tigris
need to at least retry if there are send errors on put
if we move flush server side, then computing oid can be done just once, then the upload await be separate
instant put returns seems the greatest speed up, if we could only somehow batch them
getAtomicHead should never check an empty commit, and resolve path should never be used on a known missing repo, so we should tell git not to check for config.
getAtomicHead should take advantage of the HEADs tree oid
seed can be written into the secrets once it is well known, to save a lookup
store the tree in the head marker too, which can save reading in the commit just to get the tree oid out
? is putObject faster if it has headers, since putAtomic seems always faster than bulk puts ?
meta-tip commit can do the commit in parallel with the flush.
getAtomicHead is always faster than weak get, same with write
cpu might be strained, since the encryption was being done on a single core
store the span context in the middleware context, and use this to reset the parent of every middleware
is setting the whole bucket to a region and a fixed consistency going to be faster all round, and avoid all the rigmarole ?
### metrics to add
count for number of duplicate object get requests
puts that are then get should raise an alarm
flag the stat requests to tigris as something different

### tests to add
do a single commit with multilevel dirs, and ensure everything is happening in parallel

## Results

1. `Prepare files (N=1)            27.6 s           0.0 (  27.1 s â€¦   28.0 s)   28.0 s   28.0 s   28.0 s`
	1. for a single file, it takes 30 seconds just to add it


## Wins
ensureActorRepo was not cached and was being checked every time a blob was being written