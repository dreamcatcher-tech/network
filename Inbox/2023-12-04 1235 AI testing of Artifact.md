
>[!tip] Created: [2023-12-04 Mon 12:35]

>[!question] Targets: 

>[!danger] Depends: 

If we gave it all the controls to interact with chains, then we could ask it to do legal moves and try to break the underlying system, or make it behave in a way that is inconsistent with the documentation.

In this way, the docs are always kept in line with what the code does, since an AI is processing it.

The docs are used by the AI to know what it is allowed to do.