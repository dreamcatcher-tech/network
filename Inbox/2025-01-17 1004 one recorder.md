
>[!tip] Created: [2025-01-17 Fri 10:04]

>[!question] Targets: 

>[!danger] Depends: 

The interface for making reatime sensor data ubiquitously available on the platform.

The concept of sections within a continuous recording environment. So what would happen is we'd both turn on our recorders, which may have already been running. And then... We'll start an agreed conversation, like a meeting. That meeting. Simply has access to both these streams for the period of time that it exists. We can also do multi-layered meetings, where we can strip some information out that's private, so we can flick it to private mode. Which is off record, and then we can flick back into on record mode. As well, as we're parsing, we can determine any leakage of sensitive information. We can even patch the information with anonymized words, which are automatically generated. And so this presentation layer of what the meeting stream was, is patches upon the core information. And so the raw recording is shared in these chunks or blocks, which are often cut on speech boundaries. And then the meeting on top may use these items directly, or may modify them to redact them, or may cut them differently. Where it can then refer to an object by a range of bytes. There can also be layers that are direct derivatives, where some sort of processing has occurred, such as an audio cleanup. Or a compression step.

This allows one to take part in multiple concurrent meetings, effectively, which a form of multi person meeting ?  When each person comes back to talking to the other one, it is speaking to them and the work of their bots and your bots.

Make widgets like rapid wordstream interfaces on watches that can let you rapidly ingest streams of relevant text to load up your mind rapidly.