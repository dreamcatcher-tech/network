
>[!tip] Created: [2023-11-27 Mon 08:32]

>[!question] Targets: 

>[!danger] Depends: 


~~react component remount errors~~
~~whisper errors~~
~~bug in assertion for artifact~~
make threads use loopback
goalie UI tester in storybook
schema as first class member.
automated tests / appraisals.
UI for the automated tests of bulk changes
Present this as a jitter - the storybook should be able to preselect what the jitter is so you only need to input the data, or have it automatically begin processing so you just refresh the page and it starts operating.  The tests should be run inside a jitter, not their own item.

Draw on the stateboard as the normal way to do things.
Show the filesystem in the stateboard.




system prompt writing loop - provide a test for an assistant, and say what is lacking / how to assess success, then task the AI with iterating on how to make an assistant prompt that passes the tests we set.  Be able to watch progress and to interject with chat comments as to what you think should be different, then have it run a bunch of iterations as it tries to improve.

Detect when it isn't getting much better after N times, and show a graph of progress to express its issues, which it shows to the user asking for some help.  This will enable our prompt creation studio - a forge - which can help us get the quality of our bots up high.

The storybook for automated tests would auto load the md file, process it, show these results on screen, and begin running all the tests based on some system change.

Once we have permanent storage, you would edit the md file, and it would auto trigger the run, and you could come back and check on how it was doing at any point, or be notified when it finishes.

Make a system that appraises the documentation in the chain and says what was ambiguous or not helpful.  May suggest docs that should be improved based on the use case they just hit.  These changes can be accumulated in large suites of tests that can ensure the documentation is compact, to the point, and covers huge numbers of possible use cases.  This makes the platform highly robust, very understandable to human and machine, and is boosted by machine, but can be improved by humans making a direct contribution rather than an issue and a PR.