
>[!tip] Created: [2024-04-14 Sun 19:45]

>[!question] Targets: 

>[!danger] Depends: 

provision cleanly
should never be sending 'after' to the server
implement pause and resume on the terminal so that hidden pages do not poll for changes
dropping the db should lock all the incoming requests
maintenance flag on the db to pause all clients - drop needs to be instantaneous
reload the page when a terminal stream error is detected
clients should detect home address change and reload the page
clients should detect when what they're watching has died, and take recovery action
clients should detect when the UI has updated, and should cause a reload
clients should detect when they are not the primary tab and go to sleep to save resources
set an env var to do a db drop if home repoid matches as part of provisioning for cleanliness
be able to pull the latest version from HAL
push to HAL
push to a branch above you, such as your actor branch
webhooks on github repos to pull in the latest version
save changes to hal to the actor, then to the top level repo, then to github
ls to browse multiple sessions
set the git commit to be the hal session commit, not the terminal commit
show the help file and the thread in a viewer
push and pull to github from a hal session
hal.ts is not the same as hal in the ui - theyo need to be the same thing
help file writer that writes the help files and updates a summary list
implement halv0.2 as bot maker
map reduce operation for data records
make a deployment of the CRM using a restricted help file
banking csv processing example - auto generate test data, then generate types of usage and user interactions
implement cancellation of process options, so can stop the llm if it has run away
multisession with each user name different
mobile phone dimensions testing

speed up the system in test environment
	Native pierce relay, rather than thru an isolate
	lazy branching without doing a commit
	Branches should be more instantaneous 
	For daemons, no need to send a reply back
	pierce tracking should be not splice based, but dedicated in the db
	make branching be part of transmission so its atomic
	Do not use the queue if you can do the next action directly
	branches should be skipped in creation if they are transient
	generate the first non machine terminal at the same time as root terminal is created
	why is hot ping causing branches to form ?
machine merging
github oauth logins
speed up cloud usage
Pierce should be atomic and retry
multithreaded ai chat in test environment
show threads of help invocations in UI
backstage admin view for graphs of the whole system - show historical token rate
navigating git in the UI
be able to update HAL and push back to the core repo
small customer test
larger than atomics can handle features - be able to spawn 1000 branches gracefully
large customer test
mertrics on cloud, including error rates, so can tune effectively
certain errors in atomics should be atomic errors and not cause a message retry
atomics should be resumable very cheaply, with all async ops done at once, before commit
store pierce outputs directly, so that splice watching can be skipped over
reliable high volume transaction processing, but start with reliable low volume for SM
Benchmarks
Do not clone HAL each session, do this only once on account creation
Change account management in the UI to use dedicated account chains
batch branching
make ts types and schemas for isolates come from a single source of truth, and be exported as a separate package.
make accountid and sessionid be more compact and friendly
implement dns lookups for actorId values based on registered github names and orgs

Full user account testing
oauth
billing
Large file loading
Parallel intelligence tests

Modifying lots of files in parallel, like separate customer records.
Dashboard with total processing for the platform, and the protocol in general, like tokens consumed, ai credits spent, db writes and reads, data under management.

inside a deploy instance, is each run isolated fromt he other ?
how much impact does the ajv schema step have for us ?

isolate reuse counter by storing a global and incrementing it each time.

How can we get back to helps and generating NL apps ?

Fine tuning on synthetic data once we have big prompts that we like and want to bake the model down for speed - can bake multistep operations to increase speed.
Vector db usage so we can use embeddings liberally, to make recall across large datasets.
if browser detects a new installation, it should dump its application state and reload.