
>[!tip] Created: [2023-09-30 Sat 23:10]

>[!question] Targets: 

>[!danger] Depends: 

The data stream of the prompt should be saved as this is valuable to have.

If the UI could interpret prompts from gpt, such as graphcs of tokens held, then we could allow for more general questions about the state of things, such as "what do you think the value of this thing will be in 2 years ?" and "what is the sum of the top 5 packets ?"

Can use typescript to force a format to be met, and allow it to keep trying until it gets it right.

Let it plot charts about how groups of packets have progressed.

Can develop your own dashboard homepage with charts that you have defined in natural language, and control the layout using natural language.

So even adjusting a window should be like "little bit left" and have the object representing the window layout be adjusted slightly by the ai prompter, which is then interpreted by the UI.

So by default, the whole app is laid out in natural language, with the UI elements just rendering what the language machine sent back.  Means we can get people to chat up some UI elements of their own, making them creative.

Particularly since the graphcs can be generated by image generators, we can make highly customized UIs.  Then can sent it off to some human for some polish.

So the chat bot would be the help, as well as the controller of it.

There could be a component definition language that is almost text based that can be used to generate UIs.  Almost be like a form of mermaid diagram by for NLP interfaces, so buttons, forms, scroll boxes.

"Always show me graphs as pie charts" should know to update a global register of preferences, which are stored as natural language, and used to decide how to output the current UI state.
"make the screen show dark".

Preferences being always natural language is better, since it is more user intent based.
We could interpret requests and normalize them against common settings others use.

Screen is like a terminal screen, where each screen is fully redrawn on every change.

Could probably hold the whole UI state within the AI model in ram, and so changes to it via NLP can be with clicking on a gui that triggers an NLP instruction, or using NLP.
This means that user stories can be specied as natural language, and perhaps an application can be generated from just this description.

Should be able to auto generate a state chart for any GUI that was described in this markdown / yml style format.

"take a whitelist of what tokens to show from site xyz"

Blockchain aspect is important so we can do all the AI tricks offline, but also so we can share resources to allow anyone to contribute them, and so we can provide cheaper and faster response times, plus trust.  Also gives us a faster to build system, with AI built in by default, and global scalability built in.  But primarily it provides data self sovereignty to the users, and provenance of all changes.  Blockchain gives the rollback, simulate forwards aspect that is critical for an AI powered system - always be able to back out of your changes, no matter how large, and always be able to simulate what they changes will be, then apply them directly - this part is key for AI to be able to learn what it should have done, but also for humans to consider the complex changes an AI proposes to make.  Atomically being able to merge these in is critical.

Goal is that if this is the first framework you learned how to use, then you would think it insane to do any other way.  So ignoring the cost of learning, this would be a quicker framework, plus has a labour market built in.

Can switch out the UI that you are using.  Each selected LLM would need to pass a basic fitness test before being allowed to drive.

Changing preferences can be done like writing a packet - the target is the preferences file, which has a strict format, where new formats can be added in as people invent new things and names for things they want.  Then a translation to a standardized form for all.  When you ask for what you want, it will put up a diff of the preferences that it is about to change for your approval.

Key is that everything must be undoable, and also outcomes simulatable before commiting to anything.  Give people a strong sense of being in control, and that the AI won't do anything they were not ok with.

Traditional UI could be navigated with a prompt and response window down the bottom, that can move around the UI, but the whole UI is the target of the chat, and is made compatible with the prompt interactions.  eg: all text box edits are diff capable, all actions from the ai are undoable.  Navigation can be performed easily.  Some actions, like nav, the ai just takes since they are not change inducing to the permanent state.  Back button in browser undoes that.

An API should be an LLM into the system ?  Remote system describes what it wants, target simulates the output, and the remote system iterates until ready to commit.

Prompt gives you search ability too, like all the packets that mention "rain".
