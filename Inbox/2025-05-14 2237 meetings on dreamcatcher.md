
>[!tip] Created: [2025-05-14 Wed 22:37]

>[!question] Targets: 

>[!danger] Depends: 

Option 1: We could open the browser in Horizon and then each of us could share our current Dreamcatcher tab. 

For any connected computers, we could allow them to either share their whole screen or some other thing using the Chrome Screen Sharing Protocol, and then that would stream back to a widget that we could all observe within the Quest browser. 

We could allow the sound to be done by Meta so that we're talking and the speech and the motion and the liveliness is handled by the VR provider. 

We could use the browser's mic and transport that over Artifact so that the sound was handled by us, so that we can tap it for transcription purposes. It means that we could use buffered speech to control what's coming back in from the other person too, otherwise we're at the mercy of real-time only.

We would have keys in the browser that would let us mute the main stream so that we could pass in instructions to our Dreamcatcher instances. 

We could make a WebXR or some kind of a VR compatible version of our webpage that turned the controls for Artifact into something 3D. 

when sharing your widget or your workbench, could allow to see others mouse movements, but also could let them interact with the system, just guards on the important stuff like account control.

Worst-case, if being in browser mode defers the presence cues that we get from the avatars, we can move to an app like Fluid that specializes in multiple browsers. We don't need a shared browser window; we just have our individual widget windows. 