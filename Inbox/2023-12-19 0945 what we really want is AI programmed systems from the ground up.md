
>[!tip] Created: [2023-12-19 Tue 09:45]

>[!question] Targets: 

>[!danger] Depends: 

So we need to build a system that can let us architect in natural language, with AI helping to refine the thinking and designs, and then implementing those systems in various concrete forms, like javascript, python, or TLA+

If we can design our systems in this way, we need not toil nearly as much to keep a system alive and renewable.  Regeneration of the system is much easier and open to the maximum number of people.

The lower down from this pinnacle we exist, the more toil for us, and the more the chance of falling off the mountain, so to speak.  The more entropy in the system, the more chance of collapse.  Whereas pure language at the pinnacle, endlessly assailed and cleaned by AI, the more chance we have to stay structurally sound, as rot can be cleaned downwards, confusion is cleansed at the top.

Each of these atoms of reasoning would be an NFT, and missing pieces could be encapsulated in NFTs to be.  So a roadmap could be auto generated out of the logic plans we have, and the estimated work required to fill in the holes.

So how would we specify the dreamcatcher in this way ?
How would we specify the system that designed systems in this way, in this way ?
What about the protocol for channels between chains, with promises, and then with a later rendition for generators ?
Make the solidity contract flow design work in this way ?
Define some metrics around these solutions like chatter, size of payload, and other types of measurement that are design goals, which any given design should optimize for.


Could make some artifact datums that represent flowchart elements.
In order represents a sequence.
Branch or switch is a control flow object that has children, which can ln to something in the flat top level flow.
Parallel is another flow element.

So to design the stuckloop, we could lay out a block diagram, and then run some scenarios thru it.  We would then adjust the blocks until the output of executing in AI mind was satisfactory, and then we would generate more scenarios.  Teach each box how to generate some sample outputs, so that when "executing" it has some parameters that it uses as a guide to limit responses.

This would define the API of each function that is required, and we could start with the schema of the function IO and build up from there.

With this system, we should be able to describe how the charging mechanism of our main chain works, and run some scenarios thru it to see what happens.  Answer questions from people about it, where their questions are curated by AI and errors or open questions are fixed by us, so that either the model is improved, or with a small tweak a suitable answer can be generated from the existing design.  So set up scenarios to describe all the questions people have about it.  Ensure the model can withstand this NL assailing.

What if we made ambient attribution work inside a game first ? Where all player actions are accounted for, and the AI decides who earned what on a given raid ?

Might be striving for making a TLA+ NL interface, where getting to a working model is the goal of the system, and guarantees correctness, then the implementations in whatever language for execution are independent.  TLA+ is hard to learn, but with NL tools it could be much easier to get a good quality model.  Changes in the TLA model directly could be reconciled with the NL model.

Then, we would check an implementation with the TLA model, rather than the NL model, since the NL model still allows ambiguity.