
>[!tip] Created: [2025-01-10 Fri 09:40]

>[!question] Targets: 

>[!danger] Depends: 

allow deals where people can purchase peak bandwidth ahead of time, so if congestion will make things hard, some providers might sell dedicated slots in advance

The redudancy links could also be a form of TOR, so censorship resistant realtime streaming.

Have checkers in the streams that determine if a node did indeed do what it was supposed to.

If the hops were made to be super low latency forwarders, and hopefully can begin the forwarding before the packet has fully arrived, decreasing latency, particularly if there are many hops to be made.

If we ran our meetings using this model of a source that is always on, then we could make supercuts of voice messages we each left, plus replies that were async, plus we could have very short meetings that get aggregated.

So instead of a heavy broadcast, we can have very short broadcasts, and the bots cut them up an enhance what we say plus say something of their own.

This is a good avenue to go down, since the reliability of blockchains but also brought to realtime streaming seems gold.

Every venture always has the economic structure baked in to it, like conways law or something, and so having a clean and fair equity structure is key

This should be able to work on local meshes, so that on a local city block network, the service can be discovered and the video call can occur strictly between meshed nodes, rather than going thru the telcoms carrier.

Cut thru forwarding can be applied on the wireless mesh to ensure very low latencies.

Replace the local phone system within a corporation, and remove the local lan as different to the internet.

A network built in this way should be easy to make a netflix clone, particularly where the media is coming from different places rather than a centralized library, and it should also be able to support low latency video calling and gaming, all on the same underlying transport, so it makes this like one layer above the internet where the additional concerns of the last decade have been incorporated.

The model is that all sensors are broadcasting constantly, and are able to broadcast to the whole world in realtime, then all use cases are actually just a degradation of that, rather than struggling hard to lift each node up to be that world broadcast capable thing.  This is an inverse model to the current way of doing things.

A decentralized, trust-layer SFU with sandboxed app execution can preserve data sovereignty by separating code authorship from data handling. The SFU acts as a neutral broker for streams, while sensitive data is processed in isolated runtimes. The “always-on” mic scenario benefits from this because neither the hardware maker nor the app vendor directly sees raw streams; instead, they interact with a third-party node specialized in secure transport and execution. This approach is akin to autonomous “virtual entities” that can independently join or leave any system, but with cryptographic guarantees to safeguard user data end to end.

Being an SFU seems like something that traditional centralized struggles with due to the architecture, and so it is costly to do at scale in central.  So a decentralized version should out perform by all measures.

WebRTC should be used for sending and receiving the workloads as well, due to the minimum latency, so we can be even faster than the nearest anything.  And once quic becomes mainstream, our apps have excellent switchability characteristics too.