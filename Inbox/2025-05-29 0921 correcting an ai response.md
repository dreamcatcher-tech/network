
>[!tip] Created: [2025-05-29 Thu 09:21]

>[!question] Targets: 

>[!danger] Depends: 

this seems critical to the training of the system.  it's the key thing humans want from a system.

if the ai gives a response, and I refute it, then the global knowledge base should be updated, so that it never makes that error again.

this requires a verification source, and for things like software, this can easily be checked.

some knowledge is live, and so a checker can be used to ensure currency.  like what are the cli args for something.

if we were all contributing to this curated knowledge base, we'd all be much happier

> this begs for the construction of an AI wikipedia

with an ai gatekeeper that allows update only after scrutiny, plus a staking system so you can earn credits for guaranteeing correctness using staked currency.