
>[!tip] Created: [2025-09-19 Fri 13:13]

>[!question] Targets: 

>[!danger] Depends: 

if we have a gateway app that handles clerk, and then once the use has proved their clerkness, they get redirected to their computer.

they are their browser, rather than they are their computer, so they might have access to other computers based on their clerkid.

each computer is a folder on the server, named after their clerk id.
they can make other computers, but something in there points back to their clerkid.

have a gateway service that walks users thru the auth loop.  this is clustered.

Each computer has a clustered little image of fast machines that handle the incoming traffic, check auth, wake up workers, assign fibers to workers.

these are nameless and stateless.

we do several fly replay hops
1. hits the external gateway which handles auth
2. fly replay over to the computer the user is trying to hit after checking the auth
	1. look at the dns name and figure out the computer mapping
	2. create the computer if it does not exist
	3. fly-replay over to the app that represents the computer they are trying to hit
3. on the computer gateway machines, fly replay to the agent they want to hit
	1. look at the subdomain to walk the proctree to find the target agent
	2. check the auth allows them to connect with that agent, using just the nfs state
	3. if allowed, ensure there is a running machine for that agent
	4. fly replay onto that agent

principle: each computer is reponsible for its own auth.

The nfs fiber state does not have to be commited to start with, as it can be just pure nfs disk persistence.  file locks ensure that the agent is exclusive on the file.

flat fiber ids for each agent, just monotonically increasing.
tree can be deduced from the flat layout.
names of the agents are dynamic and are in the agent state.

git repos are stored flat, by a monotonically increasing id ?
or have no overlaps, since we cannot efficiently make use of the same git repo in several locations

workspaces are stored per agent, in the agent state.
agent state has the boot config, the workspace, and the running state.

use the NFS store to track the list of running machines ?
holds the mapping of agentIds to machineids.
maps agent dns names to machineIds.

default behaviour on landing on the computer is to redirect to a new agent in the /entry folder, which is given a funny memorable name, and is destroyed when the user leaves the page, or decays when they haven't been there in a while.

the proc folder can be read by all, but can only be altered by making mcp calls.

set the image for the worker in the nfs store when a build succeeds.
basically, each worker image app exists purely to generate the images and validate they work in fly infrastructure, but the computer app will decide what image to use when it needs one.

principle: repos are the shared data between agents - agentic state is private.

computers need to be able to store their own repos
is a computer actually a git repo too, but with the special consensus branch in place ?
The computers folder is actually within a bigger computer, which is the hoster computer ?

the nfs filesystem layout.

```
computers/
	c1/
		config.json (latency, cost, soveriegnty)
		agents/
			a1/
				parent (symlink to the parent agent folder)
				children/
					childName1@ (symlink to child agents by agentId)
					childName2@
				machine.json@ (symlink to the machine we are running on)
				config.json
				agent.toml (agent config and also git repos the workspace needs)
				home/ (where the agent stores its chats and inner workings)
				summary.md
				workspace/ (the mutable workspace for the agent)
				messages/
					inbox/
						c3:a2/
							0.json
							1.json
					outbox/				
			a2/
			a3/
		repos/
			r1/ (can be authoratative, or clones of remotes hosted elsewhere)
			r2/
		machines/
			.lock (only one writer at a time)
			m1.json (agentId?, running state, dockerImage)
			m2.json
			m3.json
	c2/
	c3/

```

later, we would start to store repos on a per computer basis.
repos have to live somewhere, since computers are the only place we ever store anything.
computers are a repo themselves.
repos are repos, but they are symlink refferenced by a computer, and also symlink referenced inside agents.

machines with no agentId are hot standby

if the fly app is the name of the computer, then we don't need any mappings.

for a computer to know what its nfs path is, it would just look at its name, and then mount the nfs share.

computer always has a root agent ?
no, computer always has a serve/ agents directory, so it can handle multiple incoming requests, like a landing area.  maybe incoming, or lobby, or concierge, or shell ?

must use bind mounts to expose workspace etc.
agent-home is for agent home, so we don't pick up cache dirs etc.

so computer would boot up, mount the nfs server, and then start walking around doing admin
agents would boot up, mount the nfs sub path they were given, use bind bounds to expose workdir and other things to the right place, possibly bind mounting .codex so we get all the session data too.
