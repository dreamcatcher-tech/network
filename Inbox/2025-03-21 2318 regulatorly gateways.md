
>[!tip] Created: [2025-03-21 Fri 23:18]

>[!question] Targets: 

>[!danger] Depends: 

regulated industries like an insurance company require humans to adhere to certain standards. We should be able to put bots in place that can police these things and ensure that anything going out is always in adherence with policy.

The same system could be used to enable AIs to begin responding to clients in real-time, possibly even without human supervision, so long as we had trust in the regulatory crowbar that would block anything that sounded suspicious. A bad AI, one that wasn't performing well, would get flagged a lot and cost a lot of tokens to determine whether or not it was wrong.

I feel like these systems will always have to be two separate systems: a semantic firewall that performs various regulatory checks and the generative creative answer-generating system. 

almost like a tension between creation and control. 