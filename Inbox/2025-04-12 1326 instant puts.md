
>[!tip] Created: [2025-04-12 Sat 13:26]

>[!question] Targets: 

>[!danger] Depends: 

Making a KV store cache solves medium performance issues in one hit, but it still results in sequential puts. 

So if put returned instantly but a get for the same key had to wait for the put to be complete that might be faster. 

Most helpful is knowing who made the actual call and why, like what context was the call made within.

We could make a blobstore which was a wrapper around the base blobstore, or a clone, which we could use to flush the promises out of ?

Then we make it instant for puts ?

So the issue is, if the puts are for cas objects, what to do if the put fails ?

Before shutdown, the kv store cache should finish all its puts to the bucket ?

kv store is good anyway, long term.

but is it safe to say a put is done when it isn't ?
It only matters once we go to write the head.

First we need to make sure that it is actually git that is doing these sequential writes.
Then we need to have a way to await them all before we write them.

The kv cache should be there ANYWAY but only for reads, writes should be handled by a context aware buffer.

rm could be be considered instant too, where we rm from the cache first, then rm from the remote bucket.