
>[!tip] Created: [2024-05-02 Thu 17:28]

>[!question] Targets: 

>[!danger] Depends: 

Ingesting much case law, we should be able to generate a license document that incorporated vast amounts of wisdom that was designed to be the Dreamcatcher license.

The definitive attribution system is the chain of upgrade reasoning from running the initial council of LLMs.

Basically anyone can run them, and anyone can add new models or suggest changes to the prompts.

The LLMs know about reputable sources from their training and so can make judgements on new models being released and included in the swarm.

They can review code that makes them able to call external services.

They can prove that a given API call was made in error, by storing ssl certs, and then we can sue companies or something like that and cause the AI to run again.

If they had an autonomous sense of truth, they should be able to carry much of this with them from their training, and they should know how to verify that something is correct with a few trusted outreach methods.

A blockchain that let many users submit staked versions of the news, so the AIs could rely upon these at huge loss to the users if the falsified information.

The license is updated by the bot swarm, and they also run the judgements on it.