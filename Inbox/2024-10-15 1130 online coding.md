
>[!tip] Created: [2024-10-15 Tue 11:30]

>[!question] Targets: 

>[!danger] Depends: 

If we could front vscode entirely online, and then have some kind of adapter that causes code runs to execute in aws lambda functions, then we could write all our code in the browser ?

Linting and type checking might be able to run in browser ?

So it would be like stackblitz, but backed by lambda functions that ran in parallel, and used artifact for the filesystem.

Artifact can integrate a git tool, so there is only git as the fs.

Linter would run in the browser.

All the files would be integrated with artifact directly.

So the browser would be a widget.

Running napp tests would be done on artifact, which is just another widget that runs.

Push pull from github is managed in editor.

Debugging could be handled by providing a docker container that connects to the debugger in the browser.  So the docker container spins up only as needed, or it could be along running lambda ?

Or, make a version of the debugger that uses lambda to run to the breakpoint, and the return the result, so AI can use it ?

May need codemirror instead of monaco: https://blog.replit.com/codemirror 

Plug in to some other online services, like replit, to make the online debugging work, as they will handle all the orchestration of services in the background, and probably have some debugger protocols that we can bolt on.

You should be able to start your own server, and connect it up to artifact to await commands such as starting a debugging session.

If we are heading in this direction, then there is no more need for a desktop workstation, just a mobile phone and maybe a second screen.  Laptop goes away too, since having a net connection is all that matters.  Maybe a github codespaces repo when required.  VR sessions only need a browser window, not a whole desktop.

A local cpu for times when the net is poor should be kept available.  It would be the primary supplier of resources, and would always be speculatively attempting to execute.  If it hits a web api request, then it will pause and wait for status of the cloud deployment, since it needs this ability anyway.  So you could just use this thing thru a tunnel, and use a web browser to interact with it, then it manages going out to the net or not.  If it finishes first, it returns that result to you, else returns the remote.  Also updates the remote version if it comes in after, since this like a chain reorg.
## Benefits
No local dev needed.
AI attached to coding.
Very cheap to get high powered machines using lambda functions, provides vast parallelism on demand with zero idle cost.
Shareable with others.
Easy to publish a stuck, with incentives attached.
Zero setup for collaboration.