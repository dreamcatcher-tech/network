
>[!tip] Created: [2024-08-10 Sat 10:32]

>[!question] Targets: 

>[!danger] Depends: 

If we set up a schema that gives ways to think about a problem, some target goals, and then we can force a style of thinking on the bot.

The response would be the final part of the prompt, but the reasoning steps make it far more accurate.

User could see the reasoning steps first, whilst the longer prompt is being generated.
Or at least be able to show it later if they wanted to drill down.

Get the bot to select what behavioural rules seem most relevant to adhere to.

Can additionally stop the prompt part way thru and do some reassessment to keep incremental steering going.

Also allows the bot to answer the question "why did you say that ?" with more clarity, since its thinking is recorded.

The trick is to influence the final outcome with some thinking beforehand.