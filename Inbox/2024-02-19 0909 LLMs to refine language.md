
>[!tip] Created: [2024-02-19 Mon 09:09]

>[!question] Targets: 

>[!danger] Depends: 

An LLM should be able to reason thru making a new language, where it is logically consistent, and easy to express all the concepts it knows about in english.

It may be a good intermediary language between all languages.

Like math, but more for description and communication.

Should give us a cleaner way to think, and a more direct way to interact with LLMs.

Should provide a way to generate synthetic data in a way that LLMs can be trained on cleanly.  Catergorizing something as true or not should be deferrable and switchable, where all that matters is logical consistency.

Any truths that an LLM says should be traceable down to some assumptions that trigger something being true or not.  The whole system is floating, and says things only based on other things.