
>[!tip] Created: [2023-12-11 Mon 08:14]

>[!question] Targets: 

>[!danger] Depends: 

Once we make an eval suite, we should pay for improvements in scores.

Say what the limits of the allowed LLMs are.  Eg: cost, openness

Pay for log improvements.

Set up pipelines of prompt passing using functions to chain things together.
So make a pipeline like interface, so they can get called with something, then they return back some output, or possible trigger other trees of actions.