
>[!tip] Created: [2024-11-19 Tue 11:52]

>[!question] Targets: 

>[!danger] Depends: 

Reasoning is here to stay, and will only get better.

An agent could be constructed to critical reason about some statements another agent gave to them.  It could in the background use TLA+ to create a logical model and then reason it thru, then highlight any errors in the model that could not be reconciled.

Different kinds of reasoner could be constructed and all could run in parallel, with early results coming back from fast ones vs deeper results from others.

One could be made to use only modal logic to analyze the situation, and another could use some other class of logic.

This swarm should come at it from many different angles.